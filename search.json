[
  {
    "objectID": "westdri_talk.html#about-me",
    "href": "westdri_talk.html#about-me",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "About Me",
    "text": "About Me\n\nUBC Economics, research in econometrics, industrial organization\nMy Website\nmy github\nTeach courses using Julia\n\nECON 622: Computational Economics with Data Science Applications\nECON 567 (empirical industrial organization)"
  },
  {
    "objectID": "westdri_talk.html#useful-resources",
    "href": "westdri_talk.html#useful-resources",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "Useful Resources",
    "text": "Useful Resources\n\nPerformance Tips in Julia Manual\nHow to optimise Julia code: A practical guide Nissen (2022)\nOptimizing Serial Code Rackauckas (2019)\nCoding for performance (basis for this talk) Schrimpf (2019 (revised 2024))"
  },
  {
    "objectID": "westdri_talk.html#overview",
    "href": "westdri_talk.html#overview",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "Overview",
    "text": "Overview"
  },
  {
    "objectID": "westdri_talk.html#avoid-premature-optimization",
    "href": "westdri_talk.html#avoid-premature-optimization",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "Avoid Premature Optimization",
    "text": "Avoid Premature Optimization\n\n\nComplete, correct \\(&gt;&gt;\\) fast, incorrect, unfinished\nClear, maintainable \\(&gt;\\) fast, incomprensible (almost always)\nBut some practices can both make code faster and clearer"
  },
  {
    "objectID": "westdri_talk.html#functions",
    "href": "westdri_talk.html#functions",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "Functions",
    "text": "Functions\n\nJulia functions are JIT compiled, global scripts are not\nCode needs to be in a function for full performance\nOrganizing code into functions is also better for readability and maintenance"
  },
  {
    "objectID": "westdri_talk.html#type-stability",
    "href": "westdri_talk.html#type-stability",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "Type Stability",
    "text": "Type Stability\n\nTo generate efficient code, the Julia compiler needs to know the types of all variables\nGiven the types of the inputs of a function, the types of its intermediate variables and output should be deterministic"
  },
  {
    "objectID": "westdri_talk.html#type-stable-example",
    "href": "westdri_talk.html#type-stable-example",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "Type Stable: Example",
    "text": "Type Stable: Example\n\nusing BenchmarkTools\nfunction unstabletrick(x, t)\n  sum(xi &lt; t ? xi : t for xi in x)\nend\n\nt = 0.5\nn = 10000\nx = (rand(n).-0.5)*10"
  },
  {
    "objectID": "westdri_talk.html#type-stable-example-1",
    "href": "westdri_talk.html#type-stable-example-1",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "Type Stable: Example",
    "text": "Type Stable: Example\n\n\nStable: Float to Float\n\n@benchmark unstabletrick(x, 0.)\n\n\nBenchmarkTools.Trial: 10000 samples with 3 evaluations.\n Range (min … max):  8.869 μs …  32.050 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     8.873 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   8.934 μs ± 512.959 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n  █▁▁                             ▂                           ▁\n  ███▆▅▄▁▃▁▁▁▁▃▃▁▃▁▁▃▄▁▃▁▁▁▁▁▁▁▁▁▃█▄▅▁▁▁▃▁▁▁▁▁▁▁▁▃▆▇▆▆▄▄▄▁▁▄▄ █\n  8.87 μs      Histogram: log(frequency) by time      9.89 μs &lt;\n Memory estimate: 16 bytes, allocs estimate: 1.\n\n\n\n\nStable: Int to Int\n\nxint = round.(Int, x)\n@benchmark unstabletrick(xint, 0)\n\n\nBenchmarkTools.Trial: 10000 samples with 10 evaluations.\n Range (min … max):  1.774 μs …  4.231 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     1.799 μs              ┊ GC (median):    0.00%\n Time  (mean ± σ):   1.808 μs ± 80.238 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n       ▂▄▅▆█▆▄▃▂▁                                             \n  ▂▂▃▅▇███████████▆▆▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂ ▃\n  1.77 μs        Histogram: frequency by time        1.92 μs &lt;\n Memory estimate: 16 bytes, allocs estimate: 1.\n\n\n\n\nUnstable: (Int & Float) to (Int | Float)\n\n@benchmark unstabletrick(xint, 0.)\n\n\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  53.550 μs … 206.241 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     55.188 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   57.352 μs ±   6.870 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n  ▁▆█▆▂  ▃▃▂▁▂                                                 ▁\n  █████▆▇██████▇██▄▅▇▆▄▃▅▄▂▅▇▇█████▇█▇▇▇▇▆▆▅▅▅▄▃▂▃▃▂▂▃▅▃▄▄▆▅▆▆ █\n  53.6 μs       Histogram: log(frequency) by time      89.3 μs &lt;\n Memory estimate: 16 bytes, allocs estimate: 1.\n\n\n\n\n\n\n6-32x slowdown!"
  },
  {
    "objectID": "westdri_talk.html#detecting-type-instability",
    "href": "westdri_talk.html#detecting-type-instability",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "Detecting Type Instability",
    "text": "Detecting Type Instability\n\n\n\n@code_warntype unstabletrick(xint,0)\n\nMethodInstance for unstabletrick(::Vector{Int64}, ::Int64)\n  from unstabletrick(x, t) @ Main In[2]:2\nArguments\n  #self#::Core.Const(unstabletrick)\n  x::Vector{Int64}\n  t::Int64\nLocals\n  #13::var\"#13#14\"{Int64}\nBody::Int64\n1 ─ %1 = Main.:(var\"#13#14\")::Core.Const(var\"#13#14\")\n│   %2 = Core.typeof(t)::Core.Const(Int64)\n│   %3 = Core.apply_type(%1, %2)::Core.Const(var\"#13#14\"{Int64})\n│        (#13 = %new(%3, t))\n│   %5 = #13::var\"#13#14\"{Int64}\n│   %6 = Base.Generator(%5, x)::Base.Generator{Vector{Int64}, var\"#13#14\"{Int64}}\n│   %7 = Main.sum(%6)::Int64\n└──      return %7\n\n\n\n\n\n@code_warntype unstabletrick(xint,0.)\n\nMethodInstance for unstabletrick(::Vector{Int64}, ::Float64)\n  from unstabletrick(x, t) @ Main In[2]:2\nArguments\n  #self#::Core.Const(unstabletrick)\n  x::Vector{Int64}\n  t::Float64\nLocals\n  #13::var\"#13#14\"{Float64}\nBody::Union{Float64, Int64}\n1 ─ %1 = Main.:(var\"#13#14\")::Core.Const(var\"#13#14\")\n│   %2 = Core.typeof(t)::Core.Const(Float64)\n│   %3 = Core.apply_type(%1, %2)::Core.Const(var\"#13#14\"{Float64})\n│        (#13 = %new(%3, t))\n│   %5 = #13::var\"#13#14\"{Float64}\n│   %6 = Base.Generator(%5, x)::Base.Generator{Vector{Int64}, var\"#13#14\"{Float64}}\n│   %7 = Main.sum(%6)::Union{Float64, Int64}\n└──      return %7"
  },
  {
    "objectID": "westdri_talk.html#extended-example",
    "href": "westdri_talk.html#extended-example",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "Extended Example",
    "text": "Extended Example\n\n\n\n\nCode for klm()\nusing ForwardDiff, LinearAlgebra, Distributions\nfunction statparts(gi::Function)\n  function P(A) # projection matrix\n    A*pinv(A'*A)*A'\n  end\n  function(θ)\n    giθ = gi(θ)\n    p = length(θ)\n    (n, k) = size(giθ)\n    Ω = cov(giθ)\n    gn=mean(gi(θ), dims=1)'\n    Gi= ForwardDiff.jacobian(gi,θ)\n    Gi = reshape(Gi, n , k, p)\n    G = mean(Gi, dims=1)\n    Γ = zeros(eltype(Gi),p,k,k)\n    D = zeros(eltype(Gi),k, p)\n    for j in 1:p\n      for i in 1:n\n        Γ[j,:,:] += (Gi[i,:,j] .- G[1,:,j]) * giθ[i,:]'\n      end\n      Γ[j,:,:] ./= n\n      D[:,j] = G[1,:,j] - Γ[j,:,:]*inv(Ω)*gn\n    end\n    return(n,k,p,gn, Ω, D, P)\n  end\nend\n\nfunction klm(gi::Function)\n  SP = statparts(gi)\n  function(θ)\n    (n,k,p,gn, Ω, D, P) = SP(θ)\n    return n*(gn'*Ω^(-1/2)*P(Ω^(-1/2)*D)*Ω^(-1/2)*gn)[1]\n  end\nend\n\nimport Random\nfunction simulate_ivshare(n,β,γ,ρ)\n  z = randn(n, size(γ)[1])\n  endo = randn(n, length(β))\n  x = z*γ .+ endo\n  ξ = rand(Normal(0,sqrt((1.0-ρ^2))),n).+endo[:,1]*ρ\n  y = cdf.(Logistic(), x*β .+ ξ)\n  return((y=y,x=x,z=z))\nend\nn = 100\nk = 2\niv = 3\nβ0 = ones(k)\nπ0 = vcat(5*I,ones(iv-k,k))\nρ = 0.5\nRandom.seed!(622)\n(y,x,z) = simulate_ivshare(n,β0,π0,ρ)\n\nfunction gi_ivshare(β,y,x,z)\n  ξ = quantile.(Logistic(),y) .- x*β\n  ξ.*z\nend\n\ngi = let y=y, x=x, z=z\n  β-&gt;gi_ivshare(β,y,x,z)\nend\n\n\n#20 (generic function with 1 method)\n\n\n\n@code_warntype statparts(gi)(β0)\n\nMethodInstance for (::var\"#15#17\"{var\"#20#21\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}, var\"#P#16\"})(::Vector{Float64})\n  from (::var\"#15#17\")(θ) @ Main In[8]:6\nArguments\n  #self#::var\"#15#17\"{var\"#20#21\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}, var\"#P#16\"}\n  θ::Vector{Float64}\nLocals\n  @_3::Union{Nothing, Tuple{Int64, Int64}}\n  @_4::Int64\n  D::Union{Array{Float64, 3}, Matrix}\n  Γ::Union{Array{Float64, 4}, Array{_A, 3} where _A}\n  G::Any\n  Gi::Any\n  gn::Adjoint{Float64, Matrix{Float64}}\n  Ω::Matrix{Float64}\n  k::Int64\n  n::Int64\n  p::Int64\n  giθ::Matrix{Float64}\n  @_15::Union{Nothing, Tuple{Int64, Int64}}\n  j::Int64\n  i::Int64\nBody::Tuple{Int64, Int64, Int64, Adjoint{Float64, Matrix{Float64}}, Matrix{Float64}, Union{Array{Float64, 3}, Matrix}, var\"#P#16\"}\n1 ─ %1  = Core.getfield(#self#, :gi)::var\"#20#21\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}\n│         (giθ = (%1)(θ))\n│         (p = Main.length(θ))\n│   %4  = Main.size(giθ)::Tuple{Int64, Int64}\n│   %5  = Base.indexed_iterate(%4, 1)::Core.PartialStruct(Tuple{Int64, Int64}, Any[Int64, Core.Const(2)])\n│         (n = Core.getfield(%5, 1))\n│         (@_4 = Core.getfield(%5, 2))\n│   %8  = Base.indexed_iterate(%4, 2, @_4::Core.Const(2))::Core.PartialStruct(Tuple{Int64, Int64}, Any[Int64, Core.Const(3)])\n│         (k = Core.getfield(%8, 1))\n│         (Ω = Main.cov(giθ))\n│   %11 = Core.getfield(#self#, :gi)::var\"#20#21\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}\n│   %12 = (%11)(θ)::Matrix{Float64}\n│   %13 = (:dims,)::Core.Const((:dims,))\n│   %14 = Core.apply_type(Core.NamedTuple, %13)::Core.Const(NamedTuple{(:dims,)})\n│   %15 = Core.tuple(1)::Core.Const((1,))\n│   %16 = (%14)(%15)::Core.Const((dims = 1,))\n│   %17 = Core.kwcall(%16, Main.mean, %12)::Matrix{Float64}\n│         (gn = Main.:var\"'\"(%17))\n│   %19 = ForwardDiff.jacobian::Core.Const(ForwardDiff.jacobian)\n│   %20 = Core.getfield(#self#, :gi)::var\"#20#21\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}\n│         (Gi = (%19)(%20, θ))\n│         (Gi = Main.reshape(Gi, n, k, p))\n│   %23 = (:dims,)::Core.Const((:dims,))\n│   %24 = Core.apply_type(Core.NamedTuple, %23)::Core.Const(NamedTuple{(:dims,)})\n│   %25 = Core.tuple(1)::Core.Const((1,))\n│   %26 = (%24)(%25)::Core.Const((dims = 1,))\n│         (G = Core.kwcall(%26, Main.mean, Gi))\n│   %28 = Main.eltype(Gi)::Any\n│   %29 = p::Int64\n│   %30 = k::Int64\n│         (Γ = Main.zeros(%28, %29, %30, k))\n│   %32 = Main.eltype(Gi)::Any\n│   %33 = k::Int64\n│         (D = Main.zeros(%32, %33, p))\n│   %35 = (1:p)::Core.PartialStruct(UnitRange{Int64}, Any[Core.Const(1), Int64])\n│         (@_3 = Base.iterate(%35))\n│   %37 = (@_3 === nothing)::Bool\n│   %38 = Base.not_int(%37)::Bool\n└──       goto #7 if not %38\n2 ┄ %40 = @_3::Tuple{Int64, Int64}\n│         (j = Core.getfield(%40, 1))\n│   %42 = Core.getfield(%40, 2)::Int64\n│   %43 = (1:n)::Core.PartialStruct(UnitRange{Int64}, Any[Core.Const(1), Int64])\n│         (@_15 = Base.iterate(%43))\n│   %45 = (@_15 === nothing)::Bool\n│   %46 = Base.not_int(%45)::Bool\n└──       goto #5 if not %46\n3 ┄ %48 = @_15::Tuple{Int64, Int64}\n│         (i = Core.getfield(%48, 1))\n│   %50 = Core.getfield(%48, 2)::Int64\n│   %51 = Base.getindex(Γ, j, Main.:(:), Main.:(:))::Matrix\n│   %52 = Main.:-::Core.Const(-)\n│   %53 = Base.getindex(Gi, i, Main.:(:), j)::Any\n│   %54 = Base.getindex(G, 1, Main.:(:), j)::Any\n│   %55 = Base.broadcasted(%52, %53, %54)::Any\n│   %56 = Base.materialize(%55)::Any\n│   %57 = Base.getindex(giθ, i, Main.:(:))::Vector{Float64}\n│   %58 = Main.:var\"'\"(%57)::Adjoint{Float64, Vector{Float64}}\n│   %59 = (%56 * %58)::Any\n│   %60 = (%51 + %59)::Any\n│         Base.setindex!(Γ, %60, j, Main.:(:), Main.:(:))\n│         (@_15 = Base.iterate(%43, %50))\n│   %63 = (@_15 === nothing)::Bool\n│   %64 = Base.not_int(%63)::Bool\n└──       goto #5 if not %64\n4 ─       goto #3\n5 ┄ %67 = Base.dotview(Γ, j, Main.:(:), Main.:(:))::SubArray{_A, 2, P, Tuple{Int64, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}}, true} where {_A, P&lt;:(Array{_A, 3} where _A)}\n│   %68 = Main.:/::Core.Const(/)\n│   %69 = Base.getindex(Γ, j, Main.:(:), Main.:(:))::Matrix\n│   %70 = Base.broadcasted(%68, %69, n)::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{2}, Nothing, typeof(/), &lt;:Tuple{Matrix, Int64}}\n│         Base.materialize!(%67, %70)\n│   %72 = Base.getindex(G, 1, Main.:(:), j)::Any\n│   %73 = Base.getindex(Γ, j, Main.:(:), Main.:(:))::Matrix\n│   %74 = Main.inv(Ω)::Matrix{Float64}\n│   %75 = (%73 * %74 * gn)::Any\n│   %76 = (%72 - %75)::Any\n│         Base.setindex!(D, %76, Main.:(:), j)\n│         (@_3 = Base.iterate(%35, %42))\n│   %79 = (@_3 === nothing)::Bool\n│   %80 = Base.not_int(%79)::Bool\n└──       goto #7 if not %80\n6 ─       goto #2\n7 ┄ %83 = n::Int64\n│   %84 = k::Int64\n│   %85 = p::Int64\n│   %86 = gn::Adjoint{Float64, Matrix{Float64}}\n│   %87 = Ω::Matrix{Float64}\n│   %88 = D::Union{Array{Float64, 3}, Matrix}\n│   %89 = Core.getfield(#self#, :P)::Core.Const(var\"#P#16\"())\n│   %90 = Core.tuple(%83, %84, %85, %86, %87, %88, %89)::Tuple{Int64, Int64, Int64, Adjoint{Float64, Matrix{Float64}}, Matrix{Float64}, Union{Array{Float64, 3}, Matrix}, var\"#P#16\"}\n└──       return %90\n\n\n\n\n@benchmark statparts(gi)(β0)\n\n\nBenchmarkTools.Trial: 8849 samples with 1 evaluation.\n Range (min … max):  515.028 μs …   5.083 ms  ┊ GC (min … max): 0.00% … 87.32%\n Time  (median):     530.912 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   560.219 μs ± 294.968 μs  ┊ GC (mean ± σ):  3.58% ±  6.01%\n      ▂▇█▆▂                                                      \n  ▁▁▂▅█████▇▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁ ▂\n  515 μs           Histogram: frequency by time          637 μs &lt;\n Memory estimate: 221.16 KiB, allocs estimate: 3910.\n\n\n\n\n\n\nklm_stable()\nfunction statparts_stable(gi::F) where {F &lt;: Function}\n  function P(A) # projection matrix\n    A*pinv(A'*A)*A'\n  end\n  function(θ)\n    giθ = gi(θ)\n    p = length(θ)\n    (n, k) = size(giθ)\n    Ω = cov(giθ)\n    gn=mean(gi(θ), dims=1)'\n    Gi = similar(gn,n,k,p)\n    Gi= ForwardDiff.jacobian!(Gi,gi,θ)\n    G = mean(Gi, dims=1)\n    Γ = zeros(eltype(Gi),p,k,k)\n    D = zeros(eltype(Gi),k, p)\n    for j in 1:p\n      for i in 1:n\n        Γ[j,:,:] += (Gi[i,:,j] .- G[1,:,j]) * giθ[i,:]'\n      end\n      Γ[j,:,:] ./= n\n      D[:,j] = G[1,:,j] - Γ[j,:,:]*inv(Ω)*gn\n    end\n    return(n,k,p,gn, Ω, D, P)\n  end\nend\n\nfunction klm_stable(gi::F) where {F &lt;: Function}\n  SP = statparts_stable(gi)\n  function(θ)\n    (n,k,p,gn, Ω, D, P) = SP(θ)\n    λ, v = eigen(Ω)\n    irΩ = v*diagm(λ.^(-1/2))*v'\n    return n*(gn'*irΩ*P(irΩ*D)*irΩ*gn)[1]\n  end\nend\n\n\nklm_stable (generic function with 1 method)\n\n\n\n@code_warntype statparts_stable(gi)(β0)\n\nMethodInstance for (::var\"#22#24\"{var\"#20#21\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}, var\"#P#23\"})(::Vector{Float64})\n  from (::var\"#22#24\")(θ) @ Main In[11]:5\nArguments\n  #self#::var\"#22#24\"{var\"#20#21\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}, var\"#P#23\"}\n  θ::Vector{Float64}\nLocals\n  @_3::Union{Nothing, Tuple{Int64, Int64}}\n  @_4::Int64\n  D::Matrix{Float64}\n  Γ::Array{Float64, 3}\n  G::Array{Float64, 3}\n  Gi::Array{Float64, 3}\n  gn::Adjoint{Float64, Matrix{Float64}}\n  Ω::Matrix{Float64}\n  k::Int64\n  n::Int64\n  p::Int64\n  giθ::Matrix{Float64}\n  @_15::Union{Nothing, Tuple{Int64, Int64}}\n  j::Int64\n  i::Int64\nBody::Tuple{Int64, Int64, Int64, Adjoint{Float64, Matrix{Float64}}, Matrix{Float64}, Matrix{Float64}, var\"#P#23\"}\n1 ─ %1  = Core.getfield(#self#, :gi)::var\"#20#21\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}\n│         (giθ = (%1)(θ))\n│         (p = Main.length(θ))\n│   %4  = Main.size(giθ)::Tuple{Int64, Int64}\n│   %5  = Base.indexed_iterate(%4, 1)::Core.PartialStruct(Tuple{Int64, Int64}, Any[Int64, Core.Const(2)])\n│         (n = Core.getfield(%5, 1))\n│         (@_4 = Core.getfield(%5, 2))\n│   %8  = Base.indexed_iterate(%4, 2, @_4::Core.Const(2))::Core.PartialStruct(Tuple{Int64, Int64}, Any[Int64, Core.Const(3)])\n│         (k = Core.getfield(%8, 1))\n│         (Ω = Main.cov(giθ))\n│   %11 = Core.getfield(#self#, :gi)::var\"#20#21\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}\n│   %12 = (%11)(θ)::Matrix{Float64}\n│   %13 = (:dims,)::Core.Const((:dims,))\n│   %14 = Core.apply_type(Core.NamedTuple, %13)::Core.Const(NamedTuple{(:dims,)})\n│   %15 = Core.tuple(1)::Core.Const((1,))\n│   %16 = (%14)(%15)::Core.Const((dims = 1,))\n│   %17 = Core.kwcall(%16, Main.mean, %12)::Matrix{Float64}\n│         (gn = Main.:var\"'\"(%17))\n│         (Gi = Main.similar(gn, n, k, p))\n│   %20 = ForwardDiff.jacobian!::Core.Const(ForwardDiff.jacobian!)\n│   %21 = Gi::Array{Float64, 3}\n│   %22 = Core.getfield(#self#, :gi)::var\"#20#21\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}\n│         (Gi = (%20)(%21, %22, θ))\n│   %24 = (:dims,)::Core.Const((:dims,))\n│   %25 = Core.apply_type(Core.NamedTuple, %24)::Core.Const(NamedTuple{(:dims,)})\n│   %26 = Core.tuple(1)::Core.Const((1,))\n│   %27 = (%25)(%26)::Core.Const((dims = 1,))\n│         (G = Core.kwcall(%27, Main.mean, Gi))\n│   %29 = Main.eltype(Gi)::Core.Const(Float64)\n│   %30 = p::Int64\n│   %31 = k::Int64\n│         (Γ = Main.zeros(%29, %30, %31, k))\n│   %33 = Main.eltype(Gi)::Core.Const(Float64)\n│   %34 = k::Int64\n│         (D = Main.zeros(%33, %34, p))\n│   %36 = (1:p)::Core.PartialStruct(UnitRange{Int64}, Any[Core.Const(1), Int64])\n│         (@_3 = Base.iterate(%36))\n│   %38 = (@_3 === nothing)::Bool\n│   %39 = Base.not_int(%38)::Bool\n└──       goto #7 if not %39\n2 ┄ %41 = @_3::Tuple{Int64, Int64}\n│         (j = Core.getfield(%41, 1))\n│   %43 = Core.getfield(%41, 2)::Int64\n│   %44 = (1:n)::Core.PartialStruct(UnitRange{Int64}, Any[Core.Const(1), Int64])\n│         (@_15 = Base.iterate(%44))\n│   %46 = (@_15 === nothing)::Bool\n│   %47 = Base.not_int(%46)::Bool\n└──       goto #5 if not %47\n3 ┄ %49 = @_15::Tuple{Int64, Int64}\n│         (i = Core.getfield(%49, 1))\n│   %51 = Core.getfield(%49, 2)::Int64\n│   %52 = Base.getindex(Γ, j, Main.:(:), Main.:(:))::Matrix{Float64}\n│   %53 = Main.:-::Core.Const(-)\n│   %54 = Base.getindex(Gi, i, Main.:(:), j)::Vector{Float64}\n│   %55 = Base.getindex(G, 1, Main.:(:), j)::Vector{Float64}\n│   %56 = Base.broadcasted(%53, %54, %55)::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{1}, Nothing, typeof(-), Tuple{Vector{Float64}, Vector{Float64}}}\n│   %57 = Base.materialize(%56)::Vector{Float64}\n│   %58 = Base.getindex(giθ, i, Main.:(:))::Vector{Float64}\n│   %59 = Main.:var\"'\"(%58)::Adjoint{Float64, Vector{Float64}}\n│   %60 = (%57 * %59)::Matrix{Float64}\n│   %61 = (%52 + %60)::Matrix{Float64}\n│         Base.setindex!(Γ, %61, j, Main.:(:), Main.:(:))\n│         (@_15 = Base.iterate(%44, %51))\n│   %64 = (@_15 === nothing)::Bool\n│   %65 = Base.not_int(%64)::Bool\n└──       goto #5 if not %65\n4 ─       goto #3\n5 ┄ %68 = Base.dotview(Γ, j, Main.:(:), Main.:(:))::SubArray{Float64, 2, Array{Float64, 3}, Tuple{Int64, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}}, true}\n│   %69 = Main.:/::Core.Const(/)\n│   %70 = Base.getindex(Γ, j, Main.:(:), Main.:(:))::Matrix{Float64}\n│   %71 = Base.broadcasted(%69, %70, n)::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{2}, Nothing, typeof(/), Tuple{Matrix{Float64}, Int64}}\n│         Base.materialize!(%68, %71)\n│   %73 = Base.getindex(G, 1, Main.:(:), j)::Vector{Float64}\n│   %74 = Base.getindex(Γ, j, Main.:(:), Main.:(:))::Matrix{Float64}\n│   %75 = Main.inv(Ω)::Matrix{Float64}\n│   %76 = (%74 * %75 * gn)::Matrix{Float64}\n│   %77 = (%73 - %76)::Matrix{Float64}\n│         Base.setindex!(D, %77, Main.:(:), j)\n│         (@_3 = Base.iterate(%36, %43))\n│   %80 = (@_3 === nothing)::Bool\n│   %81 = Base.not_int(%80)::Bool\n└──       goto #7 if not %81\n6 ─       goto #2\n7 ┄ %84 = n::Int64\n│   %85 = k::Int64\n│   %86 = p::Int64\n│   %87 = gn::Adjoint{Float64, Matrix{Float64}}\n│   %88 = Ω::Matrix{Float64}\n│   %89 = D::Matrix{Float64}\n│   %90 = Core.getfield(#self#, :P)::Core.Const(var\"#P#23\"())\n│   %91 = Core.tuple(%84, %85, %86, %87, %88, %89, %90)::Tuple{Int64, Int64, Int64, Adjoint{Float64, Matrix{Float64}}, Matrix{Float64}, Matrix{Float64}, var\"#P#23\"}\n└──       return %91\n\n\n\n\n@benchmark statparts_stable(gi)(β0)\n\n\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):   96.255 μs …   3.907 ms  ┊ GC (min … max):  0.00% … 93.85%\n Time  (median):     113.599 μs               ┊ GC (median):     0.00%\n Time  (mean ± σ):   128.550 μs ± 219.933 μs  ┊ GC (mean ± σ):  10.38% ±  5.86%\n             ▃▄▆▆▇▇█▇▇▅▄▃▁                                       \n  ▁▁▁▂▃▄▅▅▆▇███████████████▇▆▅▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁ ▃\n  96.3 μs          Histogram: frequency by time          156 μs &lt;\n Memory estimate: 173.17 KiB, allocs estimate: 1466.\n\n\n\n\nusing Test\n@test klm(gi)(β0) ≈ klm_stable(gi)(β0)\n\n\nTest Passed\n\n\n\n\n\n\nSee https://schrimpf.github.io/ARGridBootstrap.jl/assignment.html#statparts for more information"
  },
  {
    "objectID": "westdri_talk.html#profiling",
    "href": "westdri_talk.html#profiling",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "Profiling",
    "text": "Profiling\n\n\nprofileiframe\nusing Profile, ProfileCanvas\nfunction profilehtmlstring()\n  buf = IOBuffer()\n  show(buf, MIME(\"text/html\"), ProfileCanvas.view(Profile.fetch()))\n  s=String(take!(buf))\n  println(\"\\n&lt;br&gt;&lt;br&gt;\\n\"*s*\"\\n&lt;br&gt;\\n\")\nend\nfunction profileiframe(filename=\"proftmp.html\")\n  #buf = IOBuffer()\n  #show(buf, MIME(\"text/html\"), ProfileCanvas.view(Profile.fetch()))\n  #s=String(take!(buf))\n  #s=replace(s, \"\\\"\" =&gt; \"&quot\" )\n  #  HTML(\"&lt;iframe srcdata=\\\"\"*s*\"\\\" width=\\\"1200\\\"  height=\\\"650\\\"&gt;&lt;/iframe&gt;\\n\")\n  ProfileCanvas.html_file(filename)\n  HTML(\"&lt;iframe src=\\\"\"*filename*\"\\\" width=\\\"1200\\\"  height=\\\"650\\\"&gt;&lt;/iframe&gt;\\n\")\nend\n\n\nProfile.clear();\nProfile.init(n=10^7,delay=0.00001);\n@profile sum(klm_stable(gi)(β0) for i in 1:100)\nprofileiframe(\"klmprof.html\") # only needed for quarto, just use @profview elsewhere"
  },
  {
    "objectID": "westdri_talk.html#reducing-allocations",
    "href": "westdri_talk.html#reducing-allocations",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "Reducing Allocations",
    "text": "Reducing Allocations\n\nAllocating memory is slow\nReduce allocations by:\n\nUsing @views instead of slices\nPre-allocating and reusing arrays\nEliminate dynamic allocations with StaticArrays or similar compile time known size types"
  },
  {
    "objectID": "westdri_talk.html#reduced-allocations",
    "href": "westdri_talk.html#reduced-allocations",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "Reduced Allocations",
    "text": "Reduced Allocations\n\n\nklm_fast()\nfunction statparts_fast(gi::F) where {F &lt;: Function}\n  function P(A::AbstractMatrix) # projection matrix\n    A*pinv(A'*A)*A'\n  end\n  let gi=gi\n    function(θ)\n      giθ = gi(θ)\n      p = length(θ)\n      (n, k) = size(giθ)\n      Ω = Hermitian(cov(giθ))\n      gn=mean(gi(θ), dims=1)'\n      iΩgn = Ω \\ gn\n      Gi = similar(gn,n,k,p)\n      ForwardDiff.jacobian!(Gi,gi,θ)\n      G = mean(Gi, dims=1)\n      Γ = zeros(eltype(Gi),p,k,k)\n      D = zeros(eltype(Gi),k, p)\n      @inbounds for j in 1:p\n        @inbounds for i in 1:n\n          @views Γ[j,:,:] .+= (Gi[i,:,j] .- G[1,:,j]) * giθ[i,:]'\n        end\n        Γ[j,:,:] ./= n\n        @views D[:,j] .= G[1,:,j] .- Γ[j,:,:]*iΩgn\n      end\n      return(n,k,p,gn, Ω, D, P)\n    end\n  end\nend\n\nfunction klm_fast(gi::F) where {F &lt;: Function}\n  SP = statparts_fast(gi)\n  function(θ)\n    (n,k,p,gn, Ω, D, P) = SP(θ)\n    λ, v = eigen(Ω)\n    irΩ = v*diagm(λ.^(-1/2))*v'\n    return n*(gn'*irΩ*P(irΩ*D)*irΩ*gn)[1]\n  end\nend\n\n\nklm_fast (generic function with 1 method)\n\n\n\n@benchmark klm_fast(gi)(β0)\n\n\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  69.396 μs …   4.616 ms  ┊ GC (min … max):  0.00% … 91.18%\n Time  (median):     76.164 μs               ┊ GC (median):     0.00%\n Time  (mean ± σ):   88.132 μs ± 220.386 μs  ┊ GC (mean ± σ):  11.94% ±  4.69%\n           ▂▄▅█▇▇█▇▅▄▃                                          \n  ▁▁▁▂▂▃▄▆██████████████▆▅▄▃▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁ ▃\n  69.4 μs         Histogram: frequency by time         95.7 μs &lt;\n Memory estimate: 118.53 KiB, allocs estimate: 501.\n\n\n\n\n@test klm_fast(gi)(β0) ≈ klm(gi)(β0)\n\n\nTest Passed"
  },
  {
    "objectID": "westdri_talk.html#staticarrays",
    "href": "westdri_talk.html#staticarrays",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "StaticArrays",
    "text": "StaticArrays\n\n\nextra functions\nstruct Integrator{Tx, Tw}\n    x::Tx\n    w::Tw\nend\n\nfunction Integrator(dx::Distribution, n=100)\n    x = [rand(dx) for _ in 1:n]\n    w = Base.Iterators.Repeated(1/n)\n    Integrator(x,w)\nend\n\n(∫::Integrator)(f) = sum((xw)-&gt;f(xw[1])*xw[2], zip(∫.x, ∫.w))\n\n\n\n\nCode\nfunction share(δ, Σ, x, ∫)\n  J,K = size(x)\n  (length(δ) == J) || error(\"length(δ)=$(length(δ)) != size(x,1)=$J\")\n  (K,K) == size(Σ) || error(\"size(x,2)=$K != size(Σ)=$(size(Σ))\")\n  xΣ = x*Σ\n  function shareν(ν)\n    s = δ + xΣ*ν\n    smax=max(0,maximum(s))\n    s = s .- smax\n    s = exp.(s)\n    s *= 1/(sum(s) + exp(0-smax))\n    return(s)\n  end\n  return(∫(shareν))\nend\n\n\nshare (generic function with 1 method)\n\n\n\n\nHeap allocated arrays\n\nJ = 10\nK = 5\nδ = rand(J)\nX = randn(J,K)\nΣ = I + zeros(K,K)\n∫ = Integrator(MvNormal(zeros(K),I))\n\n@benchmark share(δ,Σ,X,∫)\n\n\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  51.831 μs …   5.307 ms  ┊ GC (min … max):  0.00% … 97.61%\n Time  (median):     68.402 μs               ┊ GC (median):     0.00%\n Time  (mean ± σ):   86.401 μs ± 231.977 μs  ┊ GC (mean ± σ):  12.17% ±  4.47%\n                ▁▆█                                             \n  ▁▁▂▂▂▂▂▂▂▃▄▆▇█████▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▄▆█▇▃▂▂▂▂▁▁▁▁▁▁▁ ▂\n  51.8 μs         Histogram: frequency by time          113 μs &lt;\n Memory estimate: 98.78 KiB, allocs estimate: 700.\n\n\n\n\nStack allocated arrays\n\nusing StaticArrays\nsδ = SVector{J}(δ)\nsΣ = SMatrix{K,K}(Σ)\nsX = SMatrix{J,K}(X)\nnd = length(∫.x)\niw = SVector{nd}(fill(1/nd,nd))\nix = [SVector{K}(x) for x ∈ ∫.x]\ns∫ = Integrator(ix,iw)\n\n@benchmark share(sδ,sΣ,sX,s∫)\n\n\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  9.681 μs …  25.636 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     9.779 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   9.841 μs ± 563.245 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n    ▂█▇  ▁▄▇▃                                                  \n  ▃▆████▇████▇▅▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▂▂▃▃▃▂▂▂▃▃▃▂ ▃\n  9.68 μs         Histogram: frequency by time        10.4 μs &lt;\n Memory estimate: 96 bytes, allocs estimate: 1."
  },
  {
    "objectID": "westdri_talk.html#memory-considerations",
    "href": "westdri_talk.html#memory-considerations",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "Memory Considerations",
    "text": "Memory Considerations\n\n\nComputations are faster when operating accessing contiguous chunks of memory\n\nAccess arrays by columns\n\nData moves RAM ⇒ Cache ⇒ CPU Registers\n\nRAM ⇒ Cache much slower than Cache ⇒ CPU Registers\nCan see big benefits from small code that fits on cache\nCPU prefetches data from RAM ⇒ Cache, by predicting what will be needed\nNeeded data not on Cache when needed is a “cache miss”, these are costly\nPredictable code without branches and accessing contiguous memory helps avoid caches misses"
  },
  {
    "objectID": "westdri_talk.html#single-instruction-multiple-data",
    "href": "westdri_talk.html#single-instruction-multiple-data",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "Single Instruction, Multiple Data",
    "text": "Single Instruction, Multiple Data\n\nCPUs can perform the same operation on multiple numbers at the same time\n\n“Vectorized instructions”\nCurrent generation x86 CPUs have 512 bit registers, can operate on 8 Float64 values at once\n\nCompiler tries to use vectorized instructions when possible\n\nLoop of fixed length (no break or continue)\nNo branching\nRe-ordering allowed (indicate with @simd)"
  },
  {
    "objectID": "westdri_talk.html#sisd",
    "href": "westdri_talk.html#sisd",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "SISD",
    "text": "SISD\n\nfunction slowdot(a,b)\n  out = one(promote_type(eltype(a),eltype(b)))\n  for i in eachindex(a)\n    out += a[i]*b[i]\n  end\n  out\nend\n\nn = 1_000\na = rand(n)\nb = rand(n)\n@code_llvm slowdot(a,b)\n\n;  @ In[24]:1 within `slowdot`\ndefine double @julia_slowdot_4839({}* noundef nonnull align 16 dereferenceable(40) %0, {}* noundef nonnull align 16 dereferenceable(40) %1) #0 {\ntop:\n;  @ In[24]:3 within `slowdot`\n; ┌ @ abstractarray.jl:321 within `eachindex`\n; │┌ @ abstractarray.jl:137 within `axes1`\n; ││┌ @ abstractarray.jl:98 within `axes`\n; │││┌ @ array.jl:191 within `size`\n      %2 = bitcast {}* %0 to { i8*, i64, i16, i16, i32 }*\n      %arraylen_ptr = getelementptr inbounds { i8*, i64, i16, i16, i32 }, { i8*, i64, i16, i16, i32 }* %2, i64 0, i32 1\n      %arraylen = load i64, i64* %arraylen_ptr, align 8\n; └└└└\n; ┌ @ range.jl:897 within `iterate`\n; │┌ @ range.jl:672 within `isempty`\n; ││┌ @ operators.jl:378 within `&gt;`\n; │││┌ @ int.jl:83 within `&lt;`\n      %.not.not = icmp eq i64 %arraylen, 0\n; └└└└\n  br i1 %.not.not, label %L31, label %L13.preheader\n\nL13.preheader:                                    ; preds = %top\n  %3 = bitcast {}* %1 to { i8*, i64, i16, i16, i32 }*\n  %arraylen_ptr8 = getelementptr inbounds { i8*, i64, i16, i16, i32 }, { i8*, i64, i16, i16, i32 }* %3, i64 0, i32 1\n  %arraylen9 = load i64, i64* %arraylen_ptr8, align 8\n  %4 = bitcast {}* %0 to double**\n  %arrayptr23 = load double*, double** %4, align 8\n  %5 = bitcast {}* %1 to double**\n  %arrayptr1524 = load double*, double** %5, align 8\n;  @ In[24]:4 within `slowdot`\n; ┌ @ essentials.jl:13 within `getindex`\n   %smin = call i64 @llvm.smin.i64(i64 %arraylen9, i64 0)\n   %6 = sub i64 %arraylen9, %smin\n   %smax = call i64 @llvm.smax.i64(i64 %smin, i64 -1)\n   %7 = add nsw i64 %smax, 1\n   %8 = mul nuw nsw i64 %6, %7\n   %exit.mainloop.at = call i64 @llvm.umin.i64(i64 %arraylen, i64 %8)\n   %.not = icmp eq i64 %exit.mainloop.at, 0\n   br i1 %.not, label %main.pseudo.exit, label %idxend13.preheader\n\nidxend13.preheader:                               ; preds = %L13.preheader\n; └\n;  @ In[24]:5 within `slowdot`\n  %9 = add nsw i64 %exit.mainloop.at, -1\n  %xtraiter = and i64 %exit.mainloop.at, 7\n  %10 = icmp ult i64 %9, 7\n  br i1 %10, label %main.exit.selector.unr-lcssa, label %idxend13.preheader.new\n\nidxend13.preheader.new:                           ; preds = %idxend13.preheader\n  %unroll_iter = and i64 %exit.mainloop.at, 9223372036854775800\n  br label %idxend13\n\nL31:                                              ; preds = %idxend13.postloop, %main.exit.selector, %top\n  %value_phi20 = phi double [ 1.000000e+00, %top ], [ %.lcssa50, %main.exit.selector ], [ %63, %idxend13.postloop ]\n  ret double %value_phi20\n\noob:                                              ; preds = %L13.postloop\n;  @ In[24]:4 within `slowdot`\n; ┌ @ essentials.jl:13 within `getindex`\n   %errorbox = alloca i64, align 8\n   store i64 %value_phi3.postloop, i64* %errorbox, align 8\n   call void @ijl_bounds_error_ints({}* %0, i64* nonnull %errorbox, i64 1)\n   unreachable\n\noob11:                                            ; preds = %idxend.postloop\n   %errorbox12 = alloca i64, align 8\n   store i64 %value_phi3.postloop, i64* %errorbox12, align 8\n   call void @ijl_bounds_error_ints({}* %1, i64* nonnull %errorbox12, i64 1)\n   unreachable\n\nidxend13:                                         ; preds = %idxend13, %idxend13.preheader.new\n   %value_phi3 = phi i64 [ 1, %idxend13.preheader.new ], [ %50, %idxend13 ]\n   %value_phi5 = phi double [ 1.000000e+00, %idxend13.preheader.new ], [ %49, %idxend13 ]\n   %niter = phi i64 [ 0, %idxend13.preheader.new ], [ %niter.next.7, %idxend13 ]\n   %11 = add nsw i64 %value_phi3, -1\n   %12 = getelementptr inbounds double, double* %arrayptr23, i64 %11\n   %arrayref = load double, double* %12, align 8\n   %13 = getelementptr inbounds double, double* %arrayptr1524, i64 %11\n   %arrayref16 = load double, double* %13, align 8\n; └\n; ┌ @ float.jl:411 within `*`\n   %14 = fmul double %arrayref, %arrayref16\n; └\n; ┌ @ float.jl:409 within `+`\n   %15 = fadd double %value_phi5, %14\n; └\n;  @ In[24]:5 within `slowdot`\n; ┌ @ range.jl:901 within `iterate`\n   %16 = add nuw nsw i64 %value_phi3, 1\n; └\n;  @ In[24]:4 within `slowdot`\n; ┌ @ essentials.jl:13 within `getindex`\n   %17 = getelementptr inbounds double, double* %arrayptr23, i64 %value_phi3\n   %arrayref.1 = load double, double* %17, align 8\n   %18 = getelementptr inbounds double, double* %arrayptr1524, i64 %value_phi3\n   %arrayref16.1 = load double, double* %18, align 8\n; └\n; ┌ @ float.jl:411 within `*`\n   %19 = fmul double %arrayref.1, %arrayref16.1\n; └\n; ┌ @ float.jl:409 within `+`\n   %20 = fadd double %15, %19\n; └\n;  @ In[24]:5 within `slowdot`\n; ┌ @ range.jl:901 within `iterate`\n   %21 = add nuw nsw i64 %value_phi3, 2\n; └\n;  @ In[24]:4 within `slowdot`\n; ┌ @ essentials.jl:13 within `getindex`\n   %22 = getelementptr inbounds double, double* %arrayptr23, i64 %16\n   %arrayref.2 = load double, double* %22, align 8\n   %23 = getelementptr inbounds double, double* %arrayptr1524, i64 %16\n   %arrayref16.2 = load double, double* %23, align 8\n; └\n; ┌ @ float.jl:411 within `*`\n   %24 = fmul double %arrayref.2, %arrayref16.2\n; └\n; ┌ @ float.jl:409 within `+`\n   %25 = fadd double %20, %24\n; └\n;  @ In[24]:5 within `slowdot`\n; ┌ @ range.jl:901 within `iterate`\n   %26 = add nuw nsw i64 %value_phi3, 3\n; └\n;  @ In[24]:4 within `slowdot`\n; ┌ @ essentials.jl:13 within `getindex`\n   %27 = getelementptr inbounds double, double* %arrayptr23, i64 %21\n   %arrayref.3 = load double, double* %27, align 8\n   %28 = getelementptr inbounds double, double* %arrayptr1524, i64 %21\n   %arrayref16.3 = load double, double* %28, align 8\n; └\n; ┌ @ float.jl:411 within `*`\n   %29 = fmul double %arrayref.3, %arrayref16.3\n; └\n; ┌ @ float.jl:409 within `+`\n   %30 = fadd double %25, %29\n; └\n;  @ In[24]:5 within `slowdot`\n; ┌ @ range.jl:901 within `iterate`\n   %31 = add nuw nsw i64 %value_phi3, 4\n; └\n;  @ In[24]:4 within `slowdot`\n; ┌ @ essentials.jl:13 within `getindex`\n   %32 = getelementptr inbounds double, double* %arrayptr23, i64 %26\n   %arrayref.4 = load double, double* %32, align 8\n   %33 = getelementptr inbounds double, double* %arrayptr1524, i64 %26\n   %arrayref16.4 = load double, double* %33, align 8\n; └\n; ┌ @ float.jl:411 within `*`\n   %34 = fmul double %arrayref.4, %arrayref16.4\n; └\n; ┌ @ float.jl:409 within `+`\n   %35 = fadd double %30, %34\n; └\n;  @ In[24]:5 within `slowdot`\n; ┌ @ range.jl:901 within `iterate`\n   %36 = add nuw nsw i64 %value_phi3, 5\n; └\n;  @ In[24]:4 within `slowdot`\n; ┌ @ essentials.jl:13 within `getindex`\n   %37 = getelementptr inbounds double, double* %arrayptr23, i64 %31\n   %arrayref.5 = load double, double* %37, align 8\n   %38 = getelementptr inbounds double, double* %arrayptr1524, i64 %31\n   %arrayref16.5 = load double, double* %38, align 8\n; └\n; ┌ @ float.jl:411 within `*`\n   %39 = fmul double %arrayref.5, %arrayref16.5\n; └\n; ┌ @ float.jl:409 within `+`\n   %40 = fadd double %35, %39\n; └\n;  @ In[24]:5 within `slowdot`\n; ┌ @ range.jl:901 within `iterate`\n   %41 = add nuw nsw i64 %value_phi3, 6\n; └\n;  @ In[24]:4 within `slowdot`\n; ┌ @ essentials.jl:13 within `getindex`\n   %42 = getelementptr inbounds double, double* %arrayptr23, i64 %36\n   %arrayref.6 = load double, double* %42, align 8\n   %43 = getelementptr inbounds double, double* %arrayptr1524, i64 %36\n   %arrayref16.6 = load double, double* %43, align 8\n; └\n; ┌ @ float.jl:411 within `*`\n   %44 = fmul double %arrayref.6, %arrayref16.6\n; └\n; ┌ @ float.jl:409 within `+`\n   %45 = fadd double %40, %44\n; └\n; ┌ @ essentials.jl:13 within `getindex`\n   %46 = getelementptr inbounds double, double* %arrayptr23, i64 %41\n   %arrayref.7 = load double, double* %46, align 8\n   %47 = getelementptr inbounds double, double* %arrayptr1524, i64 %41\n   %arrayref16.7 = load double, double* %47, align 8\n; └\n; ┌ @ float.jl:411 within `*`\n   %48 = fmul double %arrayref.7, %arrayref16.7\n; └\n; ┌ @ float.jl:409 within `+`\n   %49 = fadd double %45, %48\n; └\n;  @ In[24]:5 within `slowdot`\n; ┌ @ range.jl:901 within `iterate`\n   %50 = add nuw nsw i64 %value_phi3, 8\n; └\n  %niter.next.7 = add nuw i64 %niter, 8\n  %niter.ncmp.7.not = icmp eq i64 %niter.next.7, %unroll_iter\n  br i1 %niter.ncmp.7.not, label %main.exit.selector.unr-lcssa.loopexit, label %idxend13\n\nmain.exit.selector.unr-lcssa.loopexit:            ; preds = %idxend13\n; ┌ @ range.jl:901 within `iterate`\n   %51 = add nuw nsw i64 %value_phi3, 7\n; └\n  br label %main.exit.selector.unr-lcssa\n\nmain.exit.selector.unr-lcssa:                     ; preds = %main.exit.selector.unr-lcssa.loopexit, %idxend13.preheader\n  %value_phi3.lcssa.ph = phi i64 [ undef, %idxend13.preheader ], [ %51, %main.exit.selector.unr-lcssa.loopexit ]\n  %.lcssa50.ph = phi double [ undef, %idxend13.preheader ], [ %49, %main.exit.selector.unr-lcssa.loopexit ]\n  %.lcssa49.ph = phi i64 [ undef, %idxend13.preheader ], [ %50, %main.exit.selector.unr-lcssa.loopexit ]\n  %value_phi3.unr = phi i64 [ 1, %idxend13.preheader ], [ %50, %main.exit.selector.unr-lcssa.loopexit ]\n  %value_phi5.unr = phi double [ 1.000000e+00, %idxend13.preheader ], [ %49, %main.exit.selector.unr-lcssa.loopexit ]\n  %lcmp.mod.not = icmp eq i64 %xtraiter, 0\n  br i1 %lcmp.mod.not, label %main.exit.selector, label %idxend13.epil\n\nidxend13.epil:                                    ; preds = %idxend13.epil, %main.exit.selector.unr-lcssa\n  %value_phi3.epil = phi i64 [ %57, %idxend13.epil ], [ %value_phi3.unr, %main.exit.selector.unr-lcssa ]\n  %value_phi5.epil = phi double [ %56, %idxend13.epil ], [ %value_phi5.unr, %main.exit.selector.unr-lcssa ]\n  %epil.iter = phi i64 [ %epil.iter.next, %idxend13.epil ], [ 0, %main.exit.selector.unr-lcssa ]\n;  @ In[24]:4 within `slowdot`\n; ┌ @ essentials.jl:13 within `getindex`\n   %52 = add nsw i64 %value_phi3.epil, -1\n   %53 = getelementptr inbounds double, double* %arrayptr23, i64 %52\n   %arrayref.epil = load double, double* %53, align 8\n   %54 = getelementptr inbounds double, double* %arrayptr1524, i64 %52\n   %arrayref16.epil = load double, double* %54, align 8\n; └\n; ┌ @ float.jl:411 within `*`\n   %55 = fmul double %arrayref.epil, %arrayref16.epil\n; └\n; ┌ @ float.jl:409 within `+`\n   %56 = fadd double %value_phi5.epil, %55\n; └\n;  @ In[24]:5 within `slowdot`\n; ┌ @ range.jl:901 within `iterate`\n   %57 = add nuw nsw i64 %value_phi3.epil, 1\n; └\n  %epil.iter.next = add i64 %epil.iter, 1\n  %epil.iter.cmp.not = icmp eq i64 %epil.iter.next, %xtraiter\n  br i1 %epil.iter.cmp.not, label %main.exit.selector, label %idxend13.epil\n\nmain.exit.selector:                               ; preds = %idxend13.epil, %main.exit.selector.unr-lcssa\n  %value_phi3.lcssa = phi i64 [ %value_phi3.lcssa.ph, %main.exit.selector.unr-lcssa ], [ %value_phi3.epil, %idxend13.epil ]\n;  @ In[24]:4 within `slowdot`\n; ┌ @ float.jl:409 within `+`\n   %.lcssa50 = phi double [ %.lcssa50.ph, %main.exit.selector.unr-lcssa ], [ %56, %idxend13.epil ]\n; └\n;  @ In[24]:5 within `slowdot`\n; ┌ @ range.jl:901 within `iterate`\n   %.lcssa49 = phi i64 [ %.lcssa49.ph, %main.exit.selector.unr-lcssa ], [ %57, %idxend13.epil ]\n; └\n  %58 = icmp ult i64 %value_phi3.lcssa, %arraylen\n  br i1 %58, label %main.pseudo.exit, label %L31\n\nmain.pseudo.exit:                                 ; preds = %main.exit.selector, %L13.preheader\n  %value_phi3.copy = phi i64 [ 1, %L13.preheader ], [ %.lcssa49, %main.exit.selector ]\n  %value_phi5.copy = phi double [ 1.000000e+00, %L13.preheader ], [ %.lcssa50, %main.exit.selector ]\n  br label %L13.postloop\n\nL13.postloop:                                     ; preds = %idxend13.postloop, %main.pseudo.exit\n  %value_phi3.postloop = phi i64 [ %64, %idxend13.postloop ], [ %value_phi3.copy, %main.pseudo.exit ]\n  %value_phi5.postloop = phi double [ %63, %idxend13.postloop ], [ %value_phi5.copy, %main.pseudo.exit ]\n;  @ In[24]:4 within `slowdot`\n; ┌ @ essentials.jl:13 within `getindex`\n   %59 = add i64 %value_phi3.postloop, -1\n   %inbounds.postloop = icmp ult i64 %59, %arraylen\n   br i1 %inbounds.postloop, label %idxend.postloop, label %oob\n\nidxend.postloop:                                  ; preds = %L13.postloop\n   %inbounds10.postloop = icmp ult i64 %59, %arraylen9\n   br i1 %inbounds10.postloop, label %idxend13.postloop, label %oob11\n\nidxend13.postloop:                                ; preds = %idxend.postloop\n   %60 = getelementptr inbounds double, double* %arrayptr23, i64 %59\n   %arrayref.postloop = load double, double* %60, align 8\n   %61 = getelementptr inbounds double, double* %arrayptr1524, i64 %59\n   %arrayref16.postloop = load double, double* %61, align 8\n; └\n; ┌ @ float.jl:411 within `*`\n   %62 = fmul double %arrayref.postloop, %arrayref16.postloop\n; └\n; ┌ @ float.jl:409 within `+`\n   %63 = fadd double %value_phi5.postloop, %62\n; └\n;  @ In[24]:5 within `slowdot`\n; ┌ @ range.jl:901 within `iterate`\n; │┌ @ promotion.jl:521 within `==`\n    %.not.not25.postloop = icmp eq i64 %value_phi3.postloop, %arraylen\n; │└\n   %64 = add nuw nsw i64 %value_phi3.postloop, 1\n; └\n  br i1 %.not.not25.postloop, label %L31, label %L13.postloop\n}"
  },
  {
    "objectID": "westdri_talk.html#simd",
    "href": "westdri_talk.html#simd",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "SIMD",
    "text": "SIMD\n\nfunction fastdot(a,b)\n  out = one(promote_type(eltype(a),eltype(b)))\n  @simd for i in eachindex(a)\n    out += a[i]*b[i]\n  end\n  out\nend\n\n@code_llvm fastdot(a,b)\n\n;  @ In[25]:1 within `fastdot`\ndefine double @julia_fastdot_4863({}* noundef nonnull align 16 dereferenceable(40) %0, {}* noundef nonnull align 16 dereferenceable(40) %1) #0 {\ntop:\n;  @ In[25]:3 within `fastdot`\n; ┌ @ simdloop.jl:69 within `macro expansion`\n; │┌ @ abstractarray.jl:321 within `eachindex`\n; ││┌ @ abstractarray.jl:137 within `axes1`\n; │││┌ @ abstractarray.jl:98 within `axes`\n; ││││┌ @ array.jl:191 within `size`\n       %2 = bitcast {}* %0 to { i8*, i64, i16, i16, i32 }*\n       %arraylen_ptr = getelementptr inbounds { i8*, i64, i16, i16, i32 }, { i8*, i64, i16, i16, i32 }* %2, i64 0, i32 1\n       %arraylen = load i64, i64* %arraylen_ptr, align 8\n; │└└└└\n; │ @ simdloop.jl:72 within `macro expansion`\n; │┌ @ int.jl:83 within `&lt;`\n    %.not = icmp eq i64 %arraylen, 0\n; │└\n   br i1 %.not, label %L32, label %L13.lr.ph\n\nL13.lr.ph:                                        ; preds = %top\n   %3 = bitcast {}* %1 to { i8*, i64, i16, i16, i32 }*\n   %arraylen_ptr4 = getelementptr inbounds { i8*, i64, i16, i16, i32 }, { i8*, i64, i16, i16, i32 }* %3, i64 0, i32 1\n   %arraylen5 = load i64, i64* %arraylen_ptr4, align 8\n   %4 = bitcast {}* %0 to double**\n   %arrayptr17 = load double*, double** %4, align 8\n   %5 = bitcast {}* %1 to double**\n   %arrayptr1118 = load double*, double** %5, align 8\n; │ @ simdloop.jl:75 within `macro expansion`\n   %6 = add i64 %arraylen5, -9223372036854775807\n   %smax = call i64 @llvm.smax.i64(i64 %6, i64 0)\n   %7 = sub i64 %arraylen5, %smax\n   %arraylen5.lobit = ashr i64 %arraylen5, 63\n   %8 = add nsw i64 %arraylen5.lobit, 1\n   %9 = mul nuw nsw i64 %7, %8\n   %smin27 = call i64 @llvm.smin.i64(i64 %arraylen, i64 %9)\n   %exit.mainloop.at = call i64 @llvm.smax.i64(i64 %smin27, i64 0)\n   %.not39 = icmp slt i64 %smin27, 1\n   br i1 %.not39, label %main.pseudo.exit, label %idxend9.preheader\n\nidxend9.preheader:                                ; preds = %L13.lr.ph\n   %min.iters.check = icmp ult i64 %exit.mainloop.at, 16\n   br i1 %min.iters.check, label %scalar.ph, label %vector.ph\n\nvector.ph:                                        ; preds = %idxend9.preheader\n   %n.vec = and i64 %exit.mainloop.at, 9223372036854775792\n   %10 = add nsw i64 %n.vec, -16\n   %11 = lshr exact i64 %10, 4\n   %12 = add nuw nsw i64 %11, 1\n   %xtraiter = and i64 %12, 1\n   %13 = icmp eq i64 %10, 0\n   br i1 %13, label %middle.block.unr-lcssa, label %vector.ph.new\n\nvector.ph.new:                                    ; preds = %vector.ph\n   %unroll_iter = and i64 %12, 2305843009213693950\n   br label %vector.body\n\nvector.body:                                      ; preds = %vector.body, %vector.ph.new\n; │ @ simdloop.jl:76 within `macro expansion`\n; │┌ @ simdloop.jl:54 within `simd_index`\n; ││┌ @ int.jl:87 within `+`\n     %index = phi i64 [ 0, %vector.ph.new ], [ %index.next.1, %vector.body ]\n     %vec.phi = phi &lt;4 x double&gt; [ &lt;double 1.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00&gt;, %vector.ph.new ], [ %58, %vector.body ]\n     %vec.phi44 = phi &lt;4 x double&gt; [ &lt;double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00&gt;, %vector.ph.new ], [ %59, %vector.body ]\n     %vec.phi45 = phi &lt;4 x double&gt; [ &lt;double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00&gt;, %vector.ph.new ], [ %60, %vector.body ]\n     %vec.phi46 = phi &lt;4 x double&gt; [ &lt;double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00&gt;, %vector.ph.new ], [ %61, %vector.body ]\n     %niter = phi i64 [ 0, %vector.ph.new ], [ %niter.next.1, %vector.body ]\n; │└└\n; │ @ simdloop.jl:77 within `macro expansion` @ In[25]:4\n; │┌ @ essentials.jl:13 within `getindex`\n    %14 = getelementptr inbounds double, double* %arrayptr17, i64 %index\n    %15 = bitcast double* %14 to &lt;4 x double&gt;*\n    %wide.load = load &lt;4 x double&gt;, &lt;4 x double&gt;* %15, align 8\n    %16 = getelementptr inbounds double, double* %14, i64 4\n    %17 = bitcast double* %16 to &lt;4 x double&gt;*\n    %wide.load47 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %17, align 8\n    %18 = getelementptr inbounds double, double* %14, i64 8\n    %19 = bitcast double* %18 to &lt;4 x double&gt;*\n    %wide.load48 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %19, align 8\n    %20 = getelementptr inbounds double, double* %14, i64 12\n    %21 = bitcast double* %20 to &lt;4 x double&gt;*\n    %wide.load49 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %21, align 8\n    %22 = getelementptr inbounds double, double* %arrayptr1118, i64 %index\n    %23 = bitcast double* %22 to &lt;4 x double&gt;*\n    %wide.load50 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %23, align 8\n    %24 = getelementptr inbounds double, double* %22, i64 4\n    %25 = bitcast double* %24 to &lt;4 x double&gt;*\n    %wide.load51 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %25, align 8\n    %26 = getelementptr inbounds double, double* %22, i64 8\n    %27 = bitcast double* %26 to &lt;4 x double&gt;*\n    %wide.load52 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %27, align 8\n    %28 = getelementptr inbounds double, double* %22, i64 12\n    %29 = bitcast double* %28 to &lt;4 x double&gt;*\n    %wide.load53 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %29, align 8\n; │└\n; │┌ @ float.jl:411 within `*`\n    %30 = fmul contract &lt;4 x double&gt; %wide.load, %wide.load50\n    %31 = fmul contract &lt;4 x double&gt; %wide.load47, %wide.load51\n    %32 = fmul contract &lt;4 x double&gt; %wide.load48, %wide.load52\n    %33 = fmul contract &lt;4 x double&gt; %wide.load49, %wide.load53\n; │└\n; │┌ @ float.jl:409 within `+`\n    %34 = fadd reassoc contract &lt;4 x double&gt; %vec.phi, %30\n    %35 = fadd reassoc contract &lt;4 x double&gt; %vec.phi44, %31\n    %36 = fadd reassoc contract &lt;4 x double&gt; %vec.phi45, %32\n    %37 = fadd reassoc contract &lt;4 x double&gt; %vec.phi46, %33\n; │└\n; │ @ simdloop.jl:76 within `macro expansion`\n; │┌ @ simdloop.jl:54 within `simd_index`\n; ││┌ @ int.jl:87 within `+`\n     %index.next = or i64 %index, 16\n; │└└\n; │ @ simdloop.jl:77 within `macro expansion` @ In[25]:4\n; │┌ @ essentials.jl:13 within `getindex`\n    %38 = getelementptr inbounds double, double* %arrayptr17, i64 %index.next\n    %39 = bitcast double* %38 to &lt;4 x double&gt;*\n    %wide.load.1 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %39, align 8\n    %40 = getelementptr inbounds double, double* %38, i64 4\n    %41 = bitcast double* %40 to &lt;4 x double&gt;*\n    %wide.load47.1 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %41, align 8\n    %42 = getelementptr inbounds double, double* %38, i64 8\n    %43 = bitcast double* %42 to &lt;4 x double&gt;*\n    %wide.load48.1 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %43, align 8\n    %44 = getelementptr inbounds double, double* %38, i64 12\n    %45 = bitcast double* %44 to &lt;4 x double&gt;*\n    %wide.load49.1 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %45, align 8\n    %46 = getelementptr inbounds double, double* %arrayptr1118, i64 %index.next\n    %47 = bitcast double* %46 to &lt;4 x double&gt;*\n    %wide.load50.1 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %47, align 8\n    %48 = getelementptr inbounds double, double* %46, i64 4\n    %49 = bitcast double* %48 to &lt;4 x double&gt;*\n    %wide.load51.1 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %49, align 8\n    %50 = getelementptr inbounds double, double* %46, i64 8\n    %51 = bitcast double* %50 to &lt;4 x double&gt;*\n    %wide.load52.1 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %51, align 8\n    %52 = getelementptr inbounds double, double* %46, i64 12\n    %53 = bitcast double* %52 to &lt;4 x double&gt;*\n    %wide.load53.1 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %53, align 8\n; │└\n; │┌ @ float.jl:411 within `*`\n    %54 = fmul contract &lt;4 x double&gt; %wide.load.1, %wide.load50.1\n    %55 = fmul contract &lt;4 x double&gt; %wide.load47.1, %wide.load51.1\n    %56 = fmul contract &lt;4 x double&gt; %wide.load48.1, %wide.load52.1\n    %57 = fmul contract &lt;4 x double&gt; %wide.load49.1, %wide.load53.1\n; │└\n; │┌ @ float.jl:409 within `+`\n    %58 = fadd reassoc contract &lt;4 x double&gt; %34, %54\n    %59 = fadd reassoc contract &lt;4 x double&gt; %35, %55\n    %60 = fadd reassoc contract &lt;4 x double&gt; %36, %56\n    %61 = fadd reassoc contract &lt;4 x double&gt; %37, %57\n; │└\n; │ @ simdloop.jl:76 within `macro expansion`\n; │┌ @ simdloop.jl:54 within `simd_index`\n; ││┌ @ int.jl:87 within `+`\n     %index.next.1 = add nuw i64 %index, 32\n     %niter.next.1 = add i64 %niter, 2\n     %niter.ncmp.1 = icmp eq i64 %niter.next.1, %unroll_iter\n     br i1 %niter.ncmp.1, label %middle.block.unr-lcssa, label %vector.body\n\nmiddle.block.unr-lcssa:                           ; preds = %vector.body, %vector.ph\n     %.lcssa63.ph = phi &lt;4 x double&gt; [ undef, %vector.ph ], [ %58, %vector.body ]\n     %.lcssa62.ph = phi &lt;4 x double&gt; [ undef, %vector.ph ], [ %59, %vector.body ]\n     %.lcssa61.ph = phi &lt;4 x double&gt; [ undef, %vector.ph ], [ %60, %vector.body ]\n     %.lcssa60.ph = phi &lt;4 x double&gt; [ undef, %vector.ph ], [ %61, %vector.body ]\n     %index.unr = phi i64 [ 0, %vector.ph ], [ %index.next.1, %vector.body ]\n     %vec.phi.unr = phi &lt;4 x double&gt; [ &lt;double 1.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00&gt;, %vector.ph ], [ %58, %vector.body ]\n     %vec.phi44.unr = phi &lt;4 x double&gt; [ &lt;double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00&gt;, %vector.ph ], [ %59, %vector.body ]\n     %vec.phi45.unr = phi &lt;4 x double&gt; [ &lt;double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00&gt;, %vector.ph ], [ %60, %vector.body ]\n     %vec.phi46.unr = phi &lt;4 x double&gt; [ &lt;double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00&gt;, %vector.ph ], [ %61, %vector.body ]\n     %lcmp.mod.not = icmp eq i64 %xtraiter, 0\n     br i1 %lcmp.mod.not, label %middle.block, label %vector.body.epil.preheader\n\nvector.body.epil.preheader:                       ; preds = %middle.block.unr-lcssa\n; │└└\n; │ @ simdloop.jl:77 within `macro expansion` @ In[25]:4\n; │┌ @ essentials.jl:13 within `getindex`\n    %62 = getelementptr inbounds double, double* %arrayptr17, i64 %index.unr\n    %63 = bitcast double* %62 to &lt;4 x double&gt;*\n    %wide.load.epil = load &lt;4 x double&gt;, &lt;4 x double&gt;* %63, align 8\n    %64 = getelementptr inbounds double, double* %62, i64 4\n    %65 = bitcast double* %64 to &lt;4 x double&gt;*\n    %wide.load47.epil = load &lt;4 x double&gt;, &lt;4 x double&gt;* %65, align 8\n    %66 = getelementptr inbounds double, double* %62, i64 8\n    %67 = bitcast double* %66 to &lt;4 x double&gt;*\n    %wide.load48.epil = load &lt;4 x double&gt;, &lt;4 x double&gt;* %67, align 8\n    %68 = getelementptr inbounds double, double* %62, i64 12\n    %69 = bitcast double* %68 to &lt;4 x double&gt;*\n    %wide.load49.epil = load &lt;4 x double&gt;, &lt;4 x double&gt;* %69, align 8\n    %70 = getelementptr inbounds double, double* %arrayptr1118, i64 %index.unr\n    %71 = bitcast double* %70 to &lt;4 x double&gt;*\n    %wide.load50.epil = load &lt;4 x double&gt;, &lt;4 x double&gt;* %71, align 8\n    %72 = getelementptr inbounds double, double* %70, i64 4\n    %73 = bitcast double* %72 to &lt;4 x double&gt;*\n    %wide.load51.epil = load &lt;4 x double&gt;, &lt;4 x double&gt;* %73, align 8\n    %74 = getelementptr inbounds double, double* %70, i64 8\n    %75 = bitcast double* %74 to &lt;4 x double&gt;*\n    %wide.load52.epil = load &lt;4 x double&gt;, &lt;4 x double&gt;* %75, align 8\n    %76 = getelementptr inbounds double, double* %70, i64 12\n    %77 = bitcast double* %76 to &lt;4 x double&gt;*\n    %wide.load53.epil = load &lt;4 x double&gt;, &lt;4 x double&gt;* %77, align 8\n; │└\n; │┌ @ float.jl:411 within `*`\n    %78 = fmul contract &lt;4 x double&gt; %wide.load.epil, %wide.load50.epil\n    %79 = fmul contract &lt;4 x double&gt; %wide.load47.epil, %wide.load51.epil\n    %80 = fmul contract &lt;4 x double&gt; %wide.load48.epil, %wide.load52.epil\n    %81 = fmul contract &lt;4 x double&gt; %wide.load49.epil, %wide.load53.epil\n; │└\n; │┌ @ float.jl:409 within `+`\n    %82 = fadd reassoc contract &lt;4 x double&gt; %vec.phi.unr, %78\n    %83 = fadd reassoc contract &lt;4 x double&gt; %vec.phi44.unr, %79\n    %84 = fadd reassoc contract &lt;4 x double&gt; %vec.phi45.unr, %80\n    %85 = fadd reassoc contract &lt;4 x double&gt; %vec.phi46.unr, %81\n; │└\n; │ @ simdloop.jl:75 within `macro expansion`\n   br label %middle.block\n\nmiddle.block:                                     ; preds = %vector.body.epil.preheader, %middle.block.unr-lcssa\n; │ @ simdloop.jl:77 within `macro expansion` @ In[25]:4\n; │┌ @ float.jl:409 within `+`\n    %.lcssa63 = phi &lt;4 x double&gt; [ %.lcssa63.ph, %middle.block.unr-lcssa ], [ %82, %vector.body.epil.preheader ]\n    %.lcssa62 = phi &lt;4 x double&gt; [ %.lcssa62.ph, %middle.block.unr-lcssa ], [ %83, %vector.body.epil.preheader ]\n    %.lcssa61 = phi &lt;4 x double&gt; [ %.lcssa61.ph, %middle.block.unr-lcssa ], [ %84, %vector.body.epil.preheader ]\n    %.lcssa60 = phi &lt;4 x double&gt; [ %.lcssa60.ph, %middle.block.unr-lcssa ], [ %85, %vector.body.epil.preheader ]\n; │└\n; │ @ simdloop.jl:75 within `macro expansion`\n   %bin.rdx = fadd reassoc contract &lt;4 x double&gt; %.lcssa62, %.lcssa63\n   %bin.rdx54 = fadd reassoc contract &lt;4 x double&gt; %.lcssa61, %bin.rdx\n   %bin.rdx55 = fadd reassoc contract &lt;4 x double&gt; %.lcssa60, %bin.rdx54\n   %86 = call reassoc contract double @llvm.vector.reduce.fadd.v4f64(double -0.000000e+00, &lt;4 x double&gt; %bin.rdx55)\n   %cmp.n = icmp eq i64 %exit.mainloop.at, %n.vec\n   br i1 %cmp.n, label %main.exit.selector, label %scalar.ph\n\nscalar.ph:                                        ; preds = %middle.block, %idxend9.preheader\n   %bc.resume.val = phi i64 [ %n.vec, %middle.block ], [ 0, %idxend9.preheader ]\n   %bc.merge.rdx = phi double [ %86, %middle.block ], [ 1.000000e+00, %idxend9.preheader ]\n   br label %idxend9\n\nL32:                                              ; preds = %idxend9.postloop, %main.exit.selector, %top\n   %value_phi13 = phi double [ 1.000000e+00, %top ], [ %.lcssa43, %main.exit.selector ], [ %97, %idxend9.postloop ]\n; │ @ simdloop.jl:86 within `macro expansion`\n   ret double %value_phi13\n\noob:                                              ; preds = %L13.postloop\n; │ @ simdloop.jl:77 within `macro expansion` @ In[25]:4\n; │┌ @ essentials.jl:13 within `getindex`\n    %errorbox = alloca i64, align 8\n    store i64 %93, i64* %errorbox, align 8\n    call void @ijl_bounds_error_ints({}* %0, i64* nonnull %errorbox, i64 1)\n    unreachable\n\noob7:                                             ; preds = %idxend.postloop\n    %errorbox8 = alloca i64, align 8\n    store i64 %93, i64* %errorbox8, align 8\n    call void @ijl_bounds_error_ints({}* %1, i64* nonnull %errorbox8, i64 1)\n    unreachable\n\nidxend9:                                          ; preds = %idxend9, %scalar.ph\n    %value_phi124 = phi i64 [ %87, %idxend9 ], [ %bc.resume.val, %scalar.ph ]\n    %value_phi23 = phi double [ %91, %idxend9 ], [ %bc.merge.rdx, %scalar.ph ]\n; │└\n; │ @ simdloop.jl:76 within `macro expansion`\n; │┌ @ simdloop.jl:54 within `simd_index`\n; ││┌ @ int.jl:87 within `+`\n     %87 = add nuw nsw i64 %value_phi124, 1\n; │└└\n; │ @ simdloop.jl:77 within `macro expansion` @ In[25]:4\n; │┌ @ essentials.jl:13 within `getindex`\n    %88 = getelementptr inbounds double, double* %arrayptr17, i64 %value_phi124\n    %arrayref = load double, double* %88, align 8\n    %89 = getelementptr inbounds double, double* %arrayptr1118, i64 %value_phi124\n    %arrayref12 = load double, double* %89, align 8\n; │└\n; │┌ @ float.jl:411 within `*`\n    %90 = fmul contract double %arrayref, %arrayref12\n; │└\n; │┌ @ float.jl:409 within `+`\n    %91 = fadd reassoc contract double %value_phi23, %90\n; │└\n; │ @ simdloop.jl:75 within `macro expansion`\n   %exitcond.not = icmp eq i64 %87, %exit.mainloop.at\n   br i1 %exitcond.not, label %main.exit.selector, label %idxend9\n\nmain.exit.selector:                               ; preds = %idxend9, %middle.block\n; │ @ simdloop.jl:77 within `macro expansion` @ In[25]:4\n; │┌ @ float.jl:409 within `+`\n    %.lcssa43 = phi double [ %86, %middle.block ], [ %91, %idxend9 ]\n; │└\n; │ @ simdloop.jl:75 within `macro expansion`\n   %92 = icmp ult i64 %exit.mainloop.at, %arraylen\n   br i1 %92, label %main.pseudo.exit, label %L32\n\nmain.pseudo.exit:                                 ; preds = %main.exit.selector, %L13.lr.ph\n   %value_phi23.copy = phi double [ 1.000000e+00, %L13.lr.ph ], [ %.lcssa43, %main.exit.selector ]\n   br label %L13.postloop\n\nL13.postloop:                                     ; preds = %idxend9.postloop, %main.pseudo.exit\n   %value_phi124.postloop = phi i64 [ %exit.mainloop.at, %main.pseudo.exit ], [ %93, %idxend9.postloop ]\n   %value_phi23.postloop = phi double [ %value_phi23.copy, %main.pseudo.exit ], [ %97, %idxend9.postloop ]\n; │ @ simdloop.jl:76 within `macro expansion`\n; │┌ @ simdloop.jl:54 within `simd_index`\n; ││┌ @ int.jl:87 within `+`\n     %93 = add nuw nsw i64 %value_phi124.postloop, 1\n; │└└\n; │ @ simdloop.jl:77 within `macro expansion` @ In[25]:4\n; │┌ @ essentials.jl:13 within `getindex`\n    %inbounds.postloop = icmp ult i64 %value_phi124.postloop, %arraylen\n    br i1 %inbounds.postloop, label %idxend.postloop, label %oob\n\nidxend.postloop:                                  ; preds = %L13.postloop\n    %inbounds6.postloop = icmp ult i64 %value_phi124.postloop, %arraylen5\n    br i1 %inbounds6.postloop, label %idxend9.postloop, label %oob7\n\nidxend9.postloop:                                 ; preds = %idxend.postloop\n    %94 = getelementptr inbounds double, double* %arrayptr17, i64 %value_phi124.postloop\n    %arrayref.postloop = load double, double* %94, align 8\n    %95 = getelementptr inbounds double, double* %arrayptr1118, i64 %value_phi124.postloop\n    %arrayref12.postloop = load double, double* %95, align 8\n; │└\n; │┌ @ float.jl:411 within `*`\n    %96 = fmul contract double %arrayref.postloop, %arrayref12.postloop\n; │└\n; │┌ @ float.jl:409 within `+`\n    %97 = fadd reassoc contract double %value_phi23.postloop, %96\n; │└\n; │ @ simdloop.jl:75 within `macro expansion`\n; │┌ @ int.jl:83 within `&lt;`\n    %.not16.postloop = icmp ult i64 %93, %arraylen\n; │└\n   br i1 %.not16.postloop, label %L13.postloop, label %L32\n; └\n}"
  },
  {
    "objectID": "westdri_talk.html#multiple-faster-than-single",
    "href": "westdri_talk.html#multiple-faster-than-single",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "Multiple faster than Single",
    "text": "Multiple faster than Single\n\n\n\n@benchmark slowdot($a,$b)\n\n\nBenchmarkTools.Trial: 10000 samples with 53 evaluations.\n Range (min … max):  878.736 ns …  2.349 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     879.792 ns              ┊ GC (median):    0.00%\n Time  (mean ± σ):   887.537 ns ± 48.328 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n  █         ▂                                                  ▁\n  █▁▁▁▁▁▁▃█▅█▄▄▄▄▅█▅▄▃▃▃▄▅▁▁▁▁▁▃▁▁▁▃▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▃▄▅▆▅▆▅ █\n  879 ns        Histogram: log(frequency) by time      1.19 μs &lt;\n Memory estimate: 0 bytes, allocs estimate: 0.\n\n\n\n\n\n@benchmark fastdot($a,$b)\n\n\nBenchmarkTools.Trial: 10000 samples with 929 evaluations.\n Range (min … max):  110.352 ns … 198.192 ns  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     110.478 ns               ┊ GC (median):    0.00%\n Time  (mean ± σ):   111.761 ns ±   4.059 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n  █                    ▄                                        ▁\n  █▇▁▁▁▁▁▁█▇▃▆▆▅▇█▇▆▅▄▅█▄▄▁▁▃▃▃▁▁▁██▄▄▅▆▅▆▆▅▅▆▆▆▅▄▅▄▆▅▆▆▆▆▅▄▃▅▅ █\n  110 ns        Histogram: log(frequency) by time        130 ns &lt;\n Memory estimate: 0 bytes, allocs estimate: 0."
  },
  {
    "objectID": "westdri_talk.html#beyond-simd",
    "href": "westdri_talk.html#beyond-simd",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "Beyond @simd",
    "text": "Beyond @simd\n\n@simd is somewhat conservative in its vectorization\nThe LoopVectorization provides a more aggresive auto-vectorization macro, @turbo\n\nUnless new maintainer steps forward, will not work with Julia 1.11 and newer\nDoes not work for all loops\n\nCan manually write SIMD code\n\nUsing SIMD.jl\nUsing llvmcall (not recommended)"
  },
  {
    "objectID": "westdri_talk.html#simd.jl-example",
    "href": "westdri_talk.html#simd.jl-example",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "SIMD.jl Example",
    "text": "SIMD.jl Example\n\nBased on https://schrimpf.github.io/ARGridBootstrap.jl/argridboot.html#simd\n\n\n\nCode\nusing LoopVectorization, SIMD\n\nT = 1000\ne = zeros(T)\ny = randn(T)\nθ = ones(3);\n\n\n\n\n\n\nCode\nfunction resids!(e, yin, θ)\n  T = length(yin)\n  @inbounds @simd for t in 2:T\n    e[t-1] = yin[t] - θ[1] - θ[2]*t - θ[3]*yin[t-1]\n  end\n  nothing\nend\n\n@code_llvm resids!(e,y, θ)\n\n\n;  @ In[29]:1 within `resids!`\ndefine nonnull {}* @\"japi1_resids!_4964\"({}* %function, {}** noalias nocapture noundef readonly %args, i32 %nargs) #0 {\ntop:\n  %stackargs = alloca {}**, align 8\n  store volatile {}** %args, {}*** %stackargs, align 8\n  %0 = getelementptr inbounds {}*, {}** %args, i64 1\n  %1 = load {}*, {}** %0, align 8\n;  @ In[29]:2 within `resids!`\n; ┌ @ essentials.jl:10 within `length`\n   %2 = bitcast {}* %1 to { i8*, i64, i16, i16, i32 }*\n   %arraylen_ptr = getelementptr inbounds { i8*, i64, i16, i16, i32 }, { i8*, i64, i16, i16, i32 }* %2, i64 0, i32 1\n   %arraylen = load i64, i64* %arraylen_ptr, align 8\n; └\n;  @ In[29]:3 within `resids!`\n; ┌ @ simdloop.jl within `macro expansion`\n   %3 = call i64 @llvm.umax.i64(i64 %arraylen, i64 1)\n; │ @ simdloop.jl:71 within `macro expansion`\n; │┌ @ simdloop.jl:51 within `simd_inner_length`\n; ││┌ @ range.jl:761 within `length`\n; │││┌ @ int.jl:87 within `+`\n      %4 = add nsw i64 %3, -1\n; │└└└\n; │ @ simdloop.jl:72 within `macro expansion`\n; │┌ @ int.jl:83 within `&lt;`\n    %5 = icmp ult i64 %arraylen, 2\n    %.not23.not = icmp eq i64 %4, 0\n; │└\n   %or.cond = select i1 %5, i1 true, i1 %.not23.not\n   br i1 %or.cond, label %L56, label %L19.lr.ph\n\nL19.lr.ph:                                        ; preds = %top\n   %6 = getelementptr inbounds {}*, {}** %args, i64 2\n   %7 = bitcast {}** %6 to double***\n   %8 = load double**, double*** %7, align 8\n   %9 = bitcast {}** %args to double***\n   %10 = load double**, double*** %9, align 8\n   %11 = bitcast {}* %1 to double**\n   %arrayptr17 = load double*, double** %11, align 8\n   %arrayptr418 = load double*, double** %8, align 8\n   %12 = getelementptr inbounds double, double* %arrayptr418, i64 1\n   %13 = getelementptr inbounds double, double* %arrayptr418, i64 2\n   %arrayptr1622 = load double*, double** %10, align 8\n; │ @ simdloop.jl:75 within `macro expansion`\n   %min.iters.check = icmp ult i64 %4, 8\n   br i1 %min.iters.check, label %scalar.ph, label %vector.memcheck\n\nvector.memcheck:                                  ; preds = %L19.lr.ph\n   %scevgep = getelementptr double, double* %arrayptr1622, i64 %4\n   %scevgep28 = getelementptr double, double* %arrayptr17, i64 %3\n   %scevgep31 = getelementptr double, double* %arrayptr418, i64 3\n   %bound0 = icmp ult double* %arrayptr1622, %scevgep28\n   %bound1 = icmp ult double* %arrayptr17, %scevgep\n   %found.conflict = and i1 %bound0, %bound1\n   %bound033 = icmp ult double* %arrayptr1622, %scevgep31\n   %bound134 = icmp ult double* %arrayptr418, %scevgep\n   %found.conflict35 = and i1 %bound033, %bound134\n   %conflict.rdx = or i1 %found.conflict, %found.conflict35\n   br i1 %conflict.rdx, label %scalar.ph, label %vector.ph\n\nvector.ph:                                        ; preds = %vector.memcheck\n   %n.vec = and i64 %4, -4\n   %14 = add nsw i64 %n.vec, -4\n   %15 = lshr exact i64 %14, 2\n   %16 = add nuw nsw i64 %15, 1\n   %xtraiter = and i64 %16, 1\n   %17 = icmp eq i64 %14, 0\n   br i1 %17, label %middle.block.unr-lcssa, label %vector.ph.new\n\nvector.ph.new:                                    ; preds = %vector.ph\n   %unroll_iter = and i64 %16, 9223372036854775806\n; │ @ simdloop.jl:77 within `macro expansion` @ In[29]:4\n; │┌ @ essentials.jl:13 within `getindex`\n    %.pre = load double, double* %arrayptr418, align 8\n    %.pre43 = load double, double* %12, align 8\n    %.pre44 = load double, double* %13, align 8\n; │└\n; │ @ simdloop.jl:75 within `macro expansion`\n   br label %vector.body\n\nvector.body:                                      ; preds = %vector.body, %vector.ph.new\n; │ @ simdloop.jl:77 within `macro expansion` @ In[29]:4\n; │┌ @ essentials.jl:13 within `getindex`\n    %index = phi i64 [ 0, %vector.ph.new ], [ %index.next.1, %vector.body ]\n    %vec.ind = phi &lt;4 x i64&gt; [ &lt;i64 0, i64 1, i64 2, i64 3&gt;, %vector.ph.new ], [ %vec.ind.next.1, %vector.body ]\n    %niter = phi i64 [ 0, %vector.ph.new ], [ %niter.next.1, %vector.body ]\n; │└\n; │ @ simdloop.jl:76 within `macro expansion`\n; │┌ @ simdloop.jl:54 within `simd_index`\n; ││┌ @ range.jl:929 within `getindex`\n; │││┌ @ int.jl:87 within `+`\n      %18 = add nuw nsw &lt;4 x i64&gt; %vec.ind, &lt;i64 2, i64 2, i64 2, i64 2&gt;\n; │└└└\n; │ @ simdloop.jl:77 within `macro expansion` @ In[29]:4\n; │┌ @ essentials.jl:13 within `getindex`\n    %19 = or i64 %index, 1\n    %20 = getelementptr inbounds double, double* %arrayptr17, i64 %19\n    %21 = bitcast double* %20 to &lt;4 x double&gt;*\n    %wide.load = load &lt;4 x double&gt;, &lt;4 x double&gt;* %21, align 8\n; │└\n; │ @ simdloop.jl:75 within `macro expansion`\n   %broadcast.splatinsert = insertelement &lt;4 x double&gt; poison, double %.pre, i64 0\n   %broadcast.splat = shufflevector &lt;4 x double&gt; %broadcast.splatinsert, &lt;4 x double&gt; poison, &lt;4 x i32&gt; zeroinitializer\n   %22 = fsub &lt;4 x double&gt; %wide.load, %broadcast.splat\n; │ @ simdloop.jl:77 within `macro expansion` @ In[29]:4\n; │┌ @ promotion.jl:423 within `*`\n; ││┌ @ promotion.jl:393 within `promote`\n; │││┌ @ promotion.jl:370 within `_promote`\n; ││││┌ @ number.jl:7 within `convert`\n; │││││┌ @ float.jl:159 within `Float64`\n        %broadcast.splatinsert36 = insertelement &lt;4 x double&gt; poison, double %.pre43, i64 0\n        %broadcast.splat37 = shufflevector &lt;4 x double&gt; %broadcast.splatinsert36, &lt;4 x double&gt; poison, &lt;4 x i32&gt; zeroinitializer\n        %23 = sitofp &lt;4 x i64&gt; %18 to &lt;4 x double&gt;\n; │└└└└└\n; │ @ simdloop.jl:75 within `macro expansion`\n   %24 = fmul &lt;4 x double&gt; %broadcast.splat37, %23\n; │ @ simdloop.jl:77 within `macro expansion` @ In[29]:4\n; │┌ @ float.jl:410 within `-`\n    %25 = fsub &lt;4 x double&gt; %22, %24\n; │└\n; │┌ @ essentials.jl:13 within `getindex`\n    %broadcast.splatinsert39 = insertelement &lt;4 x double&gt; poison, double %.pre44, i64 0\n    %broadcast.splat40 = shufflevector &lt;4 x double&gt; %broadcast.splatinsert39, &lt;4 x double&gt; poison, &lt;4 x i32&gt; zeroinitializer\n    %26 = getelementptr inbounds double, double* %arrayptr17, i64 %index\n    %27 = bitcast double* %26 to &lt;4 x double&gt;*\n    %wide.load38 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %27, align 8\n; │└\n; │ @ simdloop.jl:75 within `macro expansion`\n   %28 = fmul &lt;4 x double&gt; %broadcast.splat40, %wide.load38\n; │ @ simdloop.jl:77 within `macro expansion` @ In[29]:4\n; │┌ @ float.jl:410 within `-`\n    %29 = fsub &lt;4 x double&gt; %25, %28\n; │└\n; │┌ @ array.jl:1021 within `setindex!`\n    %30 = getelementptr inbounds double, double* %arrayptr1622, i64 %index\n    %31 = bitcast double* %30 to &lt;4 x double&gt;*\n    store &lt;4 x double&gt; %29, &lt;4 x double&gt;* %31, align 8\n; │└\n; │┌ @ essentials.jl:13 within `getindex`\n    %index.next = or i64 %index, 4\n; │└\n; │ @ simdloop.jl:76 within `macro expansion`\n; │┌ @ simdloop.jl:54 within `simd_index`\n; ││┌ @ range.jl:929 within `getindex`\n; │││┌ @ int.jl:87 within `+`\n      %32 = add &lt;4 x i64&gt; %vec.ind, &lt;i64 6, i64 6, i64 6, i64 6&gt;\n; │└└└\n; │ @ simdloop.jl:77 within `macro expansion` @ In[29]:4\n; │┌ @ essentials.jl:13 within `getindex`\n    %33 = or i64 %index, 5\n    %34 = getelementptr inbounds double, double* %arrayptr17, i64 %33\n    %35 = bitcast double* %34 to &lt;4 x double&gt;*\n    %wide.load.1 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %35, align 8\n; │└\n; │ @ simdloop.jl:75 within `macro expansion`\n   %36 = fsub &lt;4 x double&gt; %wide.load.1, %broadcast.splat\n; │ @ simdloop.jl:77 within `macro expansion` @ In[29]:4\n; │┌ @ promotion.jl:423 within `*`\n; ││┌ @ promotion.jl:393 within `promote`\n; │││┌ @ promotion.jl:370 within `_promote`\n; ││││┌ @ number.jl:7 within `convert`\n; │││││┌ @ float.jl:159 within `Float64`\n        %37 = sitofp &lt;4 x i64&gt; %32 to &lt;4 x double&gt;\n; │└└└└└\n; │ @ simdloop.jl:75 within `macro expansion`\n   %38 = fmul &lt;4 x double&gt; %broadcast.splat37, %37\n; │ @ simdloop.jl:77 within `macro expansion` @ In[29]:4\n; │┌ @ float.jl:410 within `-`\n    %39 = fsub &lt;4 x double&gt; %36, %38\n; │└\n; │┌ @ essentials.jl:13 within `getindex`\n    %40 = getelementptr inbounds double, double* %arrayptr17, i64 %index.next\n    %41 = bitcast double* %40 to &lt;4 x double&gt;*\n    %wide.load38.1 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %41, align 8\n; │└\n; │ @ simdloop.jl:75 within `macro expansion`\n   %42 = fmul &lt;4 x double&gt; %broadcast.splat40, %wide.load38.1\n; │ @ simdloop.jl:77 within `macro expansion` @ In[29]:4\n; │┌ @ float.jl:410 within `-`\n    %43 = fsub &lt;4 x double&gt; %39, %42\n; │└\n; │┌ @ array.jl:1021 within `setindex!`\n    %44 = getelementptr inbounds double, double* %arrayptr1622, i64 %index.next\n    %45 = bitcast double* %44 to &lt;4 x double&gt;*\n    store &lt;4 x double&gt; %43, &lt;4 x double&gt;* %45, align 8\n; │└\n; │┌ @ essentials.jl:13 within `getindex`\n    %index.next.1 = add nuw i64 %index, 8\n    %vec.ind.next.1 = add &lt;4 x i64&gt; %vec.ind, &lt;i64 8, i64 8, i64 8, i64 8&gt;\n    %niter.next.1 = add i64 %niter, 2\n    %niter.ncmp.1 = icmp eq i64 %niter.next.1, %unroll_iter\n    br i1 %niter.ncmp.1, label %middle.block.unr-lcssa.loopexit, label %vector.body\n\nmiddle.block.unr-lcssa.loopexit:                  ; preds = %vector.body\n    %phi.bo = add &lt;4 x i64&gt; %vec.ind, &lt;i64 10, i64 10, i64 10, i64 10&gt;\n    %phi.cast = sitofp &lt;4 x i64&gt; %phi.bo to &lt;4 x double&gt;\n    br label %middle.block.unr-lcssa\n\nmiddle.block.unr-lcssa:                           ; preds = %middle.block.unr-lcssa.loopexit, %vector.ph\n    %index.unr = phi i64 [ 0, %vector.ph ], [ %index.next.1, %middle.block.unr-lcssa.loopexit ]\n    %vec.ind.unr = phi &lt;4 x double&gt; [ &lt;double 2.000000e+00, double 3.000000e+00, double 4.000000e+00, double 5.000000e+00&gt;, %vector.ph ], [ %phi.cast, %middle.block.unr-lcssa.loopexit ]\n    %lcmp.mod.not = icmp eq i64 %xtraiter, 0\n    br i1 %lcmp.mod.not, label %middle.block, label %vector.body.epil.preheader\n\nvector.body.epil.preheader:                       ; preds = %middle.block.unr-lcssa\n    %46 = or i64 %index.unr, 1\n    %47 = getelementptr inbounds double, double* %arrayptr17, i64 %46\n    %48 = bitcast double* %47 to &lt;4 x double&gt;*\n    %wide.load.epil = load &lt;4 x double&gt;, &lt;4 x double&gt;* %48, align 8\n    %49 = load double, double* %arrayptr418, align 8\n; │└\n; │ @ simdloop.jl:75 within `macro expansion`\n   %broadcast.splatinsert.epil = insertelement &lt;4 x double&gt; poison, double %49, i64 0\n   %broadcast.splat.epil = shufflevector &lt;4 x double&gt; %broadcast.splatinsert.epil, &lt;4 x double&gt; poison, &lt;4 x i32&gt; zeroinitializer\n   %50 = fsub &lt;4 x double&gt; %wide.load.epil, %broadcast.splat.epil\n; │ @ simdloop.jl:77 within `macro expansion` @ In[29]:4\n; │┌ @ essentials.jl:13 within `getindex`\n    %51 = load double, double* %12, align 8\n; │└\n; │┌ @ promotion.jl:423 within `*`\n; ││┌ @ promotion.jl:393 within `promote`\n; │││┌ @ promotion.jl:370 within `_promote`\n; ││││┌ @ number.jl:7 within `convert`\n; │││││┌ @ float.jl:159 within `Float64`\n        %broadcast.splatinsert36.epil = insertelement &lt;4 x double&gt; poison, double %51, i64 0\n        %broadcast.splat37.epil = shufflevector &lt;4 x double&gt; %broadcast.splatinsert36.epil, &lt;4 x double&gt; poison, &lt;4 x i32&gt; zeroinitializer\n; │└└└└└\n; │ @ simdloop.jl:75 within `macro expansion`\n   %52 = fmul &lt;4 x double&gt; %broadcast.splat37.epil, %vec.ind.unr\n; │ @ simdloop.jl:77 within `macro expansion` @ In[29]:4\n; │┌ @ float.jl:410 within `-`\n    %53 = fsub &lt;4 x double&gt; %50, %52\n; │└\n; │┌ @ essentials.jl:13 within `getindex`\n    %54 = load double, double* %13, align 8\n    %broadcast.splatinsert39.epil = insertelement &lt;4 x double&gt; poison, double %54, i64 0\n    %broadcast.splat40.epil = shufflevector &lt;4 x double&gt; %broadcast.splatinsert39.epil, &lt;4 x double&gt; poison, &lt;4 x i32&gt; zeroinitializer\n    %55 = getelementptr inbounds double, double* %arrayptr17, i64 %index.unr\n    %56 = bitcast double* %55 to &lt;4 x double&gt;*\n    %wide.load38.epil = load &lt;4 x double&gt;, &lt;4 x double&gt;* %56, align 8\n; │└\n; │ @ simdloop.jl:75 within `macro expansion`\n   %57 = fmul &lt;4 x double&gt; %broadcast.splat40.epil, %wide.load38.epil\n; │ @ simdloop.jl:77 within `macro expansion` @ In[29]:4\n; │┌ @ float.jl:410 within `-`\n    %58 = fsub &lt;4 x double&gt; %53, %57\n; │└\n; │┌ @ array.jl:1021 within `setindex!`\n    %59 = getelementptr inbounds double, double* %arrayptr1622, i64 %index.unr\n    %60 = bitcast double* %59 to &lt;4 x double&gt;*\n    store &lt;4 x double&gt; %58, &lt;4 x double&gt;* %60, align 8\n; │└\n; │ @ simdloop.jl:75 within `macro expansion`\n   br label %middle.block\n\nmiddle.block:                                     ; preds = %vector.body.epil.preheader, %middle.block.unr-lcssa\n   %cmp.n = icmp eq i64 %4, %n.vec\n   br i1 %cmp.n, label %L56, label %scalar.ph\n\nscalar.ph:                                        ; preds = %middle.block, %vector.memcheck, %L19.lr.ph\n   %bc.resume.val = phi i64 [ %n.vec, %middle.block ], [ 0, %L19.lr.ph ], [ 0, %vector.memcheck ]\n   %61 = add nsw i64 %3, -2\n   %xtraiter41 = and i64 %4, 1\n   %lcmp.mod42.not = icmp eq i64 %xtraiter41, 0\n   br i1 %lcmp.mod42.not, label %L19.prol.loopexit, label %L19.prol.preheader\n\nL19.prol.preheader:                               ; preds = %scalar.ph\n; │ @ simdloop.jl:76 within `macro expansion`\n; │┌ @ simdloop.jl:54 within `simd_index`\n; ││┌ @ range.jl:929 within `getindex`\n; │││┌ @ int.jl:87 within `+`\n      %62 = or i64 %bc.resume.val, 2\n; │└└└\n; │ @ simdloop.jl:77 within `macro expansion` @ In[29]:4\n; │┌ @ essentials.jl:13 within `getindex`\n    %63 = or i64 %bc.resume.val, 1\n    %64 = getelementptr inbounds double, double* %arrayptr17, i64 %63\n    %arrayref.prol = load double, double* %64, align 8\n    %arrayref5.prol = load double, double* %arrayptr418, align 8\n; │└\n; │┌ @ float.jl:410 within `-`\n    %65 = fsub double %arrayref.prol, %arrayref5.prol\n; │└\n; │┌ @ essentials.jl:13 within `getindex`\n    %arrayref8.prol = load double, double* %12, align 8\n; │└\n; │┌ @ promotion.jl:423 within `*`\n; ││┌ @ promotion.jl:393 within `promote`\n; │││┌ @ promotion.jl:370 within `_promote`\n; ││││┌ @ number.jl:7 within `convert`\n; │││││┌ @ float.jl:159 within `Float64`\n        %66 = sitofp i64 %62 to double\n; ││└└└└\n; ││ @ promotion.jl:423 within `*` @ float.jl:411\n    %67 = fmul double %arrayref8.prol, %66\n; │└\n; │┌ @ float.jl:410 within `-`\n    %68 = fsub double %65, %67\n; │└\n; │┌ @ essentials.jl:13 within `getindex`\n    %arrayref11.prol = load double, double* %13, align 8\n    %69 = getelementptr inbounds double, double* %arrayptr17, i64 %bc.resume.val\n    %arrayref14.prol = load double, double* %69, align 8\n; │└\n; │┌ @ float.jl:411 within `*`\n    %70 = fmul double %arrayref11.prol, %arrayref14.prol\n; │└\n; │┌ @ float.jl:410 within `-`\n    %71 = fsub double %68, %70\n; │└\n; │┌ @ array.jl:1021 within `setindex!`\n    %72 = getelementptr inbounds double, double* %arrayptr1622, i64 %bc.resume.val\n    store double %71, double* %72, align 8\n; │└\n; │ @ simdloop.jl:75 within `macro expansion`\n   br label %L19.prol.loopexit\n\nL19.prol.loopexit:                                ; preds = %L19.prol.preheader, %scalar.ph\n   %value_phi124.unr = phi i64 [ %bc.resume.val, %scalar.ph ], [ %63, %L19.prol.preheader ]\n   %73 = icmp eq i64 %61, %bc.resume.val\n   br i1 %73, label %L56, label %L19\n\nL19:                                              ; preds = %L19, %L19.prol.loopexit\n   %value_phi124 = phi i64 [ %74, %L19 ], [ %value_phi124.unr, %L19.prol.loopexit ]\n; │ @ simdloop.jl:76 within `macro expansion`\n; │┌ @ simdloop.jl:54 within `simd_index`\n; ││┌ @ range.jl:929 within `getindex`\n; │││┌ @ int.jl:87 within `+`\n      %74 = add nuw nsw i64 %value_phi124, 2\n; │└└└\n; │ @ simdloop.jl:77 within `macro expansion` @ In[29]:4\n; │┌ @ essentials.jl:13 within `getindex`\n    %75 = add nuw nsw i64 %value_phi124, 1\n    %76 = getelementptr inbounds double, double* %arrayptr17, i64 %75\n    %arrayref = load double, double* %76, align 8\n    %arrayref5 = load double, double* %arrayptr418, align 8\n; │└\n; │┌ @ float.jl:410 within `-`\n    %77 = fsub double %arrayref, %arrayref5\n; │└\n; │┌ @ essentials.jl:13 within `getindex`\n    %arrayref8 = load double, double* %12, align 8\n; │└\n; │┌ @ promotion.jl:423 within `*`\n; ││┌ @ promotion.jl:393 within `promote`\n; │││┌ @ promotion.jl:370 within `_promote`\n; ││││┌ @ number.jl:7 within `convert`\n; │││││┌ @ float.jl:159 within `Float64`\n        %78 = sitofp i64 %74 to double\n; ││└└└└\n; ││ @ promotion.jl:423 within `*` @ float.jl:411\n    %79 = fmul double %arrayref8, %78\n; │└\n; │┌ @ float.jl:410 within `-`\n    %80 = fsub double %77, %79\n; │└\n; │┌ @ essentials.jl:13 within `getindex`\n    %arrayref11 = load double, double* %13, align 8\n    %81 = getelementptr inbounds double, double* %arrayptr17, i64 %value_phi124\n    %arrayref14 = load double, double* %81, align 8\n; │└\n; │┌ @ float.jl:411 within `*`\n    %82 = fmul double %arrayref11, %arrayref14\n; │└\n; │┌ @ float.jl:410 within `-`\n    %83 = fsub double %80, %82\n; │└\n; │┌ @ array.jl:1021 within `setindex!`\n    %84 = getelementptr inbounds double, double* %arrayptr1622, i64 %value_phi124\n    store double %83, double* %84, align 8\n; │└\n; │ @ simdloop.jl:76 within `macro expansion`\n; │┌ @ simdloop.jl:54 within `simd_index`\n; ││┌ @ range.jl:929 within `getindex`\n; │││┌ @ int.jl:87 within `+`\n      %85 = add nuw nsw i64 %value_phi124, 3\n; │└└└\n; │ @ simdloop.jl:77 within `macro expansion` @ In[29]:4\n; │┌ @ essentials.jl:13 within `getindex`\n    %86 = getelementptr inbounds double, double* %arrayptr17, i64 %74\n    %arrayref.1 = load double, double* %86, align 8\n    %arrayref5.1 = load double, double* %arrayptr418, align 8\n; │└\n; │┌ @ float.jl:410 within `-`\n    %87 = fsub double %arrayref.1, %arrayref5.1\n; │└\n; │┌ @ essentials.jl:13 within `getindex`\n    %arrayref8.1 = load double, double* %12, align 8\n; │└\n; │┌ @ promotion.jl:423 within `*`\n; ││┌ @ promotion.jl:393 within `promote`\n; │││┌ @ promotion.jl:370 within `_promote`\n; ││││┌ @ number.jl:7 within `convert`\n; │││││┌ @ float.jl:159 within `Float64`\n        %88 = sitofp i64 %85 to double\n; ││└└└└\n; ││ @ promotion.jl:423 within `*` @ float.jl:411\n    %89 = fmul double %arrayref8.1, %88\n; │└\n; │┌ @ float.jl:410 within `-`\n    %90 = fsub double %87, %89\n; │└\n; │┌ @ essentials.jl:13 within `getindex`\n    %arrayref11.1 = load double, double* %13, align 8\n    %arrayref14.1 = load double, double* %76, align 8\n; │└\n; │┌ @ float.jl:411 within `*`\n    %91 = fmul double %arrayref11.1, %arrayref14.1\n; │└\n; │┌ @ float.jl:410 within `-`\n    %92 = fsub double %90, %91\n; │└\n; │┌ @ array.jl:1021 within `setindex!`\n    %93 = getelementptr inbounds double, double* %arrayptr1622, i64 %75\n    store double %92, double* %93, align 8\n; │└\n; │ @ simdloop.jl:75 within `macro expansion`\n; │┌ @ int.jl:83 within `&lt;`\n    %exitcond.not.1 = icmp eq i64 %74, %4\n; │└\n   br i1 %exitcond.not.1, label %L56, label %L19\n\nL56:                                              ; preds = %L19, %L19.prol.loopexit, %middle.block, %top\n; │ @ simdloop.jl:76 within `macro expansion`\n; │┌ @ simdloop.jl:54 within `simd_index`\n; ││┌ @ range.jl:930 within `getindex`\n     ret {}* inttoptr (i64 131694430519304 to {}*)\n; └└└\n}\n\n\n\n@benchmark resids!($e,$y,$θ)\n\n\nBenchmarkTools.Trial: 10000 samples with 56 evaluations.\n Range (min … max):  871.304 ns …   2.891 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     875.518 ns               ┊ GC (median):    0.00%\n Time  (mean ± σ):   914.795 ns ± 111.235 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n  █▄       ▃▁   ▂                                             ▄ ▁\n  ██▃▄▃▁▁▅▅██▇▇▇█▆▅▄▅▆▇▅▁▄▅▇▄▄▄▃▄▄▅▆▆▅▅▆▅▄▄▄▁▁▄▄▅▅▆▅▄▄▄▄▅▅▄▁▁▄█ █\n  871 ns        Histogram: log(frequency) by time       1.24 μs &lt;\n Memory estimate: 0 bytes, allocs estimate: 0.\n\n\n\n\n\n\nCode\nfunction resids_turbo!(e, yin, θ)\n  T = length(yin)\n  @turbo for t in 2:T\n    e[t-1] = yin[t] - θ[1] - θ[2]*t - θ[3]*yin[t-1]\n  end\n  nothing\nend\n\n@code_llvm resids_turbo!(e,y, θ)\n\n\n;  @ In[31]:1 within `resids_turbo!`\ndefine nonnull {}* @\"japi1_resids_turbo!_5523\"({}* %function, {}** noalias nocapture noundef readonly %args, i32 %nargs) #0 {\ntop:\n  %stackargs = alloca {}**, align 8\n  store volatile {}** %args, {}*** %stackargs, align 8\n  %0 = bitcast {}** %args to double***\n  %1 = load double**, double*** %0, align 8\n  %2 = getelementptr inbounds {}*, {}** %args, i64 1\n  %3 = load {}*, {}** %2, align 8\n  %4 = getelementptr inbounds {}*, {}** %args, i64 2\n  %5 = bitcast {}** %4 to double***\n  %6 = load double**, double*** %5, align 8\n;  @ In[31]:2 within `resids_turbo!`\n; ┌ @ essentials.jl:10 within `length`\n   %7 = bitcast {}* %3 to { i8*, i64, i16, i16, i32 }*\n   %arraylen_ptr = getelementptr inbounds { i8*, i64, i16, i16, i32 }, { i8*, i64, i16, i16, i32 }* %7, i64 0, i32 1\n   %arraylen = load i64, i64* %arraylen_ptr, align 8\n; └\n;  @ In[31]:3 within `resids_turbo!`\n; ┌ @ /home/paul/.julia/packages/LoopVectorization/QgYWB/src/condense_loopset.jl:1179 within `macro expansion`\n; │┌ @ /home/paul/.julia/packages/LayoutPointers/v9n88/src/stridedpointers.jl:100 within `stridedpointer_preserve`\n; ││┌ @ /home/paul/.julia/packages/LayoutPointers/v9n88/src/stridedpointers.jl:18 within `memory_reference` @ /home/paul/.julia/packages/LayoutPointers/v9n88/src/stridedpointers.jl:21\n; │││┌ @ abstractarray.jl:1237 within `pointer`\n; ││││┌ @ pointer.jl:65 within `unsafe_convert`\n       %arrayptr225 = load double*, double** %1, align 8\n; │└└└└\n; │┌ @ abstractarray.jl:1291 within `getindex`\n; ││┌ @ abstractarray.jl:1319 within `_getindex`\n; │││┌ @ essentials.jl:13 within `getindex`\n      %arrayptr25221 = load double*, double** %6, align 8\n      %8 = getelementptr inbounds double, double* %arrayptr25221, i64 1\n      %arrayref = load double, double* %8, align 8\n      %9 = getelementptr inbounds double, double* %arrayptr25221, i64 2\n      %arrayref28 = load double, double* %9, align 8\n; │└└└\n; │┌ @ /home/paul/.julia/packages/LayoutPointers/v9n88/src/stridedpointers.jl:100 within `stridedpointer_preserve`\n; ││┌ @ /home/paul/.julia/packages/LayoutPointers/v9n88/src/stridedpointers.jl:18 within `memory_reference` @ /home/paul/.julia/packages/LayoutPointers/v9n88/src/stridedpointers.jl:21\n; │││┌ @ abstractarray.jl:1237 within `pointer`\n; ││││┌ @ pointer.jl:65 within `unsafe_convert`\n       %10 = bitcast {}* %3 to double**\n       %arrayptr30224 = load double*, double** %10, align 8\n; │└└└└\n; │┌ @ abstractarray.jl:1291 within `getindex`\n; ││┌ @ abstractarray.jl:1319 within `_getindex`\n; │││┌ @ essentials.jl:13 within `getindex`\n      %arrayref33 = load double, double* %arrayptr25221, align 8\n; │└└└\n; │┌ @ /home/paul/.julia/packages/LoopVectorization/QgYWB/src/condense_loopset.jl:390 within `gespf1`\n; ││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:479 within `gesp`\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:442 within `increment_ptr`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:407 within `_gep`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:407 within `macro expansion`\n        %ptr.1.i = getelementptr inbounds double, double* %arrayptr30224, i64 -2\n        %ptr.1.i37 = getelementptr inbounds double, double* %arrayptr225, i64 -2\n; │└└└└└\n; │┌ @ /home/paul/.julia/packages/LoopVectorization/QgYWB/src/reconstruct_loopset.jl:1107 within `_turbo_!`\n; ││┌ @ /home/paul/.julia/packages/LoopVectorization/QgYWB/src/reconstruct_loopset.jl:1107 within `macro expansion`\n; │││┌ @ operators.jl:425 within `&gt;=`\n; ││││┌ @ operators.jl:401 within `&lt;=`\n; │││││┌ @ bool.jl:39 within `|`\n        %11 = icmp ugt i64 %arraylen, 1\n; │││└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:47 within `assume`\n      call void @llvm.assume(i1 %11)\n; │││└\n; │││┌ @ /home/paul/.julia/packages/LoopVectorization/QgYWB/src/modeling/graphs.jl:236 within `vcmpend`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49 within `vsub_nsw`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49 within `macro expansion`\n        %res.i = add nsw i64 %arraylen, -11\n; ││││└└\n; ││││┌ @ int.jl:514 within `&lt;=`\n       %.not232 = icmp ult i64 %arraylen, 13\n; │││└└\n     br i1 %.not232, label %L134, label %L97.lr.ph\n\nL97.lr.ph:                                        ; preds = %top\n     %ie.i = insertelement &lt;4 x double&gt; undef, double %arrayref33, i64 0\n     %v.i = shufflevector &lt;4 x double&gt; %ie.i, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n     %12 = fneg fast double %arrayref28\n     %ie.i63 = insertelement &lt;4 x double&gt; undef, double %12, i64 0\n     %v.i64 = shufflevector &lt;4 x double&gt; %ie.i63, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n     %13 = fneg fast double %arrayref\n     %ie.i70 = insertelement &lt;4 x double&gt; undef, double %13, i64 0\n     %v.i71 = shufflevector &lt;4 x double&gt; %ie.i70, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n     br label %L97\n\nL97:                                              ; preds = %L97, %L97.lr.ph\n     %value_phi35233 = phi i64 [ 2, %L97.lr.ph ], [ %res.i91, %L97 ]\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:771 within `_vload`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:535 within `_vload_unroll`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:60 within `macro expansion`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:436 within `gep`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:414 within `_gep`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:414 within `macro expansion`\n           %ptr.1.i39 = getelementptr inbounds double, double* %ptr.1.i, i64 %value_phi35233\n; ││││││└└└\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:95 within `_vload`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:987 within `__vload`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:987 within `macro expansion`\n           %ptr.1.i41 = bitcast double* %ptr.1.i39 to &lt;4 x double&gt;*\n           %res.i42 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %ptr.1.i41, align 8\n           %ptr.1.i43 = getelementptr inbounds double, double* %ptr.1.i39, i64 4\n           %ptr.2.i44 = bitcast double* %ptr.1.i43 to &lt;4 x double&gt;*\n           %res.i45 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %ptr.2.i44, align 8\n           %ptr.1.i46 = getelementptr inbounds double, double* %ptr.1.i39, i64 8\n           %ptr.2.i47 = bitcast double* %ptr.1.i46 to &lt;4 x double&gt;*\n           %res.i48 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %ptr.2.i47, align 8\n; │││└└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/static.jl:55 within `vadd_nsw` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49 within `macro expansion`\n       %res.i49 = or i64 %value_phi35233, 1\n; │││└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:771 within `_vload`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:535 within `_vload_unroll`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:60 within `macro expansion`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:436 within `gep`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:414 within `_gep`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:414 within `macro expansion`\n           %ptr.1.i50 = getelementptr inbounds double, double* %ptr.1.i, i64 %res.i49\n; ││││││└└└\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:95 within `_vload`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:987 within `__vload`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:987 within `macro expansion`\n           %ptr.1.i52 = bitcast double* %ptr.1.i50 to &lt;4 x double&gt;*\n           %res.i53 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %ptr.1.i52, align 8\n           %ptr.1.i54 = getelementptr inbounds double, double* %ptr.1.i50, i64 4\n           %ptr.2.i55 = bitcast double* %ptr.1.i54 to &lt;4 x double&gt;*\n           %res.i56 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %ptr.2.i55, align 8\n           %ptr.1.i57 = getelementptr inbounds double, double* %ptr.1.i50, i64 8\n           %ptr.2.i58 = bitcast double* %ptr.1.i57 to &lt;4 x double&gt;*\n           %res.i59 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %ptr.2.i58, align 8\n; │││└└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:99 within `sub_fast`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:111 within `vsub_fast`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:11 within `fmap`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:116 within `vsub_fast`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:116 within `macro expansion`\n          %res.i60 = fsub reassoc nsz arcp contract afn &lt;4 x double&gt; %res.i53, %v.i\n; ││││││└└\n; ││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:11 within `fmap` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:11\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:116 within `vsub_fast`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:116 within `macro expansion`\n          %res.i61 = fsub reassoc nsz arcp contract afn &lt;4 x double&gt; %res.i56, %v.i\n; ││││││└└\n; ││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:11 within `fmap` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:11 @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:7\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:116 within `vsub_fast`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:116 within `macro expansion`\n          %res.i62 = fsub reassoc nsz arcp contract afn &lt;4 x double&gt; %res.i59, %v.i\n; │││└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:498 within `vfnmadd_fast`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:493 within `vfmadd_fast`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:393 within `vmuladd_fast` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:233\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:25 within `fmap`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:25 within `macro expansion`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:438 within `vmuladd_fast`\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:438 within `macro expansion`\n            %res.i65 = call reassoc nsz arcp contract afn &lt;4 x double&gt; @llvm.fmuladd.v4f64(&lt;4 x double&gt; %v.i64, &lt;4 x double&gt; %res.i42, &lt;4 x double&gt; %res.i60)\n            %res.i66 = call reassoc nsz arcp contract afn &lt;4 x double&gt; @llvm.fmuladd.v4f64(&lt;4 x double&gt; %v.i64, &lt;4 x double&gt; %res.i45, &lt;4 x double&gt; %res.i61)\n            %res.i67 = call reassoc nsz arcp contract afn &lt;4 x double&gt; @llvm.fmuladd.v4f64(&lt;4 x double&gt; %v.i64, &lt;4 x double&gt; %res.i48, &lt;4 x double&gt; %res.i62)\n; │││└└└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vector_width.jl:45 within `vadd_nsw` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/static.jl:53 @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49 within `macro expansion`\n       %res.i68 = add nuw nsw i64 %value_phi35233, 4\n       %res.i69 = add nuw nsw i64 %value_phi35233, 8\n; │││└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:498 within `vfnmadd_fast`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:493 within `vfmadd_fast`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:392 within `vmuladd_fast`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/VectorizationBase.jl:100 within `promote`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:203 within `convert`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:254 within `vconvert`\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:18 within `fmap`\n; ││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:140 within `vconvert`\n; │││││││││││┌ @ number.jl:7 within `convert`\n; ││││││││││││┌ @ float.jl:159 within `Float64`\n               %14 = sitofp i64 %value_phi35233 to double\n; │││││││││││└└\n; │││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:72 within `vrangeincr`\n; ││││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:94 within `macro expansion`\n               %ie.i72 = insertelement &lt;4 x double&gt; undef, double %14, i64 0\n               %v.i73 = shufflevector &lt;4 x double&gt; %ie.i72, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n               %res.i74 = fadd fast &lt;4 x double&gt; %v.i73, &lt;double 0.000000e+00, double 1.000000e+00, double 2.000000e+00, double 3.000000e+00&gt;\n; ││││││││││└└└\n; ││││││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:18 within `fmap` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:18\n; ││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:140 within `vconvert`\n; │││││││││││┌ @ number.jl:7 within `convert`\n; ││││││││││││┌ @ float.jl:159 within `Float64`\n               %15 = sitofp i64 %res.i68 to double\n; │││││││││││└└\n; │││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:72 within `vrangeincr`\n; ││││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:94 within `macro expansion`\n               %ie.i75 = insertelement &lt;4 x double&gt; undef, double %15, i64 0\n               %v.i76 = shufflevector &lt;4 x double&gt; %ie.i75, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n               %res.i77 = fadd fast &lt;4 x double&gt; %v.i76, &lt;double 0.000000e+00, double 1.000000e+00, double 2.000000e+00, double 3.000000e+00&gt;\n; ││││││││││└└└\n; ││││││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:18 within `fmap` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:18 @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:10\n; ││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:140 within `vconvert`\n; │││││││││││┌ @ number.jl:7 within `convert`\n; ││││││││││││┌ @ float.jl:159 within `Float64`\n               %16 = sitofp i64 %res.i69 to double\n; │││││││││││└└\n; │││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:72 within `vrangeincr`\n; ││││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:94 within `macro expansion`\n               %ie.i78 = insertelement &lt;4 x double&gt; undef, double %16, i64 0\n               %v.i79 = shufflevector &lt;4 x double&gt; %ie.i78, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n               %res.i80 = fadd fast &lt;4 x double&gt; %v.i79, &lt;double 0.000000e+00, double 1.000000e+00, double 2.000000e+00, double 3.000000e+00&gt;\n; ││││││└└└└└└└\n; ││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:393 within `vmuladd_fast` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:233\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:25 within `fmap`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:25 within `macro expansion`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:438 within `vmuladd_fast`\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:438 within `macro expansion`\n            %res.i81 = call reassoc nsz arcp contract afn &lt;4 x double&gt; @llvm.fmuladd.v4f64(&lt;4 x double&gt; %v.i71, &lt;4 x double&gt; %res.i74, &lt;4 x double&gt; %res.i65)\n            %res.i82 = call reassoc nsz arcp contract afn &lt;4 x double&gt; @llvm.fmuladd.v4f64(&lt;4 x double&gt; %v.i71, &lt;4 x double&gt; %res.i77, &lt;4 x double&gt; %res.i66)\n            %res.i83 = call reassoc nsz arcp contract afn &lt;4 x double&gt; @llvm.fmuladd.v4f64(&lt;4 x double&gt; %v.i71, &lt;4 x double&gt; %res.i80, &lt;4 x double&gt; %res.i67)\n; │││└└└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:1803 within `_vstore!`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:1174 within `_vstore_unroll!`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:870 within `macro expansion`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:436 within `gep`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:414 within `_gep`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:414 within `macro expansion`\n           %ptr.1.i84 = getelementptr inbounds double, double* %ptr.1.i37, i64 %value_phi35233\n; ││││││└└└\n; ││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:872 within `macro expansion`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:199 within `_vstore!`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:1482 within `__vstore!`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:1482 within `macro expansion`\n           %ptr.1.i86 = bitcast double* %ptr.1.i84 to &lt;4 x double&gt;*\n           store &lt;4 x double&gt; %res.i81, &lt;4 x double&gt;* %ptr.1.i86, align 8\n           %ptr.1.i87 = getelementptr inbounds double, double* %ptr.1.i84, i64 4\n           %ptr.2.i88 = bitcast double* %ptr.1.i87 to &lt;4 x double&gt;*\n           store &lt;4 x double&gt; %res.i82, &lt;4 x double&gt;* %ptr.2.i88, align 8\n           %ptr.1.i89 = getelementptr inbounds double, double* %ptr.1.i84, i64 8\n           %ptr.2.i90 = bitcast double* %ptr.1.i89 to &lt;4 x double&gt;*\n           store &lt;4 x double&gt; %res.i83, &lt;4 x double&gt;* %ptr.2.i90, align 8\n; │││└└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/static.jl:53 within `vadd_nsw` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49 within `macro expansion`\n       %res.i91 = add nuw nsw i64 %value_phi35233, 12\n; │││└└\n; │││┌ @ /home/paul/.julia/packages/LoopVectorization/QgYWB/src/modeling/graphs.jl:236 within `vcmpend`\n; ││││┌ @ int.jl:514 within `&lt;=`\n       %.not = icmp sgt i64 %res.i91, %res.i\n; │││└└\n     br i1 %.not, label %L134, label %L97\n\nL134:                                             ; preds = %L97, %top\n     %value_phi35.lcssa = phi i64 [ 2, %top ], [ %res.i91, %L97 ]\n; │││┌ @ /home/paul/.julia/packages/LoopVectorization/QgYWB/src/modeling/graphs.jl:229 within `cmpend`\n; ││││┌ @ int.jl:514 within `&lt;=`\n       %.not226 = icmp ugt i64 %value_phi35.lcssa, %arraylen\n; │││└└\n     br i1 %.not226, label %L233, label %L136\n\nL136:                                             ; preds = %L134\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/masks.jl:553 within `mask`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/masks.jl:520 within `_mask`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/masks.jl:520 within `macro expansion`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/masks.jl:503 within `_mask_cmp`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/masks.jl:499 within `macro expansion`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:53 within `vsub_nw`\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:53 within `macro expansion`\n            %res.i92 = add nuw i64 %arraylen, 2\n; ││││││││└└\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/masks.jl:386 within `valrem`\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/masks.jl:386 within `macro expansion`\n; ││││││││││┌ @ int.jl:347 within `&`\n             %17 = and i64 %res.i92, 3\n; ││││││││└└└\n; ││││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/masks.jl:500 within `macro expansion`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:93 within `&gt;=`\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/masks.jl:810 within `vge`\n; ││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/promotion.jl:141 within `itosize`\n; │││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:209 within `rem`\n; ││││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:461 within `vrem`\n; │││││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:199 within `convert`\n; ││││││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:195 within `vconvert`\n; │││││││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:122 within `_vbroadcast`\n; ││││││││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:95 within `macro expansion`\n                   %ie.i93 = insertelement &lt;4 x i64&gt; undef, i64 %17, i64 0\n                   %v.i94 = shufflevector &lt;4 x i64&gt; %ie.i93, &lt;4 x i64&gt; undef, &lt;4 x i32&gt; zeroinitializer\n; ││││││││││└└└└└└└\n; ││││││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/masks.jl:810 within `vge` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/masks.jl:730\n; ││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/masks.jl:690 within `macro expansion`\n             %m.i = icmp uge &lt;4 x i64&gt; %v.i94, &lt;i64 0, i64 1, i64 2, i64 3&gt;\n; │││└└└└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/static.jl:55 within `vsub_nsw` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49 within `macro expansion`\n       %res.i96 = add nsw i64 %arraylen, -4\n; │││└└\n; │││┌ @ operators.jl:378 within `&gt;`\n; ││││┌ @ int.jl:83 within `&lt;`\n       %.not227 = icmp slt i64 %res.i96, %value_phi35.lcssa\n; │││└└\n     br i1 %.not227, label %L146, label %L165\n\nL146:                                             ; preds = %L136\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:105 within `_vload`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:997 within `__vload`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:997 within `macro expansion`\n        %ptr.1.i99228 = getelementptr inbounds double, double* %ptr.1.i, i64 %value_phi35.lcssa\n        %ptr.2.i100 = bitcast double* %ptr.1.i99228 to &lt;4 x double&gt;*\n        %res.i101 = call &lt;4 x double&gt; @llvm.masked.load.v4f64.p0v4f64(&lt;4 x double&gt;* nonnull %ptr.2.i100, i32 8, &lt;4 x i1&gt; %m.i, &lt;4 x double&gt; zeroinitializer)\n; ││││└└\n; ││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:104 within `_vload`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:45 within `linear_index`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/cartesian_indexing.jl:5 within `tdot` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/cartesian_indexing.jl:9\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/lazymul.jl:61 within `lazymul`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/static.jl:53 within `vmul_nsw` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49 within `macro expansion`\n           %res.i102 = shl i64 %value_phi35.lcssa, 3\n           %res.i103 = add nuw nsw i64 %res.i102, 8\n; ││││└└└└└\n; ││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:105 within `_vload`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:997 within `__vload`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:997 within `macro expansion`\n        %ptr.0.i104 = bitcast double* %ptr.1.i to i8*\n        %ptr.1.i105 = getelementptr inbounds i8, i8* %ptr.0.i104, i64 %res.i103\n        %ptr.2.i106 = bitcast i8* %ptr.1.i105 to &lt;4 x double&gt;*\n        %res.i107 = call &lt;4 x double&gt; @llvm.masked.load.v4f64.p0v4f64(&lt;4 x double&gt;* nonnull %ptr.2.i106, i32 8, &lt;4 x i1&gt; %m.i, &lt;4 x double&gt; zeroinitializer)\n; │││└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:94 within `sub_fast`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/VectorizationBase.jl:96 within `promote`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:199 within `convert`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:191 within `vconvert`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:151 within `vbroadcast`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:122 within `_vbroadcast`\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:95 within `macro expansion`\n            %ie.i108 = insertelement &lt;4 x double&gt; undef, double %arrayref33, i64 0\n            %v.i109 = shufflevector &lt;4 x double&gt; %ie.i108, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n; ││││└└└└└└\n; ││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:95 within `sub_fast`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:116 within `vsub_fast`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:116 within `macro expansion`\n        %res.i110 = fsub reassoc nsz arcp contract afn &lt;4 x double&gt; %res.i107, %v.i109\n; │││└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:498 within `vfnmadd_fast`\n; ││││┌ @ fastmath.jl:161 within `sub_fast`\n       %18 = fneg fast double %arrayref28\n; ││││└\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:493 within `vfmadd_fast`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:392 within `vmuladd_fast`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/VectorizationBase.jl:100 within `promote`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:199 within `convert`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:191 within `vconvert`\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:151 within `vbroadcast`\n; ││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:122 within `_vbroadcast`\n; │││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:95 within `macro expansion`\n              %ie.i111 = insertelement &lt;4 x double&gt; undef, double %18, i64 0\n              %v.i112 = shufflevector &lt;4 x double&gt; %ie.i111, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n; ││││││└└└└└└\n; ││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:393 within `vmuladd_fast` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:438\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:438 within `macro expansion`\n         %res.i113 = call reassoc nsz arcp contract afn &lt;4 x double&gt; @llvm.fmuladd.v4f64(&lt;4 x double&gt; %v.i112, &lt;4 x double&gt; %res.i101, &lt;4 x double&gt; %res.i110)\n; ││││└└└\n; ││││┌ @ fastmath.jl:161 within `sub_fast`\n       %19 = fneg fast double %arrayref\n; ││││└\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:493 within `vfmadd_fast`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:392 within `vmuladd_fast`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/VectorizationBase.jl:100 within `promote`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:199 within `convert`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:191 within `vconvert`\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:151 within `vbroadcast`\n; ││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:122 within `_vbroadcast`\n; │││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:95 within `macro expansion`\n              %ie.i114 = insertelement &lt;4 x double&gt; undef, double %19, i64 0\n              %v.i115 = shufflevector &lt;4 x double&gt; %ie.i114, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n; ││││││││└└└└\n; ││││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:203 within `convert`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:140 within `vconvert`\n; │││││││││┌ @ number.jl:7 within `convert`\n; ││││││││││┌ @ float.jl:159 within `Float64`\n             %20 = sitofp i64 %value_phi35.lcssa to double\n; │││││││││└└\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:72 within `vrangeincr`\n; ││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:94 within `macro expansion`\n             %ie.i116 = insertelement &lt;4 x double&gt; undef, double %20, i64 0\n             %v.i117 = shufflevector &lt;4 x double&gt; %ie.i116, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n             %res.i118 = fadd fast &lt;4 x double&gt; %v.i117, &lt;double 0.000000e+00, double 1.000000e+00, double 2.000000e+00, double 3.000000e+00&gt;\n; ││││││└└└└└\n; ││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:393 within `vmuladd_fast` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:438\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:438 within `macro expansion`\n         %res.i119 = call reassoc nsz arcp contract afn &lt;4 x double&gt; @llvm.fmuladd.v4f64(&lt;4 x double&gt; %v.i115, &lt;4 x double&gt; %res.i118, &lt;4 x double&gt; %res.i113)\n; │││└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:212 within `_vstore!`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:1667 within `__vstore!`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:1667 within `macro expansion`\n        %ptr.1.i122229 = getelementptr inbounds double, double* %ptr.1.i37, i64 %value_phi35.lcssa\n        %ptr.2.i123 = bitcast double* %ptr.1.i122229 to &lt;4 x double&gt;*\n        call void @llvm.masked.store.v4f64.p0v4f64(&lt;4 x double&gt; %res.i119, &lt;4 x double&gt;* nonnull %ptr.2.i123, i32 8, &lt;4 x i1&gt; %m.i)\n; │││└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/static.jl:53 within `vadd_nsw` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49 within `macro expansion`\n       br label %L233\n\nL165:                                             ; preds = %L136\n; │││└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/static.jl:55 within `vsub_nsw` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49 within `macro expansion`\n       %res.i125 = add nsw i64 %arraylen, -8\n; │││└└\n; │││┌ @ operators.jl:378 within `&gt;`\n; ││││┌ @ int.jl:83 within `&lt;`\n       %.not230 = icmp slt i64 %res.i125, %value_phi35.lcssa\n; │││└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:788 within `_vload`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:659 within `_vload_unroll`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:60 within `macro expansion`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:436 within `gep`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:414 within `_gep`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:414 within `macro expansion`\n           %ptr.1.i126 = getelementptr inbounds double, double* %ptr.1.i, i64 %value_phi35.lcssa\n; ││││││└└└\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:95 within `_vload`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:987 within `__vload`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:987 within `macro expansion`\n           %ptr.1.i128 = bitcast double* %ptr.1.i126 to &lt;4 x double&gt;*\n           %res.i129 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %ptr.1.i128, align 8\n; │││││││└└\n; │││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl within `_vload`\n         %ptr.1.i130 = getelementptr inbounds double, double* %ptr.1.i126, i64 4\n         %ptr.2.i131 = bitcast double* %ptr.1.i130 to &lt;4 x double&gt;*\n; │││└└└└\n     br i1 %.not230, label %L168, label %L196\n\nL168:                                             ; preds = %L165\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:788 within `_vload`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:659 within `_vload_unroll`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:60 within `macro expansion`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:105 within `_vload`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:997 within `__vload`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:997 within `macro expansion`\n           %res.i132 = call &lt;4 x double&gt; @llvm.masked.load.v4f64.p0v4f64(&lt;4 x double&gt;* nonnull %ptr.2.i131, i32 8, &lt;4 x i1&gt; %m.i, &lt;4 x double&gt; zeroinitializer)\n; │││└└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/static.jl:55 within `vadd_nsw` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49 within `macro expansion`\n       %res.i133 = or i64 %value_phi35.lcssa, 1\n; │││└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:788 within `_vload`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:659 within `_vload_unroll`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:60 within `macro expansion`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:436 within `gep`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:414 within `_gep`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:414 within `macro expansion`\n           %ptr.1.i134 = getelementptr inbounds double, double* %ptr.1.i, i64 %res.i133\n; ││││││└└└\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:95 within `_vload`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:987 within `__vload`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:987 within `macro expansion`\n           %ptr.1.i136 = bitcast double* %ptr.1.i134 to &lt;4 x double&gt;*\n           %res.i137 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %ptr.1.i136, align 8\n; │││││││└└\n; │││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:105 within `_vload`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:997 within `__vload`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:997 within `macro expansion`\n           %ptr.1.i138 = getelementptr inbounds double, double* %ptr.1.i134, i64 4\n           %ptr.2.i139 = bitcast double* %ptr.1.i138 to &lt;4 x double&gt;*\n           %res.i140 = call &lt;4 x double&gt; @llvm.masked.load.v4f64.p0v4f64(&lt;4 x double&gt;* nonnull %ptr.2.i139, i32 8, &lt;4 x i1&gt; %m.i, &lt;4 x double&gt; zeroinitializer)\n; │││└└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:98 within `sub_fast`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/VectorizationBase.jl:96 within `promote`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:199 within `convert`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:242 within `vconvert` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:191\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:151 within `vbroadcast`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:122 within `_vbroadcast`\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:95 within `macro expansion`\n            %ie.i141 = insertelement &lt;4 x double&gt; undef, double %arrayref33, i64 0\n            %v.i142 = shufflevector &lt;4 x double&gt; %ie.i141, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n; ││││└└└└└└\n; ││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:99 within `sub_fast`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:111 within `vsub_fast`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:11 within `fmap`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:116 within `vsub_fast`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:116 within `macro expansion`\n          %res.i143 = fsub reassoc nsz arcp contract afn &lt;4 x double&gt; %res.i137, %v.i142\n; ││││││└└\n; ││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:11 within `fmap` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:7\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:116 within `vsub_fast`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:116 within `macro expansion`\n          %res.i144 = fsub reassoc nsz arcp contract afn &lt;4 x double&gt; %res.i140, %v.i142\n; │││└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:498 within `vfnmadd_fast`\n; ││││┌ @ fastmath.jl:161 within `sub_fast`\n       %21 = fneg fast double %arrayref28\n; ││││└\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:493 within `vfmadd_fast`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:392 within `vmuladd_fast`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/VectorizationBase.jl:100 within `promote`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:199 within `convert`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:242 within `vconvert` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:191\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:151 within `vbroadcast`\n; ││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:122 within `_vbroadcast`\n; │││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:95 within `macro expansion`\n              %ie.i145 = insertelement &lt;4 x double&gt; undef, double %21, i64 0\n              %v.i146 = shufflevector &lt;4 x double&gt; %ie.i145, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n; ││││││└└└└└└\n; ││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:393 within `vmuladd_fast` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:233\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:25 within `fmap`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:25 within `macro expansion`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:438 within `vmuladd_fast`\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:438 within `macro expansion`\n            %res.i147 = call reassoc nsz arcp contract afn &lt;4 x double&gt; @llvm.fmuladd.v4f64(&lt;4 x double&gt; %v.i146, &lt;4 x double&gt; %res.i129, &lt;4 x double&gt; %res.i143)\n            %res.i148 = call reassoc nsz arcp contract afn &lt;4 x double&gt; @llvm.fmuladd.v4f64(&lt;4 x double&gt; %v.i146, &lt;4 x double&gt; %res.i132, &lt;4 x double&gt; %res.i144)\n; │││└└└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vector_width.jl:45 within `vadd_nsw` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/static.jl:53 @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49 within `macro expansion`\n       %res.i149 = add nuw nsw i64 %value_phi35.lcssa, 4\n; │││└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:498 within `vfnmadd_fast`\n; ││││┌ @ fastmath.jl:161 within `sub_fast`\n       %22 = fneg fast double %arrayref\n; ││││└\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:493 within `vfmadd_fast`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:392 within `vmuladd_fast`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/VectorizationBase.jl:100 within `promote`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:199 within `convert`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:242 within `vconvert` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:191\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:151 within `vbroadcast`\n; ││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:122 within `_vbroadcast`\n; │││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:95 within `macro expansion`\n              %ie.i150 = insertelement &lt;4 x double&gt; undef, double %22, i64 0\n              %v.i151 = shufflevector &lt;4 x double&gt; %ie.i150, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n; ││││││││└└└└\n; ││││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:203 within `convert`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:254 within `vconvert`\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:18 within `fmap`\n; ││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:140 within `vconvert`\n; │││││││││││┌ @ number.jl:7 within `convert`\n; ││││││││││││┌ @ float.jl:159 within `Float64`\n               %23 = sitofp i64 %value_phi35.lcssa to double\n; │││││││││││└└\n; │││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:72 within `vrangeincr`\n; ││││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:94 within `macro expansion`\n               %ie.i152 = insertelement &lt;4 x double&gt; undef, double %23, i64 0\n               %v.i153 = shufflevector &lt;4 x double&gt; %ie.i152, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n               %res.i154 = fadd fast &lt;4 x double&gt; %v.i153, &lt;double 0.000000e+00, double 1.000000e+00, double 2.000000e+00, double 3.000000e+00&gt;\n; ││││││││││└└└\n; ││││││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:18 within `fmap` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:10\n; ││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:140 within `vconvert`\n; │││││││││││┌ @ number.jl:7 within `convert`\n; ││││││││││││┌ @ float.jl:159 within `Float64`\n               %24 = sitofp i64 %res.i149 to double\n; │││││││││││└└\n; │││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:72 within `vrangeincr`\n; ││││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:94 within `macro expansion`\n               %ie.i155 = insertelement &lt;4 x double&gt; undef, double %24, i64 0\n               %v.i156 = shufflevector &lt;4 x double&gt; %ie.i155, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n               %res.i157 = fadd fast &lt;4 x double&gt; %v.i156, &lt;double 0.000000e+00, double 1.000000e+00, double 2.000000e+00, double 3.000000e+00&gt;\n; ││││││└└└└└└└\n; ││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:393 within `vmuladd_fast` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:233\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:25 within `fmap`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:25 within `macro expansion`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:438 within `vmuladd_fast`\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:438 within `macro expansion`\n            %res.i158 = call reassoc nsz arcp contract afn &lt;4 x double&gt; @llvm.fmuladd.v4f64(&lt;4 x double&gt; %v.i151, &lt;4 x double&gt; %res.i154, &lt;4 x double&gt; %res.i147)\n            %res.i159 = call reassoc nsz arcp contract afn &lt;4 x double&gt; @llvm.fmuladd.v4f64(&lt;4 x double&gt; %v.i151, &lt;4 x double&gt; %res.i157, &lt;4 x double&gt; %res.i148)\n; │││└└└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:1826 within `_vstore!`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:1473 within `_vstore_unroll!`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:870 within `macro expansion`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:436 within `gep`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:414 within `_gep`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:414 within `macro expansion`\n           %ptr.1.i160 = getelementptr inbounds double, double* %ptr.1.i37, i64 %value_phi35.lcssa\n; ││││││└└└\n; ││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:872 within `macro expansion`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:199 within `_vstore!`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:1482 within `__vstore!`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:1482 within `macro expansion`\n           %ptr.1.i162 = bitcast double* %ptr.1.i160 to &lt;4 x double&gt;*\n           store &lt;4 x double&gt; %res.i158, &lt;4 x double&gt;* %ptr.1.i162, align 8\n; │││││││└└\n; │││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:212 within `_vstore!`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:1667 within `__vstore!`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:1667 within `macro expansion`\n           %ptr.1.i163 = getelementptr inbounds double, double* %ptr.1.i160, i64 4\n           %ptr.2.i164 = bitcast double* %ptr.1.i163 to &lt;4 x double&gt;*\n           call void @llvm.masked.store.v4f64.p0v4f64(&lt;4 x double&gt; %res.i159, &lt;4 x double&gt;* nonnull %ptr.2.i164, i32 8, &lt;4 x i1&gt; %m.i)\n; │││└└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/static.jl:53 within `vadd_nsw` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49 within `macro expansion`\n       br label %L233\n\nL196:                                             ; preds = %L165\n; │││└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:788 within `_vload`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:659 within `_vload_unroll`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:60 within `macro expansion`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:95 within `_vload`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:987 within `__vload`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:987 within `macro expansion`\n           %res.i172 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %ptr.2.i131, align 8\n; │││││││└└\n; │││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:105 within `_vload`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:997 within `__vload`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:997 within `macro expansion`\n           %ptr.1.i173 = getelementptr inbounds double, double* %ptr.1.i126, i64 8\n           %ptr.2.i174 = bitcast double* %ptr.1.i173 to &lt;4 x double&gt;*\n           %res.i175 = call &lt;4 x double&gt; @llvm.masked.load.v4f64.p0v4f64(&lt;4 x double&gt;* nonnull %ptr.2.i174, i32 8, &lt;4 x i1&gt; %m.i, &lt;4 x double&gt; zeroinitializer)\n; │││└└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/static.jl:55 within `vadd_nsw` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49 within `macro expansion`\n       %res.i176 = or i64 %value_phi35.lcssa, 1\n; │││└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:788 within `_vload`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:659 within `_vload_unroll`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:60 within `macro expansion`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:436 within `gep`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:414 within `_gep`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:414 within `macro expansion`\n           %ptr.1.i177 = getelementptr inbounds double, double* %ptr.1.i, i64 %res.i176\n; ││││││└└└\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:95 within `_vload`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:987 within `__vload`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:987 within `macro expansion`\n           %ptr.1.i179 = bitcast double* %ptr.1.i177 to &lt;4 x double&gt;*\n           %res.i180 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %ptr.1.i179, align 8\n           %ptr.1.i181 = getelementptr inbounds double, double* %ptr.1.i177, i64 4\n           %ptr.2.i182 = bitcast double* %ptr.1.i181 to &lt;4 x double&gt;*\n           %res.i183 = load &lt;4 x double&gt;, &lt;4 x double&gt;* %ptr.2.i182, align 8\n; │││││││└└\n; │││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:105 within `_vload`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:997 within `__vload`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:997 within `macro expansion`\n           %ptr.1.i184 = getelementptr inbounds double, double* %ptr.1.i177, i64 8\n           %ptr.2.i185 = bitcast double* %ptr.1.i184 to &lt;4 x double&gt;*\n           %res.i186 = call &lt;4 x double&gt; @llvm.masked.load.v4f64.p0v4f64(&lt;4 x double&gt;* nonnull %ptr.2.i185, i32 8, &lt;4 x i1&gt; %m.i, &lt;4 x double&gt; zeroinitializer)\n; │││└└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:98 within `sub_fast`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/VectorizationBase.jl:96 within `promote`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:199 within `convert`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:242 within `vconvert` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:191\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:151 within `vbroadcast`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:122 within `_vbroadcast`\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:95 within `macro expansion`\n            %ie.i187 = insertelement &lt;4 x double&gt; undef, double %arrayref33, i64 0\n            %v.i188 = shufflevector &lt;4 x double&gt; %ie.i187, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n; ││││└└└└└└\n; ││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:99 within `sub_fast`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:111 within `vsub_fast`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:11 within `fmap`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:116 within `vsub_fast`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:116 within `macro expansion`\n          %res.i189 = fsub reassoc nsz arcp contract afn &lt;4 x double&gt; %res.i180, %v.i188\n; ││││││└└\n; ││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:11 within `fmap` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:11\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:116 within `vsub_fast`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:116 within `macro expansion`\n          %res.i190 = fsub reassoc nsz arcp contract afn &lt;4 x double&gt; %res.i183, %v.i188\n; ││││││└└\n; ││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:11 within `fmap` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:11 @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:7\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:116 within `vsub_fast`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:116 within `macro expansion`\n          %res.i191 = fsub reassoc nsz arcp contract afn &lt;4 x double&gt; %res.i186, %v.i188\n; │││└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:498 within `vfnmadd_fast`\n; ││││┌ @ fastmath.jl:161 within `sub_fast`\n       %25 = fneg fast double %arrayref28\n; ││││└\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:493 within `vfmadd_fast`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:392 within `vmuladd_fast`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/VectorizationBase.jl:100 within `promote`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:199 within `convert`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:242 within `vconvert` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:191\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:151 within `vbroadcast`\n; ││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:122 within `_vbroadcast`\n; │││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:95 within `macro expansion`\n              %ie.i192 = insertelement &lt;4 x double&gt; undef, double %25, i64 0\n              %v.i193 = shufflevector &lt;4 x double&gt; %ie.i192, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n; ││││││└└└└└└\n; ││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:393 within `vmuladd_fast` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:233\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:25 within `fmap`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:25 within `macro expansion`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:438 within `vmuladd_fast`\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:438 within `macro expansion`\n            %res.i194 = call reassoc nsz arcp contract afn &lt;4 x double&gt; @llvm.fmuladd.v4f64(&lt;4 x double&gt; %v.i193, &lt;4 x double&gt; %res.i129, &lt;4 x double&gt; %res.i189)\n            %res.i195 = call reassoc nsz arcp contract afn &lt;4 x double&gt; @llvm.fmuladd.v4f64(&lt;4 x double&gt; %v.i193, &lt;4 x double&gt; %res.i172, &lt;4 x double&gt; %res.i190)\n            %res.i196 = call reassoc nsz arcp contract afn &lt;4 x double&gt; @llvm.fmuladd.v4f64(&lt;4 x double&gt; %v.i193, &lt;4 x double&gt; %res.i175, &lt;4 x double&gt; %res.i191)\n; │││└└└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vector_width.jl:45 within `vadd_nsw` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/static.jl:53 @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49 within `macro expansion`\n       %res.i197 = add nuw nsw i64 %value_phi35.lcssa, 4\n       %res.i198 = add nuw nsw i64 %value_phi35.lcssa, 8\n; │││└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:498 within `vfnmadd_fast`\n; ││││┌ @ fastmath.jl:161 within `sub_fast`\n       %26 = fneg fast double %arrayref\n; ││││└\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:493 within `vfmadd_fast`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:392 within `vmuladd_fast`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/VectorizationBase.jl:100 within `promote`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:199 within `convert`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:242 within `vconvert` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:191\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:151 within `vbroadcast`\n; ││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:122 within `_vbroadcast`\n; │││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/vbroadcast.jl:95 within `macro expansion`\n              %ie.i199 = insertelement &lt;4 x double&gt; undef, double %26, i64 0\n              %v.i200 = shufflevector &lt;4 x double&gt; %ie.i199, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n; ││││││││└└└└\n; ││││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:203 within `convert`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/conversion.jl:254 within `vconvert`\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:18 within `fmap`\n; ││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:140 within `vconvert`\n; │││││││││││┌ @ number.jl:7 within `convert`\n; ││││││││││││┌ @ float.jl:159 within `Float64`\n               %27 = sitofp i64 %value_phi35.lcssa to double\n; │││││││││││└└\n; │││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:72 within `vrangeincr`\n; ││││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:94 within `macro expansion`\n               %ie.i201 = insertelement &lt;4 x double&gt; undef, double %27, i64 0\n               %v.i202 = shufflevector &lt;4 x double&gt; %ie.i201, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n               %res.i203 = fadd fast &lt;4 x double&gt; %v.i202, &lt;double 0.000000e+00, double 1.000000e+00, double 2.000000e+00, double 3.000000e+00&gt;\n; ││││││││││└└└\n; ││││││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:18 within `fmap` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:18\n; ││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:140 within `vconvert`\n; │││││││││││┌ @ number.jl:7 within `convert`\n; ││││││││││││┌ @ float.jl:159 within `Float64`\n               %28 = sitofp i64 %res.i197 to double\n; │││││││││││└└\n; │││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:72 within `vrangeincr`\n; ││││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:94 within `macro expansion`\n               %ie.i204 = insertelement &lt;4 x double&gt; undef, double %28, i64 0\n               %v.i205 = shufflevector &lt;4 x double&gt; %ie.i204, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n               %res.i206 = fadd fast &lt;4 x double&gt; %v.i205, &lt;double 0.000000e+00, double 1.000000e+00, double 2.000000e+00, double 3.000000e+00&gt;\n; ││││││││││└└└\n; ││││││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:18 within `fmap` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:18 @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:10\n; ││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:140 within `vconvert`\n; │││││││││││┌ @ number.jl:7 within `convert`\n; ││││││││││││┌ @ float.jl:159 within `Float64`\n               %29 = sitofp i64 %res.i198 to double\n; │││││││││││└└\n; │││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:72 within `vrangeincr`\n; ││││││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/ranges.jl:94 within `macro expansion`\n               %ie.i207 = insertelement &lt;4 x double&gt; undef, double %29, i64 0\n               %v.i208 = shufflevector &lt;4 x double&gt; %ie.i207, &lt;4 x double&gt; undef, &lt;4 x i32&gt; zeroinitializer\n               %res.i209 = fadd fast &lt;4 x double&gt; %v.i208, &lt;double 0.000000e+00, double 1.000000e+00, double 2.000000e+00, double 3.000000e+00&gt;\n; ││││││└└└└└└└\n; ││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/base_defs.jl:393 within `vmuladd_fast` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:233\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:25 within `fmap`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/fmap.jl:25 within `macro expansion`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:438 within `vmuladd_fast`\n; │││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/intrin_funcs.jl:438 within `macro expansion`\n            %res.i210 = call reassoc nsz arcp contract afn &lt;4 x double&gt; @llvm.fmuladd.v4f64(&lt;4 x double&gt; %v.i200, &lt;4 x double&gt; %res.i203, &lt;4 x double&gt; %res.i194)\n            %res.i211 = call reassoc nsz arcp contract afn &lt;4 x double&gt; @llvm.fmuladd.v4f64(&lt;4 x double&gt; %v.i200, &lt;4 x double&gt; %res.i206, &lt;4 x double&gt; %res.i195)\n            %res.i212 = call reassoc nsz arcp contract afn &lt;4 x double&gt; @llvm.fmuladd.v4f64(&lt;4 x double&gt; %v.i200, &lt;4 x double&gt; %res.i209, &lt;4 x double&gt; %res.i196)\n; │││└└└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:1826 within `_vstore!`\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:1473 within `_vstore_unroll!`\n; │││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:870 within `macro expansion`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:436 within `gep`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:414 within `_gep`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:414 within `macro expansion`\n           %ptr.1.i213 = getelementptr inbounds double, double* %ptr.1.i37, i64 %value_phi35.lcssa\n; ││││││└└└\n; ││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/vecunroll/memory.jl:872 within `macro expansion`\n; ││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:199 within `_vstore!`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:1482 within `__vstore!`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:1482 within `macro expansion`\n           %ptr.1.i215 = bitcast double* %ptr.1.i213 to &lt;4 x double&gt;*\n           store &lt;4 x double&gt; %res.i210, &lt;4 x double&gt;* %ptr.1.i215, align 8\n           %ptr.1.i216 = getelementptr inbounds double, double* %ptr.1.i213, i64 4\n           %ptr.2.i217 = bitcast double* %ptr.1.i216 to &lt;4 x double&gt;*\n           store &lt;4 x double&gt; %res.i211, &lt;4 x double&gt;* %ptr.2.i217, align 8\n; │││││││└└\n; │││││││ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/strided_pointers/stridedpointers.jl:212 within `_vstore!`\n; │││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:1667 within `__vstore!`\n; ││││││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/memory_addr.jl:1667 within `macro expansion`\n           %ptr.1.i218 = getelementptr inbounds double, double* %ptr.1.i213, i64 8\n           %ptr.2.i219 = bitcast double* %ptr.1.i218 to &lt;4 x double&gt;*\n           call void @llvm.masked.store.v4f64.p0v4f64(&lt;4 x double&gt; %res.i212, &lt;4 x double&gt;* nonnull %ptr.2.i219, i32 8, &lt;4 x i1&gt; %m.i)\n; │││└└└└└└\n; │││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/static.jl:53 within `vadd_nsw` @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49\n; ││││┌ @ /home/paul/.julia/packages/VectorizationBase/6AO0m/src/llvm_intrin/binary_ops.jl:49 within `macro expansion`\n       br label %L233\n\nL233:                                             ; preds = %L196, %L168, %L146, %L134\n; │└└└└\n   ret {}* inttoptr (i64 131694430519304 to {}*)\n; └\n}\n\n\n\n@benchmark resids_turbo!($e,$y,$θ)\n\n\nBenchmarkTools.Trial: 10000 samples with 246 evaluations.\n Range (min … max):  307.907 ns … 482.476 ns  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     308.630 ns               ┊ GC (median):    0.00%\n Time  (mean ± σ):   310.946 ns ±  10.193 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n  █▇                     ▂▃▂                                    ▁\n  ██▁▄▁▁▁▁▁▁▁▆▇▇▆▁▃▄▅▅▅▆▇███▆▅▄▅▅▃▃▃▆▇██▇▁▃▁▃▁▁▄▁▁▃▁▅▆▃▄▁▄▄▄▃▃▅ █\n  308 ns        Histogram: log(frequency) by time        358 ns &lt;\n Memory estimate: 0 bytes, allocs estimate: 0."
  },
  {
    "objectID": "westdri_talk.html#example-manual-simd",
    "href": "westdri_talk.html#example-manual-simd",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "Example: Manual SIMD",
    "text": "Example: Manual SIMD\n\noneto(::Val{1}) = (1,)\noneto(::Val{N}) where N = (oneto(Val(N-1))..., N)\n\nfunction resids_simd!(e,yin, θ, width::Val{N}=Val(8)) where N\n  lane = VecRange{N}(0)\n  tv=Vec{N,Float64}(oneto(Val(N)))\n  θ1=-Vec{N,Float64}(θ[1])\n  θ2=-Vec{N,Float64}(θ[2])\n  θ3=-Vec{N,Float64}(θ[3])\n  remainder = length(e) % N\n  @inbounds for t ∈ 1:N:(length(e)-remainder) #eachindex(e)\n    @fastmath e[t+lane] = muladd(θ2,tv,yin[t+1+lane])+muladd(θ3,yin[t+lane],θ1)\n    @fastmath tv+=N\n  end\n  @inbounds for t ∈ (length(e)-remainder+1):length(e)\n    @fastmath e[t] = muladd(-θ[2],t+1,yin[t+1])-muladd(θ[3],yin[t],θ[1])\n  end\n  nothing\nend\n\n@benchmark resids_simd!($e,$y,$θ)\n\n\nBenchmarkTools.Trial: 10000 samples with 355 evaluations.\n Range (min … max):  255.042 ns … 438.270 ns  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     259.592 ns               ┊ GC (median):    0.00%\n Time  (mean ± σ):   261.000 ns ±   7.531 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n  ▄▇    ▇█   ▆▅             ▁     ▃    ▁                        ▂\n  ██▇▇▅███▇▆▇██▅▅▆▅▇█▇▇▆▅▇▆▇█▇▇▇▇▇██▆▆▄█▄▅▅▃▁▄▃▅▇▄▁▁▁▅▁▃▄▄▄▁▃▄▆ █\n  255 ns        Histogram: log(frequency) by time        294 ns &lt;\n Memory estimate: 0 bytes, allocs estimate: 0."
  },
  {
    "objectID": "westdri_talk.html#example-necessary-manual-simd",
    "href": "westdri_talk.html#example-necessary-manual-simd",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "Example: Necessary Manual SIMD",
    "text": "Example: Necessary Manual SIMD\n\n\n\nfunction xx_xy!(xx,xy,yin)\n  T = length(yin)\n  xx .= zero(eltype(xx))\n  xy .= zero(eltype(xy))\n  @inbounds @fastmath @simd for t in 2:T # @turbo errors\n    xx[1,3] += yin[t-1]\n    xx[2,3] += t*yin[t-1]\n    xx[3,3] += yin[t-1]^2\n    xy[1] += yin[t]\n    xy[2] += t*yin[t]\n    xy[3] += yin[t-1]*yin[t]\n  end\n  xx[1,1] = T-1 # = 1'*1\n  xx[1,2] = xx[2,1] = (T+1)*T/2 - 1 # sum(p+1:T)\n  xx[2,2] = (2*(T)+1)*(T)*(T+1)/6 - 1 # sum((p+1:T).^2)\n  xx[3,1] = xx[1,3]\n  xx[3,2] = xx[2,3]\n  nothing\nend\n\nxx = @MMatrix zeros(3,3)\nxy = @MVector zeros(3)\n@benchmark xx_xy!($xx,$xy,$y)\n\n\nBenchmarkTools.Trial: 10000 samples with 9 evaluations.\n Range (min … max):  2.850 μs …   7.443 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     2.854 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   2.879 μs ± 191.574 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n  █                  ▂                                        ▁\n  █▆▆▁▁▁▁▁▁▁▁▃▁▁▁▁▃▁▁█▄▄▁▃▁▁▁▁▄▄█▄▁▁▃▁▁▃▃▃▃▃▁▃▁▁▃▁▄▃▃▃▄▅▃▄▄▄▄ █\n  2.85 μs      Histogram: log(frequency) by time       3.4 μs &lt;\n Memory estimate: 0 bytes, allocs estimate: 0.\n\n\n\n\n\nfunction xx_xy_simd!(xx,xy,yin, v::Val{N}=Val(32)) where {N}\n  T = length(yin)\n  remainder=(T-1) % N\n  xx .= zero(eltype(xx))\n  xy .= zero(eltype(xy))\n  tv = Vec{N,eltype(yin)}(oneto(Val(N)))+1\n  lane = VecRange{N}(0)\n  @inbounds for t in 2:N:(T-remainder)\n    xx[1,3] += sum(yin[t-1+lane])\n    xx[2,3] += sum(yin[t-1+lane]*tv)\n    xx[3,3] += sum(yin[t-1+lane]^2)\n    xy[1] += sum(yin[t+lane])\n    xy[2] += sum(tv*yin[t+lane])\n    xy[3] += sum(yin[t-1+lane]*yin[t+lane])\n    tv += N\n  end\n  @inbounds for t in (T-remainder+1):T\n    xx[1,3] += yin[t-1]\n    xx[2,3] += yin[t-1]*t\n    xx[3,3] += yin[t-1]^2\n    xy[1] += yin[t]\n    xy[2] += t*yin[t]\n    xy[3] += yin[t-1]*yin[t]\n  end\n  xx[1,1] = T-1 # = 1'*1\n  xx[1,2] = xx[2,1] = (T+1)*T/2 - 1 # sum(2:T)\n  xx[2,2] = (2*(T)+1)*(T)*(T+1)/6 - 1 # sum((2:T).^2)\n  xx[3,1] = xx[1,3]\n  xx[3,2] = xx[2,3]\n  nothing\nend\n\n@benchmark xx_xy_simd!($xx,$xy,$y)\n\n\nBenchmarkTools.Trial: 10000 samples with 63 evaluations.\n Range (min … max):  857.698 ns …  3.089 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     868.302 ns              ┊ GC (median):    0.00%\n Time  (mean ± σ):   871.853 ns ± 33.408 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n  ▁▅▆▆█▇█▇▃                          ▁▁▁                       ▂\n  █████████▃▁▁▁▃▄▁▁▁▃▄▄▁▅▅▆▆▇▇▆▅▄▅▇█████▇▄▄▃▄▅▄▅▄▄▆▅▆▇▆▆▆▅▃▄▄▄ █\n  858 ns        Histogram: log(frequency) by time       965 ns &lt;\n Memory estimate: 0 bytes, allocs estimate: 0."
  },
  {
    "objectID": "westdri_talk.html#references",
    "href": "westdri_talk.html#references",
    "title": "Julia at Full Tilt: Profiling and Optimizations",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nNissen, Jakob Nybo. 2022. “How to Optimise Julia Code: A Practical Guide.” https://viralinstruction.com/posts/optimise/#how_to_optimise_julia_code_a_practical_guide.\n\n\nRackauckas, Chris. 2019. “Optimizing Serial Code.” https://book.sciml.ai/notes/02-Optimizing_Serial_Code/.\n\n\nSchrimpf, Paul. 2019 (revised 2024). “Coding for Performance.” https://schrimpf.github.io/ARGridBootstrap.jl/argridboot.html."
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "ARGridBootstrap",
    "section": "",
    "text": "The notes and examples are licensed under a Creative Commons Attribution-ShareAlike 4.0 International License and were written by Paul Schrimpf.\n\nBibTeX citation.\nThe license for the package source code is here."
  },
  {
    "objectID": "gpu.html",
    "href": "gpu.html",
    "title": "Coding for Performance",
    "section": "",
    "text": "This is"
  },
  {
    "objectID": "gpu.html#array-interface",
    "href": "gpu.html#array-interface",
    "title": "Coding for Performance",
    "section": "Array interface",
    "text": "Array interface\nThe easiest way to use a GPU in Julia is through a high level array interface. ArrayFire.jl, oneAPI.jl, and CUDA.jl each offer such interfaces. We will focus on CUDA.jl in these notes. CUDA.jl relies on Nvidia’s CUDA platform, so it only works with Nvidia GPUs. Nvidia tends to dominate GPGPU, and the GPUs available on cedar.computecanada.ca and in my desktop are Nvidia.\nUsing CUDA.CuArray is simple, but has some limitations. You create arrays on the GPU using CuArray. Any array level operation on these will then be performed efficiently on the GPU. This includes broadcast functions with . and matrix multiplies.\nusing CUDA, Random, BenchmarkTools\n\n\nN = 1000\nM = 1000\n\nfunction cuarraydemo(N,M)\n  # wrapped in a  function so that the CuArrays are freed\n  # otherwise we will run out GPU memory later\n  A = randn(N,M);\n  b = randn(M,2);\n  println(\"Time on CPU\")\n  function foo(A,b)\n    (A.^2)*b\n  end\n  @time c=foo(A,b);\n  @time c=foo(A,b);\n  A_gpu = CuArray(A); # copy of A in GPU memory\n  b_gpu = CuArray(b);\n  println(\"Computations on the GPU are fast\")\n  # @btime does not work inside a function\n  @time CUDA.@sync c_gpu=foo(A_gpu,b_gpu);\n  @time CUDA.@sync c_gpu=foo(A_gpu,b_gpu);\n  println(\"But copying to and from GPU memory is not\")\n  bar(A,b) =Array(foo(CuArray(A), CuArray(b)))\n  @time c2=bar(A,b);\n  @time c2=bar(A,b);\nend\ncuarraydemo (generic function with 1 method)\njulia&gt; cuarraydemo(N,M);\nTime on CPU\n  0.006783 seconds (3 allocations: 7.645 MiB)\n  0.004896 seconds (3 allocations: 7.645 MiB)\nComputations on the GPU are fast\n  0.000337 seconds (80 allocations: 3.125 KiB)\n  0.000214 seconds (80 allocations: 3.125 KiB)\nBut copying to and from GPU memory is not\n  0.001448 seconds (102 allocations: 19.578 KiB)\n  0.001112 seconds (102 allocations: 19.578 KiB)\nCuArrays also allow indexing, so you could use loops and other constructs. However, this will not be fast. CuArrays by itself will be a good method to utilize GPUs when the code is dominated by operations on large arrays.\nUnfortunately, the fastest version of our grid bootstrap code does not fit that description. A loop seems needed to generate \\(y\\) due to the recursiveness of the AR(1) model. The fastest version of the code above involves many operations on small 3x3 arrays.\nEXERCISE: modify b_est_original or b_est_mldivide to utilize CuArrays. The approach taken in those functions involves some moderate sized matrices, so it may benefit from CuArrays."
  },
  {
    "objectID": "gpu.html#custom-cuda-kernels",
    "href": "gpu.html#custom-cuda-kernels",
    "title": "Coding for Performance",
    "section": "Custom CUDA Kernels",
    "text": "Custom CUDA Kernels\nTo parallelize the code above on a GPU, we will have to use a lower level interface to the GPU. To explain how it works, we will begin with a simple example that just squares all the elements of an array.\nDisclaimer: my understanding of CUDA and the inner workings of GPUs is far from complete. Some of the details in this section might be inaccurate.\nA typical workflow with CUDA consists of\n\nAllocate GPU memory and copying arrays into it with CuArray.\nDecide how many threads and what configuration of threads to launch.\nEach thread does some computation by running a “kernel” function.\nCopy result from GPU memory to CPU memory.\n\nIn the code below, 1 happens in cuarray_cudanative_compare, 2 happens in the square! function, square_kernel! is the kernel in 3, and 4 is just not done.\n\nThreads and blocks\nCUDA organizes GPU threads into blocks. I believe that the threads in a block all execute concurrently. Threads in the same block share some memory and registers. All current Nvidia GPUs have a maximum number of threads per block of 1024. Note that threads in the same block share registers1, and different kernel functions will use different numbers of registers at once, so depending on the kernel function, you might be limited to fewer than 1024 threads per block. The number of registers available per block depends on your GPU. You can check your GPU characteristics by compiling and running the C++ program in $CUDA_PATH/samples/1_Utilities/deviceQuery/. Alternatively, you can see this information in Julia by running the code below.\nprintln(\"Maximum threads per block $(attribute(device(), CUDA.CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK))\")\nprintln(\"Maximum x blocks $(attribute(device(), CUDA.CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_X))\")\nprintln(\"Maximum registers per block $(attribute(device(), CUDA.CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_BLOCK))\")\nMaximum threads per block 1024\nMaximum x blocks 2147483647\nMaximum registers per block 65536\nThere is no simple way to predict how many registers a kernel function uses. It will depend both on the code you write and how the compiler optimizes the code. If you encounter cryptic error messages about CUDA resources unavailable, then try reducing the number of threads per block. Alternatively, you can limit the number of registers used by passing the maxregs argument to @cuda.\nYou can execute more than 1024 threads by specifying a number of blocks. There is also a limit to the number of blocks, but it is rather large. In the code below, we set the number of blocks, so that nblocks*nthreads &gt;= length(A). Each thread then operates on a single element of A. When the code is executed, each thread has a unique threadIdx and blockIdx combination, and these are used to assign threads to elements of A. The indices go from 1 to number of threads (or blocks). For convenience you can request threads and blocks to have up 3 dimensions, and there are threadIdx().y and threadIdx().z for the additional dimensions.\nfunction square!(A::CuArray)\n  n = length(A)\n  maxthreads = 1024\n  nthreads = min(maxthreads, n)\n  nblocks  = Int(ceil(n/nthreads))\n\n  @cuda threads=nthreads blocks=nblocks square_kernel!(A)\n\n  return A\nend\n\nfunction square_kernel!(A)\n  i = threadIdx().x + (blockIdx().x-1)*blockDim().x\n  if (i&lt;=length(A))\n    @inbounds A[i] *= A[i]\n  end\n  return nothing # CUDA kernels must return nothing\nend\n\nfunction cuarray_cudanative_compare(A)\n  A_gpu = CuArray(A);\n  println(\"CUDAnative square!\")\n  @time CUDA.@sync square!(A_gpu);\n  @time CUDA.@sync square!(A_gpu);\n\n  println(\"CuArray A*=A\")\n  A_gpu = CuArray(A);\n  @time CUDA.@sync A_gpu .*= A_gpu;\n  @time CUDA.@sync A_gpu .*= A_gpu;\n  return nothing\nend\ncuarray_cudanative_compare (generic function with 1 method)\njulia&gt; cuarray_cudanative_compare(randn(N,M))\nCUDAnative square!\n  0.000142 seconds (8 allocations: 400 bytes)\n  0.000128 seconds (8 allocations: 400 bytes)\nCuArray A*=A\n  0.000220 seconds (31 allocations: 2.109 KiB)\n  0.000135 seconds (31 allocations: 2.109 KiB)\n\n\nKernel Limitations\nCUDA kernel functions execute on the GPU and in GPU memory. Since GPU memory is allocated and managed differently than RAM, many Julia functions will not work in CUDA kernels. Most importantly, Julia functions that allocate dynamically sized arrays will not work. This means that even matrix multiplication like θ = ixx*xy will fail (if ixx or xy are dynamically allocated) since it allocates an array for θ. You can, however, have local scalars, tuples, and StaticArrays within a kernel function. The key difference is that the sizes of these types are known at compile time. If ixx and xy are StaticArrays, then you can do something like θ = ixx*xy. Since the compiler knows the size of ixx and xy, the compiler also know the size of θ. However, even with StaticArrays you must be careful with operations that that create new StaticArrays (like matrix multiplies). These will cause problems if called repeatedly within a loop.2\nIt is possible to dynamicaaly allocate GPU memory within a kernel function, but it requires using the low-level interface to CUDA in CUDA.jl. Moreoever, it is generally not a good idea to be dynamically allocating and freeing memory in each of the thousands of threads you execute.3"
  },
  {
    "objectID": "gpu.html#footnotes",
    "href": "gpu.html#footnotes",
    "title": "Coding for Performance",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nProcessor registers are the fastest bits of memory on the processor, and registers are where the actual addition, multiplication, and other instructions are carried out.↩︎\nIf you create StaticArrays inside a loop, they get allocated to the GPU’s “dynamic shared memory.” I believe a new allocation happens each loop iteration. This will be slow, and there is a fairly small amount of dynamic shared memory, of which you will soon run out.↩︎\nThere are situations where allocating shared memory is needed and a good idea, but these require some advanced techniques that we will not cover.↩︎"
  },
  {
    "objectID": "argridboot.html",
    "href": "argridboot.html",
    "title": "Coding for Performance",
    "section": "",
    "text": "Today we will look into some methods to improve the speed of our code. Although speed is sometimes important, never forget that speed should be low on your list of priorities when writing code. You should prioritize correctness and maintainability ahead of performance. Nonetheless, performance does matter for some problems.\nIf you have not already, be sure to read the Peformance Tips section of Julia Docs.\nAlso, read Rackauckas’s notes on “Optimizing Serial Code.” (Rackauckas 2019)."
  },
  {
    "objectID": "argridboot.html#initial-benchmark-and-profile",
    "href": "argridboot.html#initial-benchmark-and-profile",
    "title": "Coding for Performance",
    "section": "Initial Benchmark and Profile",
    "text": "Initial Benchmark and Profile\nbenchorig=@benchmark (b,t) = gridbootstrap(wrapper(b_est_original), a-&gt;ar1_original(y0, a, est.e),\n                             αgrid, nboot)\nBenchmarkTools.Trial: 38 samples with 1 evaluation.\n Range (min … max):  130.823 ms … 149.250 ms  ┊ GC (min … max): 9.70% … 8.5\n6%\n Time  (median):     131.580 ms               ┊ GC (median):    9.72%\n Time  (mean ± σ):   132.501 ms ±   3.666 ms  ┊ GC (mean ± σ):  9.77% ± 0.5\n2%\n\n  ▃█▃▅▂                                                          \n  █████▄▁▄▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▄ ▁\n  131 ms           Histogram: frequency by time          149 ms &lt;\n\n Memory estimate: 219.44 MiB, allocs estimate: 345075.\nTo make code faster, we should begin by profiling.\n# only to make profile results show nicely in generated html\n# for interactive use, just use @profview in place of @profile\nfunction profilehtmlstring() \n  buf = IOBuffer()\n  show(buf, MIME(\"text/html\"), ProfileCanvas.view(Profile.fetch()))\n  s=String(take!(buf))\n  println(\"\\n\\n\"*s*\"\\n\")\nend\nprofilehtmlstring (generic function with 1 method)\nusing Profile, ProfileCanvas\nProfile.clear();\nProfile.init(n=10^7,delay=0.0001);\n@profile (b,t) = gridbootstrap(wrapper(b_est_original), a-&gt;ar1_original(y0, a, est.e),\n                               αgrid, 999)\nprofilehtmlstring()\n\n\n\n\nThe profiler works very simply. Every 0.0001 seconds, the line of code being executed gets recorded. There are then various tools for printing and visualizing the results. The @profview macro shows a flame graph. The default view might be a bit strange. The base of the flame graph often includes Julia’s repl and various other things that can be ignored. If you click on the graph, it will zoom in. You can use mouse wheel up to zoom back out.\n\n\n\n\n\n\nTip\n\n\n\nIn VSCode, you can just use @profview in place of @profile and the profile flamegraph will open in a panel within VSCode."
  },
  {
    "objectID": "argridboot.html#removing-redudant-operations",
    "href": "argridboot.html#removing-redudant-operations",
    "title": "Coding for Performance",
    "section": "Removing Redudant Operations",
    "text": "Removing Redudant Operations\n\n\n\n\n\n\nWarning\n\n\n\nThe following was true on an older version of Julia, but now there are no gains from eliminating inv.\n\n\nFrom the output (these numbers can vary quite a bit from run to run), we see there were 640 ticks in gridbootstrap_original (exact numbers will vary on each execution, but relative ones should be similar), and almost all of these occurred within inv. If we want the code to be faster, we should focus on these lines. Calling both inv and \\ is redundant; we should combine these computations.\ns = @code_string b_est_mldivide(y)\ncode_md(s)\nfunction b_est_mldivide(yin)\n  T = length(yin)\n  x = [ones(T-1) 2:T yin[1:(T-1)]]\n  y = yin[2:T]\n  tmp = x'*x \\ [x'*y I]\n  θ = tmp[:,1]\n  ixx = tmp[:,2:4]\n  e = y - x*θ\n  se = sqrt.(diag(ixx *(e'*e))./(T-4))\n  (θ=θ,se=se,e=e)\nend\nbenchml=@benchmark (b,t) = gridbootstrap(wrapper(b_est_mldivide), a-&gt;ar1_original(y0, a, est.e),\n                             αgrid, nboot)\nBenchmarkTools.Trial: 27 samples with 1 evaluation.\n Range (min … max):  179.880 ms … 199.238 ms  ┊ GC (min … max): 6.97% … 6.4\n5%\n Time  (median):     186.427 ms               ┊ GC (median):    8.51%\n Time  (mean ± σ):   185.857 ms ±   3.287 ms  ┊ GC (mean ± σ):  8.20% ± 0.7\n1%\n\n            ▂ ▂        █▅                                        \n  ▅▁▁▁▁▁▁▁▁▁████▁▁▁▁▁▅████▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅ ▁\n  180 ms           Histogram: frequency by time          199 ms &lt;\n\n Memory estimate: 210.46 MiB, allocs estimate: 517608.\nFrom this, we get a speedup by about a factor of 4 on my computer. This used to make a big difference, but no longer seems to matter."
  },
  {
    "objectID": "argridboot.html#reducing-allocations",
    "href": "argridboot.html#reducing-allocations",
    "title": "Coding for Performance",
    "section": "Reducing Allocations",
    "text": "Reducing Allocations\nProfile.clear()\n@profile (b,t) = gridbootstrap(wrapper(b_est_mldivide), a-&gt;ar1_original(y0, a, est.e),\n                               αgrid, 999)\nprofilehtmlstring()\n\n\n\n\nNow, the most time consuming parts of the code are, unsurprisingly, the call to \\, and, perhaps surprisingly, hcat from creating x. Allocating and copying memory is relatively slow. The creation of x involves both.\n\nCaching Intermediate Arrays\nOne option is to preallocate an arrays and reuse them. The struct bEstCache does this.\nb_est_cache = ARGridBootstrap.bEstCached(T-1)\nbenchcache=@benchmark gridbootstrap(wrapper(b_est_cache), a-&gt;ar1_original(y0, a, est.e), \n                                    αgrid, nboot)\nBenchmarkTools.Trial: 36 samples with 1 evaluation.\n Range (min … max):  138.756 ms … 156.013 ms  ┊ GC (min … max): 7.03% … 6.2\n0%\n Time  (median):     139.455 ms               ┊ GC (median):    7.03%\n Time  (mean ± σ):   140.950 ms ±   3.298 ms  ┊ GC (mean ± σ):  7.63% ± 1.0\n3%\n\n  ▃▅█                                                            \n  ███▁▅▁▁▄▁▁▁▁▄▅▅▇▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄ ▁\n  139 ms           Histogram: frequency by time          156 ms &lt;\n\n Memory estimate: 143.71 MiB, allocs estimate: 162394.\nProfile.clear()\n@profview (b,t) = gridbootstrap(wrapper(b_est_cache), a-&gt;ar1_original(y0, a, est.e),\n                               αgrid, 999)\nprofilehtmlstring()\n\n\n\n\n\n\nEliminating Intermediate Arrays\nBetter yet, we can avoid creating x by just accumulating \\(X'y\\) and \\(X'X\\) in a loop.\ns = @code_string b_est_nox(y)\ncode_md(s)\nfunction b_est_nox(yin; xx_xy!::F=xx_xy!, resids!::FR=resids!) where {F&lt;:Function, FR&lt;:Function}\n  T = length(yin)\n  xx = @MMatrix zeros(eltype(yin),3,3)\n  xy = @MVector zeros(eltype(yin),3)\n  xx_xy!(xx,xy,yin)\n  ixx = inv(xx)\n  θ = ixx * xy\n  e = similar(yin,T-1)\n  resids!(e,yin,θ)\n  se = sqrt.(diag(ixx *(e'*e))./(T-4))\n  (θ=θ,se=se,e=e)\nend\nWe put the two main loops into separate functions both for organization and to allow us to focus on optimizing these loops below.\ns=@code_string ARGridBootstrap.xx_xy!(zeros(3,3),zeros(3),y)\ncode_md(s)\n@inline function xx_xy!(xx,xy,yin)\n  T = length(yin)\n  xx .= zero(eltype(xx))\n  xy .= zero(eltype(xy))\n  @inbounds @simd for t in 2:T\n    xx[1,3] += yin[t-1]\n    xx[2,3] += t*yin[t-1]\n    xx[3,3] += yin[t-1]^2\n    xy[1] += yin[t]\n    xy[2] += t*yin[t]\n    xy[3] += yin[t-1]*yin[t]\n  end\n  xx[1,1] = T-1 # = 1'*1\n  xx[1,2] = xx[2,1] = (T+1)*T/2 - 1 # sum(p+1:T)\n  xx[2,2] = (2*(T)+1)*(T)*(T+1)/6 - 1 # sum((p+1:T).^2)\n  xx[3,1] = xx[1,3]\n  xx[3,2] = xx[2,3]\n  nothing\nend\ns=@code_string ARGridBootstrap.resids!(zeros(length(y)-1),y,zeros(3))\ncode_md(s)\n@inline function resids!(e, yin, θ)\n  T = length(yin)\n  @inbounds @simd for t in 2:T\n    e[t-1] = yin[t] - θ[1] - θ[2]*t - θ[3]*yin[t-1]\n  end\n  nothing\nend\nbenchnox=@benchmark (b,t) = gridbootstrap(wrapper(b_est_nox), a-&gt;ar1_original(y0, a, est.e),\n                             αgrid, nboot)\nBenchmarkTools.Trial: 124 samples with 1 evaluation.\n Range (min … max):  37.839 ms … 61.466 ms  ┊ GC (min … max):  7.96% … 4.77\n%\n Time  (median):     41.088 ms              ┊ GC (median):    14.60%\n Time  (mean ± σ):   40.376 ms ±  2.496 ms  ┊ GC (mean ± σ):  12.25% ± 3.29\n%\n\n   ▁                    █▁▂▃                                   \n  ▇█▆▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅████▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃ ▃\n  37.8 ms         Histogram: frequency by time        46.4 ms &lt;\n\n Memory estimate: 71.70 MiB, allocs estimate: 101499.\nWe have further cut the time by a factor of two. However, this performance optimization has been costly in terms of readability and extensibility of our code. If we wanted to fit an AR(p) model instead of AR(1), the b_est_nox function would be more difficult to modify than the b_est_mldivide version.\nWe additionally gained some performance by using mutable StaticArrays to hold \\(X'X\\) and \\(X'y\\).\nxx = zeros(3,3)\nxy = zeros(3)\n@benchmark ARGridBootstrap.xx_xy!(xx,xy,y)\nBenchmarkTools.Trial: 10000 samples with 179 evaluations.\n Range (min … max):  594.637 ns …  1.129 μs  ┊ GC (min … max): 0.00% … 0.00\n%\n Time  (median):     597.760 ns              ┊ GC (median):    0.00%\n Time  (mean ± σ):   602.472 ns ± 26.903 ns  ┊ GC (mean ± σ):  0.00% ± 0.00\n%\n\n   █▄                                                          ▁\n  ▆██▇▄▄▁▁▃▁▁▁▁▁▁▁▇▄▄▄▄█▇████▇▆▅▆▅▇▅▁▅▄▄▃▃▃▄▁▄▄▄▅▅▅▆▅▅▅▅▅▅▅▅▅▆ █\n  595 ns        Histogram: log(frequency) by time       706 ns &lt;\n\n Memory estimate: 0 bytes, allocs estimate: 0.\nusing StaticArrays\nxx = @MMatrix zeros(3,3)\nxy = @MVector zeros(3)\n@benchmark ARGridBootstrap.xx_xy!(xx,xy,y)\nBenchmarkTools.Trial: 10000 samples with 181 evaluations.\n Range (min … max):  588.834 ns …  1.172 μs  ┊ GC (min … max): 0.00% … 0.00\n%\n Time  (median):     592.696 ns              ┊ GC (median):    0.00%\n Time  (mean ± σ):   597.046 ns ± 28.276 ns  ┊ GC (mean ± σ):  0.00% ± 0.00\n%\n\n   ▇█▃                      ▁                                  ▁\n  ▅███▅▁▄▁▁▁▁▁▃▁▁▁▁▃▃▁▁▄▇▇▇████▇▇▆▅▄▅▅▃▄▅▃▁▄▃▁▁▄▄▅▅▄▄▄▅▄▃▅▄▄▄▅ █\n  589 ns        Histogram: log(frequency) by time       695 ns &lt;\n\n Memory estimate: 0 bytes, allocs estimate: 0."
  },
  {
    "objectID": "argridboot.html#loopvectorization.jl",
    "href": "argridboot.html#loopvectorization.jl",
    "title": "Coding for Performance",
    "section": "LoopVectorization.jl",
    "text": "LoopVectorization.jl\nAs mentioned above, the Julia compiler tries to automactically use SIMD instructions when it is safe to do so. SIMD instructions often change the order of operations, and since floating point math is not exactly commutative. The compiler tries to avoid reordering operations, but this often prevents SIMD use. The macro @simd tells the compiler to not worry about reordering operations and insert SIMD instructions more aggresively. Still, there are some SIMD operations that the compiler will not insert automatically.\nThe LoopVectorization.jl package defines a macro, @turbo that more aggresively inserts SIMD instructions. This can make a large difference for some loops and broadcasts.\ne = zeros(length(y)-1)\nθ = @MVector zeros(3)\n@benchmark ARGridBootstrap.resids!($e,$y,$θ)\nBenchmarkTools.Trial: 10000 samples with 390 evaluations.\n Range (min … max):  246.418 ns … 555.159 ns  ┊ GC (min … max): 0.00% … 0.0\n0%\n Time  (median):     248.031 ns               ┊ GC (median):    0.00%\n Time  (mean ± σ):   250.314 ns ±  13.983 ns  ┊ GC (mean ± σ):  0.00% ± 0.0\n0%\n\n   █▆▁               ▁                                          ▁\n  ▇███▄▅▁▃▁▃▁▁▁▁▃▃▃▁▄█▄▅▆▇███▇▇▇▅▅▄▄▃▁▄▁▁▄▄▅▄▃▅▆▄▅▄▅▅▄▅▅▅▅▅▄▄▄▅ █\n  246 ns        Histogram: log(frequency) by time        300 ns &lt;\n\n Memory estimate: 0 bytes, allocs estimate: 0.\n@benchmark ARGridBootstrap.resids_turbo!($e,$y,$θ)\nBenchmarkTools.Trial: 10000 samples with 979 evaluations.\n Range (min … max):  60.996 ns … 131.267 ns  ┊ GC (min … max): 0.00% … 0.00\n%\n Time  (median):     61.709 ns               ┊ GC (median):    0.00%\n Time  (mean ± σ):   62.269 ns ±   2.848 ns  ┊ GC (mean ± σ):  0.00% ± 0.00\n%\n\n    ▄█▅▁                 ▃                                  ▁  ▁\n  ▅▅████▇▅▅▁▁▃▃▁▁▁▁▁▁▁▄▅▄██▄▄▃▃▁▁▁▄▃▄▃▁▁▁▁▃▄▄▅▇▇▇▆▆▆▅▅▅▅▆▅▃▅█▆ █\n  61 ns         Histogram: log(frequency) by time      72.5 ns &lt;\n\n Memory estimate: 0 bytes, allocs estimate: 0.\nWe can also write SIMD instructions ourselves. The SIMD.jl package makes this somewhat accessible. For an example, resids_simd uses this package to match performance of the @turbo version.\n@benchmark ARGridBootstrap.resids_simd!($e,$y,$θ, Val(8))\nBenchmarkTools.Trial: 10000 samples with 979 evaluations.\n Range (min … max):  63.778 ns … 120.281 ns  ┊ GC (min … max): 0.00% … 0.00\n%\n Time  (median):     64.349 ns               ┊ GC (median):    0.00%\n Time  (mean ± σ):   64.973 ns ±   2.993 ns  ┊ GC (mean ± σ):  0.00% ± 0.00\n%\n\n    █▅▂                ▂                                ▁      ▁\n  ▅▆████▁▃▄▃▁▁▁▁▁▁▁▁▁▃▃█▇▄▃▁▁▁▁▄▁▆▆▄▁▄▃▅▅▆▇▇▇▇▆▆▅▅▅▄▅▅▁▄█▆▄▃▅▃ █\n  63.8 ns       Histogram: log(frequency) by time      76.5 ns &lt;\n\n Memory estimate: 0 bytes, allocs estimate: 0.\nGenerally, if @turbo successfully inserted SIMD instructions and made your code substantially faster, it will not be worth your effort to try to manually write SIMD code. However, @turbo will not always be able to insert SIMD instructions. One way to check is through benchmarking. Another way is to inspect @code_llvm ARGridBootstrap.resids_turbo!(e,y,θ). Things like fadd fast &lt;4 x double&gt; are SIMD instructions. The &lt;4 x double&gt; part is the key sign. In contrast, something like %26 = fsub double %24, %25 are scalar instructions.\nThe loops in xx_xy! are not automatically vectorized. Part of the issue is that @turbo cannot tell that xx and xy are statically allocated. If we rewrite the code to use scalars, it would like get vectorized by @turbo. The b_est_stride function does this. However, it is really inconvenient to rewrite array code as scalars. It may be more maintainable to keep the arrays and write SIMD instructions ourselves.\n@benchmark ARGridBootstrap.xx_xy!($xx,$xy,$y)\nBenchmarkTools.Trial: 10000 samples with 183 evaluations.\n Range (min … max):  577.443 ns …  13.795 μs  ┊ GC (min … max): 0.00% … 0.0\n0%\n Time  (median):     580.115 ns               ┊ GC (median):    0.00%\n Time  (mean ± σ):   586.493 ns ± 134.607 ns  ┊ GC (mean ± σ):  0.00% ± 0.0\n0%\n\n   █▂                   ▁                                       ▁\n  ███▆▄▃▁▃▃▁▃▃▃▃▄▁▁▁▄█▆▇███▇▇▅▅▇▅▁▃▄▄▅▅▄▄▆▄▅▄▄▅▆▄▅▄▅▆▅▄▅▄▆▅▅▄▅▄ █\n  577 ns        Histogram: log(frequency) by time        700 ns &lt;\n\n Memory estimate: 0 bytes, allocs estimate: 0.\n@benchmark ARGridBootstrap.xx_xy_simd!($xx,$xy,$y, Val(16))\nBenchmarkTools.Trial: 10000 samples with 565 evaluations.\n Range (min … max):  206.189 ns … 321.524 ns  ┊ GC (min … max): 0.00% … 0.0\n0%\n Time  (median):     207.427 ns               ┊ GC (median):    0.00%\n Time  (mean ± σ):   209.219 ns ±   7.418 ns  ┊ GC (mean ± σ):  0.00% ± 0.0\n0%\n\n   ██▂                   ▃▁▁▁        ▁                          ▂\n  ▆███▅▄▃▁▁▁▁▁▁▃▄▃▃▃▄▄▃▄▇█████▇▆▆▅▅▅▇█▆▄▃▄▅▄▅▄▄▅▅██▅▄▃▄▁▄▃▄▄▅▅▆ █\n  206 ns        Histogram: log(frequency) by time        243 ns &lt;\n\n Memory estimate: 0 bytes, allocs estimate: 0.\nThis makes the code faster by a factor of more than 10. The Val(N) argument controls the width of vectors that gets passed to SIMD instructions. The value of N can affect execution by a factor of 5 or more. The best choice of N depends on your exact hardware and the code being executed.\nTo see how much this is worth it, let’s benchmark the full bootstrap code, but using the SIMD versions of resids! and xx_xy!\nb_est_simd = y-&gt;b_est_nox(y, xx_xy! =ARGridBootstrap.xx_xy_simd!, resids! =ARGridBootstrap.resids_simd!)\nbenchsimd=@benchmark (b,t) = gridbootstrap(wrapper(b_est_simd), a-&gt;ar1_original(y0, a, est.e),\n                             αgrid, nboot)\nBenchmarkTools.Trial: 128 samples with 1 evaluation.\n Range (min … max):  36.683 ms … 58.429 ms  ┊ GC (min … max):  8.36% … 5.09\n%\n Time  (median):     39.941 ms              ┊ GC (median):    15.25%\n Time  (mean ± σ):   39.180 ms ±  2.351 ms  ┊ GC (mean ± σ):  12.87% ± 3.57\n%\n\n   ▃                   ▄█▂                                     \n  ██▄▇▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃████▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃ ▃\n  36.7 ms         Histogram: frequency by time        45.4 ms &lt;\n\n Memory estimate: 71.70 MiB, allocs estimate: 101499.\nWe have not improved total execution very much. The problem is that very little of the total time was spent in xx_xy! and resids! to begin with. We did make those functions much faster, but they were such a small portion of total execution time, that it is not noticeable. We should focus our efforts on ar1_original if we want to improve."
  },
  {
    "objectID": "assignment.html",
    "href": "assignment.html",
    "title": "Coding for Performance",
    "section": "",
    "text": "For the assignment, most students focused on optimizing either the share function from our earlier BLP example, or the statparts function from GMMInference.\nLet’s see how we can improve these functions’ performance."
  },
  {
    "objectID": "assignment.html#initial-benchmark",
    "href": "assignment.html#initial-benchmark",
    "title": "Coding for Performance",
    "section": "Initial Benchmark",
    "text": "Initial Benchmark\nJ = 10\nK = 5\nδ = rand(J)\nX = randn(J,K)\nΣ = I + zeros(K,K)\n∫ = Integrator(MvNormal(zeros(K),I));\n@benchmark share(δ,Σ,X,∫)\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  46.078 μs …  10.655 ms  ┊ GC (min … max): 0.00% … 98.7\n0%\n Time  (median):     55.581 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   67.335 μs ± 199.461 μs  ┊ GC (mean ± σ):  8.98% ±  3.3\n8%\n\n     ▁▁    ▂▃▅▇█▇▄▄▄▂▁▁                    ▁▂▂  ▂▂▄▄▃▃▄▂▁▁     ▂\n  ▆▇████████████████████▇▆▅▇▇▆▆▆▅▆▆▆▄▅▃▄▄▁▇█████████████████▇▆ █\n  46.1 μs       Histogram: log(frequency) by time      87.2 μs &lt;\n\n Memory estimate: 65.48 KiB, allocs estimate: 499.\nProfiling it:\nusing Profile\nProfile.clear();\nProfile.init(n=10^7,delay=0.00001);\n@profile sum(share(δ,Σ,X,∫) for i ∈ 1:1000)\nprofilehtmlstring()\n\n\n\n\nIt’s a good idea to check @code_warntype and verify that there are no type instabilities (variables with type Any or Union). I checked and there are no type instabilites here."
  },
  {
    "objectID": "assignment.html#loopvectorization",
    "href": "assignment.html#loopvectorization",
    "title": "Coding for Performance",
    "section": "LoopVectorization",
    "text": "LoopVectorization\nExamining the profile, we see that the multiplication of x*Σ*ν is the single most costly operation. The second most costly are lines computing the softmax function, exp.(s)./(1 .+exp.(s))\nusing LoopVectorization\n\n@inline function dplusxMy(d::AbstractVector,x::AbstractMatrix,M::AbstractMatrix,y::AbstractVector)\n  out = similar(d)\n  @turbo for i ∈ axes(x,1)\n    r = d[i]\n    for j ∈ axes(x,2)\n      for k ∈ axes(M,2)\n        r += x[i,j]*M[j,k]*y[k]\n      end\n    end\n    out[i] = r\n  end\n  out\nend\n@inline function softmax0!(s)\n  smax=@turbo reduce(max, s, init=zero(eltype(s)))\n  s .= exp.(s .- smax)\n  s ./= (sum(s) + exp(zero(smax)-smax))\n  return(s)\nend\nfunction share_v2(δ, Σ, x, ∫)\n  J,K = size(x)\n  (length(δ) == J) || error(\"length(δ)=$(length(δ)) != size(x,1)=$J\")\n  (K,K) == size(Σ) || error(\"size(x,2)=$K != size(Σ)=$(size(Σ))\")\n  function shareν(ν)\n    s = dplusxMy(δ,x,Σ,ν)\n    softmax0!(s)\n    s\n  end\n  return(∫(shareν))\nend\n@benchmark share_v2(δ,Σ,X,∫)\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  28.545 μs …   4.955 ms  ┊ GC (min … max): 0.00% … 98.4\n1%\n Time  (median):     33.795 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   41.119 μs ± 117.942 μs  ┊ GC (mean ± σ):  6.94% ±  2.4\n1%\n\n             ▆█▂                                                \n  ▂▂▂▂▂▂▂▂▂▃▇███▄▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▂▂▂▃▃▂▄▄▃▃▃▄▅▃ ▃\n  28.5 μs         Histogram: frequency by time         53.3 μs &lt;\n\n Memory estimate: 42.05 KiB, allocs estimate: 299.\nBy writing the δ+x*Σ*ν as loop we avoid some allocations, and can use @turbo to insert SIMD instructions. This gives a noticeable speedup. About half the gains here are from writing out the loops in dplusxMy and half from using @turbo. The changes to the softmax calculation did not make much difference.\nusing Profile\nProfile.clear();\nProfile.init(n=10^7,delay=0.00001);\nProfileCanvas.@profview sum(share_v2(δ,Σ,X,∫) for i ∈ 1:1000)\nprofilehtmlstring()\n\n\n\n\nThe execution time is still dominated by the two functions mentioned above."
  },
  {
    "objectID": "assignment.html#staticarrays",
    "href": "assignment.html#staticarrays",
    "title": "Coding for Performance",
    "section": "StaticArrays",
    "text": "StaticArrays\nSince the calculations involve small arrays, it is likely to benefit from using StaticArrays.\nusing StaticArrays\nsδ = SVector{J}(δ)\nsΣ = SMatrix{K,K}(Σ)\nsX = SMatrix{J,K}(X)\nnd = length(∫.x)\niw = SVector{nd}(fill(1/nd,nd))\nix = [SVector{K}(x) for x ∈ ∫.x]\ns∫ = Integrator(ix,iw)\n@benchmark share_v2(sδ,sΣ,sX,s∫)\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  18.543 μs …   5.089 ms  ┊ GC (min … max): 0.00% … 98.5\n7%\n Time  (median):     23.061 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   28.211 μs ± 110.996 μs  ┊ GC (mean ± σ):  8.71% ±  2.2\n0%\n\n               ▄█▆▂                                             \n  ▂▃▃▃▃▃▃▂▂▂▃▄▇████▆▃▂▂▂▂▂▁▂▂▂▁▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▂▂▂▂▃▇▆▄▄▇▅▃▂▂▂ ▃\n  18.5 μs         Histogram: frequency by time         36.1 μs &lt;\n\n Memory estimate: 28.03 KiB, allocs estimate: 299.\nThe code is now 2 times faster than what we started with.\nInterestly, slightly better performance can be achieved by simply passing StaticArrays to the original code.\n@benchmark share($(MVector(sδ)),sΣ,sX,s∫) # δ gets mutated, so we must make it a Mutable SArray.\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  15.258 μs …   5.028 ms  ┊ GC (min … max): 0.00% … 98.7\n4%\n Time  (median):     18.066 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   25.243 μs ± 111.254 μs  ┊ GC (mean ± σ):  9.76% ±  2.2\n1%\n\n         ▇█▁                                                    \n  ▂▃▃▃▃▂▃███▅▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▂▁▁▂▁▁▁▂▂▃▅▅▆▆▅▅▆▄▂▂▂▂▂ ▃\n  15.3 μs         Histogram: frequency by time         33.2 μs &lt;\n\n Memory estimate: 28.03 KiB, allocs estimate: 299."
  },
  {
    "objectID": "assignment.html#non-allocating",
    "href": "assignment.html#non-allocating",
    "title": "Coding for Performance",
    "section": "Non-allocating",
    "text": "Non-allocating\nWe can do still better by eliminating the allocations. With normal arrays, broadcast operations are usually non-allocating, and normal array operations allocate. With StaticArrays, normal operatorations do not allocate.1\nAdditionally, we can precompute x*Σ outside of shareν (we could have done this at any time earlier too). This change accounts for about 1μs of the speed up.\nfunction share_v3(δ, Σ, x, ∫)\n  J,K = size(x)\n  (length(δ) == J) || error(\"length(δ)=$(length(δ)) != size(x,1)=$J\")\n  (K,K) == size(Σ) || error(\"size(x,2)=$K != size(Σ)=$(size(Σ))\")\n  xΣ = x*Σ\n  function shareν(ν)\n    s = δ + xΣ*ν\n    smax=max(0,maximum(s))\n    s -= smax*ones(typeof(s))\n    s = exp.(s)\n    s *= 1/(sum(s) + exp(0-smax))\n    return(s)\n  end\n  return(∫(shareν))\nend\nshare_v3 (generic function with 1 method)\n@benchmark share_v3(sδ,sΣ,sX,s∫)\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  9.609 μs …  24.355 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     9.706 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   9.743 μs ± 337.037 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n         ▁▂▃█▁▂▅                                               \n  ▁▁▁▁▂▄▄███████▇▆▇▄▅▆▅▇█▅▆▆▄▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁ ▃\n  9.61 μs         Histogram: frequency by time          10 μs &lt;\n\n Memory estimate: 96 bytes, allocs estimate: 1.\nThe code is now 5 times faster than the original, and only allocates once (to store the return value)."
  },
  {
    "objectID": "assignment.html#multi-threading",
    "href": "assignment.html#multi-threading",
    "title": "Coding for Performance",
    "section": "Multi-Threading",
    "text": "Multi-Threading\nMulti-threading this code is difficult because it is already quite fast. The sum in the integral can be parallelized, but unless there are a large number of integration points, the overhead from creating threads will likely outweigh the benefits.\nThe Polyester package provides a faster, but more limited threading model than base Julia. Using it, we can see modest gains, even with just 100 integration points.\nTo get type stability, I had to write the integration sum loop inside the share function. It would have been cleaner to keep the integration sum in a separate function, but I could not make it type stable that way.\nimport Polyester\nfunction share_v4(δ, Σ, x, ∫, ::Val{B}=Val(length(∫.x) ÷ 10)) where {B}\n  J,K = size(x)\n  (length(δ) == J) || error(\"length(δ)=$(length(δ)) != size(x,1)=$J\")\n  (K,K) == size(Σ) || error(\"size(x,2)=$K != size(Σ)=$(size(Σ))\")\n  xΣ = x*Σ\n  function shareν(ν)\n    s = δ + xΣ*ν\n    smax=max(0,maximum(s))\n    s -= smax*ones(typeof(s))\n    s = exp.(s)\n    s *= 1/(sum(s) + exp(0-smax))\n    return(s)\n  end\n  batchlen= length(∫.x)÷B\n  @assert B*batchlen==length(∫.x)\n  out = MVector{B,typeof(δ)}(undef)\n  Polyester.@batch for b ∈ 1:B  \n    batch = ((b-1)*(batchlen)+1):(b*batchlen)\n    out[b] = zero(typeof(δ))\n    for i ∈ batch\n      out[b] += shareν(∫.x[i])*∫.w[i]\n    end\n  end\n  return(sum(out))\nend\nPolyester.reset_threads!()\n@benchmark share_v4(sδ,sΣ,sX,s∫, Val(20))\nBenchmarkTools.Trial: 10000 samples with 8 evaluations.\n Range (min … max):  4.327 μs …  1.581 ms  ┊ GC (min … max): 0.00% … 37.99%\n Time  (median):     4.769 μs              ┊ GC (median):    0.00%\n Time  (mean ± σ):   5.510 μs ± 22.203 μs  ┊ GC (mean ± σ):  2.16% ±  0.53%\n\n       ▄▆█▇▄▁                                 ▁▂▁             \n  ▁▂▂▅███████▇▅▄▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▄▆▇████▇▆▄▄▃▂▂▁▁▁ ▃\n  4.33 μs        Histogram: frequency by time        6.39 μs &lt;\n\n Memory estimate: 1.55 KiB, allocs estimate: 2."
  },
  {
    "objectID": "assignment.html#initial-benchmark-1",
    "href": "assignment.html#initial-benchmark-1",
    "title": "Coding for Performance",
    "section": "Initial Benchmark",
    "text": "Initial Benchmark\n@benchmark klm(gi)(β0)\nBenchmarkTools.Trial: 9747 samples with 1 evaluation.\n Range (min … max):  458.320 μs …  14.717 ms  ┊ GC (min … max): 0.00% … 95.\n33%\n Time  (median):     473.890 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   506.388 μs ± 513.723 μs  ┊ GC (mean ± σ):  5.24% ±  4.\n99%\n\n        ▁▄▇█▇▆▄▂                                                 \n  ▂▂▂▃▄▆█████████▇▆▆▅▅▅▄▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂ ▃\n  458 μs           Histogram: frequency by time          542 μs &lt;\n\n Memory estimate: 211.50 KiB, allocs estimate: 2759."
  },
  {
    "objectID": "assignment.html#fixing-type-instabilities",
    "href": "assignment.html#fixing-type-instabilities",
    "title": "Coding for Performance",
    "section": "Fixing Type Instabilities",
    "text": "Fixing Type Instabilities\nFrom @code_warntype, we see that the compiles is unable to infer the type of some variables. The problem seems to start with D. This is quite puzzling because D is explicitly initialized as zeros(eltype(Gi),...).\njulia&gt; @code_warntype klm(gi)(β0)\nMethodInstance for (::var\"#24#25\"{var\"#21#23\"{var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}, var\"#P#22\"}})(::Vector{Float64})\n  from (::var\"#24#25\")(θ) @ Main ~/.julia/dev/ARGridBootstrap/docs/jmd/assignment.jmd:31\nArguments\n  #self#::var\"#24#25\"{var\"#21#23\"{var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}, var\"#P#22\"}}\n  θ::Vector{Float64}\nLocals\n  @_3::Int64\n  P::var\"#P#22\"\n  D::ANY\n  Ω::Matrix{Float64}\n  gn::Adjoint{Float64, Matrix{Float64}}\n  p::Int64\n  k::Int64\n  n::Int64\nBody::ANY\n1 ─ %1  = Core.getfield(#self#, :SP)::var\"#21#23\"{var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}, var\"#P#22\"}\n│   %2  = (%1)(θ)::TUPLE{INT64, INT64, INT64, ADJOINT{FLOAT64, MATRIX{FLOAT64}}, MATRIX{FLOAT64}, ANY, VAR\"#P#22\"}\n│   %3  = Base.indexed_iterate(%2, 1)::Core.PartialStruct(Tuple{Int64, Int64}, Any[Int64, Core.Const(2)])\n│         (n = Core.getfield(%3, 1))\n│         (@_3 = Core.getfield(%3, 2))\n│   %6  = Base.indexed_iterate(%2, 2, @_3::Core.Const(2))::Core.PartialStruct(Tuple{Int64, Int64}, Any[Int64, Core.Const(3)])\n│         (k = Core.getfield(%6, 1))\n│         (@_3 = Core.getfield(%6, 2))\n│   %9  = Base.indexed_iterate(%2, 3, @_3::Core.Const(3))::Core.PartialStruct(Tuple{Int64, Int64}, Any[Int64, Core.Const(4)])\n│         (p = Core.getfield(%9, 1))\n│         (@_3 = Core.getfield(%9, 2))\n│   %12 = Base.indexed_iterate(%2, 4, @_3::Core.Const(4))::Core.PartialStruct(Tuple{Adjoint{Float64, Matrix{Float64}}, Int64}, Any[Adjoint{Float64, Matrix{Float64}}, Core.Const(5)])\n│         (gn = Core.getfield(%12, 1))\n│         (@_3 = Core.getfield(%12, 2))\n│   %15 = Base.indexed_iterate(%2, 5, @_3::Core.Const(5))::Core.PartialStruct(Tuple{Matrix{Float64}, Int64}, Any[Matrix{Float64}, Core.Const(6)])\n│         (Ω = Core.getfield(%15, 1))\n│         (@_3 = Core.getfield(%15, 2))\n│   %18 = Base.indexed_iterate(%2, 6, @_3::Core.Const(6))::Core.PartialStruct(Tuple{Any, Int64}, Any[Any, Core.Const(7)])\n│         (D = Core.getfield(%18, 1))\n│         (@_3 = Core.getfield(%18, 2))\n│   %21 = Base.indexed_iterate(%2, 7, @_3::Core.Const(7))::Core.PartialStruct(Tuple{var\"#P#22\", Int64}, Any[var\"#P#22\", Core.Const(8)])\n│         (P = Core.getfield(%21, 1))\n│   %23 = n::Int64\n│   %24 = Main.:var\"'\"(gn)::Matrix{Float64}\n│   %25 = Ω::Matrix{Float64}\n│   %26 = (-1 / 2)::Core.Const(-0.5)\n│   %27 = (%25 ^ %26)::ANY\n│   %28 = Ω::Matrix{Float64}\n│   %29 = (-1 / 2)::Core.Const(-0.5)\n│   %30 = (%28 ^ %29)::ANY\n│   %31 = (%30 * D)::ANY\n│   %32 = (P)(%31)::ANY\n│   %33 = Ω::Matrix{Float64}\n│   %34 = (-1 / 2)::Core.Const(-0.5)\n│   %35 = (%33 ^ %34)::ANY\n│   %36 = (%24 * %27 * %32 * %35 * gn)::ANY\n│   %37 = Base.getindex(%36, 1)::ANY\n│   %38 = (%23 * %37)::ANY\n└──       return %38\nTo investigate further, let us focus on statparts.\njulia&gt; @code_warntype statparts(gi)(β0)\nMethodInstance for (::var\"#21#23\"{var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}, var\"#P#22\"})(::Vector{Float64})\n  from (::var\"#21#23\")(θ) @ Main ~/.julia/dev/ARGridBootstrap/docs/jmd/assignment.jmd:7\nArguments\n  #self#::var\"#21#23\"{var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}, var\"#P#22\"}\n  θ::Vector{Float64}\nLocals\n  @_3::UNION{NOTHING, TUPLE{INT64, INT64}}\n  @_4::Int64\n  D::ANY\n  Γ::ANY\n  G::ANY\n  Gi::ANY\n  gn::Adjoint{Float64, Matrix{Float64}}\n  Ω::Matrix{Float64}\n  k::Int64\n  n::Int64\n  p::Int64\n  giθ::Matrix{Float64}\n  @_15::UNION{NOTHING, TUPLE{INT64, INT64}}\n  j::Int64\n  i::Int64\nBody::TUPLE{INT64, INT64, INT64, ADJOINT{FLOAT64, MATRIX{FLOAT64}}, MATRIX{FLOAT64}, ANY, VAR\"#P#22\"}\n1 ─ %1  = Core.getfield(#self#, :gi)::var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}\n│         (giθ = (%1)(θ))\n│         (p = Main.length(θ))\n│   %4  = Main.size(giθ)::Tuple{Int64, Int64}\n│   %5  = Base.indexed_iterate(%4, 1)::Core.PartialStruct(Tuple{Int64, Int64}, Any[Int64, Core.Const(2)])\n│         (n = Core.getfield(%5, 1))\n│         (@_4 = Core.getfield(%5, 2))\n│   %8  = Base.indexed_iterate(%4, 2, @_4::Core.Const(2))::Core.PartialStruct(Tuple{Int64, Int64}, Any[Int64, Core.Const(3)])\n│         (k = Core.getfield(%8, 1))\n│         (Ω = Main.cov(giθ))\n│   %11 = Core.getfield(#self#, :gi)::var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}\n│   %12 = (%11)(θ)::Matrix{Float64}\n│   %13 = (:dims,)::Core.Const((:dims,))\n│   %14 = Core.apply_type(Core.NamedTuple, %13)::Core.Const(NamedTuple{(:dims,)})\n│   %15 = Core.tuple(1)::Core.Const((1,))\n│   %16 = (%14)(%15)::Core.Const((dims = 1,))\n│   %17 = Core.kwcall(%16, Main.mean, %12)::Matrix{Float64}\n│         (gn = Main.:var\"'\"(%17))\n│   %19 = ForwardDiff.jacobian::Core.Const(ForwardDiff.jacobian)\n│   %20 = Core.getfield(#self#, :gi)::var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}\n│         (Gi = (%19)(%20, θ))\n│         (Gi = Main.reshape(Gi, n, k, p))\n│   %23 = (:dims,)::Core.Const((:dims,))\n│   %24 = Core.apply_type(Core.NamedTuple, %23)::Core.Const(NamedTuple{(:dims,)})\n│   %25 = Core.tuple(1)::Core.Const((1,))\n│   %26 = (%24)(%25)::Core.Const((dims = 1,))\n│         (G = Core.kwcall(%26, Main.mean, Gi))\n│   %28 = Main.eltype(Gi)::ANY\n│   %29 = p::Int64\n│   %30 = k::Int64\n│         (Γ = Main.zeros(%28, %29, %30, k))\n│   %32 = Main.eltype(Gi)::ANY\n│   %33 = k::Int64\n│         (D = Main.zeros(%32, %33, p))\n│   %35 = (1:p)::Core.PartialStruct(UnitRange{Int64}, Any[Core.Const(1), Int64])\n│         (@_3 = Base.iterate(%35))\n│   %37 = (@_3 === nothing)::Bool\n│   %38 = Base.not_int(%37)::Bool\n└──       goto #7 if not %38\n2 ┄ %40 = @_3::Tuple{Int64, Int64}\n│         (j = Core.getfield(%40, 1))\n│   %42 = Core.getfield(%40, 2)::Int64\n│   %43 = (1:n)::Core.PartialStruct(UnitRange{Int64}, Any[Core.Const(1), Int64])\n│         (@_15 = Base.iterate(%43))\n│   %45 = (@_15 === nothing)::Bool\n│   %46 = Base.not_int(%45)::Bool\n└──       goto #5 if not %46\n3 ┄ %48 = @_15::Tuple{Int64, Int64}\n│         (i = Core.getfield(%48, 1))\n│   %50 = Core.getfield(%48, 2)::Int64\n│   %51 = Base.getindex(Γ, j, Main.:(:), Main.:(:))::ANY\n│   %52 = Main.:-::Core.Const(-)\n│   %53 = Base.getindex(Gi, i, Main.:(:), j)::ANY\n│   %54 = Base.getindex(G, 1, Main.:(:), j)::ANY\n│   %55 = Base.broadcasted(%52, %53, %54)::ANY\n│   %56 = Base.materialize(%55)::ANY\n│   %57 = Base.getindex(giθ, i, Main.:(:))::Vector{Float64}\n│   %58 = Main.:var\"'\"(%57)::Adjoint{Float64, Vector{Float64}}\n│   %59 = (%56 * %58)::ANY\n│   %60 = (%51 + %59)::ANY\n│         Base.setindex!(Γ, %60, j, Main.:(:), Main.:(:))\n│         (@_15 = Base.iterate(%43, %50))\n│   %63 = (@_15 === nothing)::Bool\n│   %64 = Base.not_int(%63)::Bool\n└──       goto #5 if not %64\n4 ─       goto #3\n5 ┄ %67 = Base.dotview(Γ, j, Main.:(:), Main.:(:))::ANY\n│   %68 = Main.:/::Core.Const(/)\n│   %69 = Base.getindex(Γ, j, Main.:(:), Main.:(:))::ANY\n│   %70 = Base.broadcasted(%68, %69, n)::ANY\n│         Base.materialize!(%67, %70)\n│   %72 = Base.getindex(G, 1, Main.:(:), j)::ANY\n│   %73 = Base.getindex(Γ, j, Main.:(:), Main.:(:))::ANY\n│   %74 = Main.inv(Ω)::Matrix{Float64}\n│   %75 = (%73 * %74 * gn)::ANY\n│   %76 = (%72 - %75)::ANY\n│         Base.setindex!(D, %76, Main.:(:), j)\n│         (@_3 = Base.iterate(%35, %42))\n│   %79 = (@_3 === nothing)::Bool\n│   %80 = Base.not_int(%79)::Bool\n└──       goto #7 if not %80\n6 ─       goto #2\n7 ┄ %83 = n::Int64\n│   %84 = k::Int64\n│   %85 = p::Int64\n│   %86 = gn::Adjoint{Float64, Matrix{Float64}}\n│   %87 = Ω::Matrix{Float64}\n│   %88 = D::ANY\n│   %89 = Core.getfield(#self#, :P)::Core.Const(var\"#P#22\"())\n│   %90 = Core.tuple(%83, %84, %85, %86, %87, %88, %89)::TUPLE{INT64, INT64, INT64, ADJOINT{FLOAT64, MATRIX{FLOAT64}}, MATRIX{FLOAT64}, ANY, VAR\"#P#22\"}\n└──       return %90\nWe see that G, Gi, Γ, and D are all type Any. For some reason, the return value of ForwardDiff.jacobian is not being inferred. We can workaround this by using an jacobian! instead.\nfunction statparts(gi::F) where {F &lt;: Function}\n  function P(A::AbstractMatrix) # projection matrix\n    A*pinv(A'*A)*A'\n  end\n  let gi=gi\n    function(θ)\n      giθ = gi(θ)\n      p = length(θ)\n      (n, k) = size(giθ)\n      Ω = Hermitian(cov(giθ))\n      gn=mean(gi(θ), dims=1)'\n      Gi = zeros(n,k,p)\n      ForwardDiff.jacobian!(Gi,gi,θ)\n      Gi = reshape(Gi, n , k, p)\n      G = mean(Gi, dims=1)\n      Γ = zeros(eltype(Gi),p,k,k)\n      D = zeros(eltype(Gi),k, p)\n      for j in 1:p\n        for i in 1:n\n          Γ[j,:,:] += (Gi[i,:,j] .- G[1,:,j]) * giθ[i,:]'\n        end\n        Γ[j,:,:] ./= n\n        D[:,j] = G[1,:,j] - Γ[j,:,:]*inv(Ω)*gn\n      end\n      return(n,k,p,gn, Ω, D, P)\n    end\n  end\nend\nstatparts (generic function with 1 method)\njulia&gt; @code_warntype statparts(gi)(β0)\nMethodInstance for (::var\"#28#30\"{var\"#P#29\", var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}})(::Vector{Float64})\n  from (::var\"#28#30\")(θ) @ Main ~/.julia/dev/ARGridBootstrap/docs/jmd/assignment.jmd:7\nArguments\n  #self#::var\"#28#30\"{var\"#P#29\", var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}}\n  θ::Vector{Float64}\nLocals\n  @_3::UNION{NOTHING, TUPLE{INT64, INT64}}\n  @_4::Int64\n  D::Matrix{Float64}\n  Γ::Array{Float64, 3}\n  G::Array{Float64, 3}\n  Gi::Array{Float64, 3}\n  gn::Adjoint{Float64, Matrix{Float64}}\n  Ω::Hermitian{Float64, Matrix{Float64}}\n  k::Int64\n  n::Int64\n  p::Int64\n  giθ::Matrix{Float64}\n  @_15::UNION{NOTHING, TUPLE{INT64, INT64}}\n  j::Int64\n  i::Int64\nBody::Tuple{Int64, Int64, Int64, Adjoint{Float64, Matrix{Float64}}, Hermitian{Float64, Matrix{Float64}}, Matrix{Float64}, var\"#P#29\"}\n1 ─ %1  = Core.getfield(#self#, Symbol(\"#457#gi\"))::var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}\n│         (giθ = (%1)(θ))\n│         (p = Main.length(θ))\n│   %4  = Main.size(giθ)::Tuple{Int64, Int64}\n│   %5  = Base.indexed_iterate(%4, 1)::Core.PartialStruct(Tuple{Int64, Int64}, Any[Int64, Core.Const(2)])\n│         (n = Core.getfield(%5, 1))\n│         (@_4 = Core.getfield(%5, 2))\n│   %8  = Base.indexed_iterate(%4, 2, @_4::Core.Const(2))::Core.PartialStruct(Tuple{Int64, Int64}, Any[Int64, Core.Const(3)])\n│         (k = Core.getfield(%8, 1))\n│   %10 = Main.cov(giθ)::Matrix{Float64}\n│         (Ω = Main.Hermitian(%10))\n│   %12 = Core.getfield(#self#, Symbol(\"#457#gi\"))::var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}\n│   %13 = (%12)(θ)::Matrix{Float64}\n│   %14 = (:dims,)::Core.Const((:dims,))\n│   %15 = Core.apply_type(Core.NamedTuple, %14)::Core.Const(NamedTuple{(:dims,)})\n│   %16 = Core.tuple(1)::Core.Const((1,))\n│   %17 = (%15)(%16)::Core.Const((dims = 1,))\n│   %18 = Core.kwcall(%17, Main.mean, %13)::Matrix{Float64}\n│         (gn = Main.:var\"'\"(%18))\n│         (Gi = Main.zeros(n, k, p))\n│   %21 = ForwardDiff.jacobian!::Core.Const(ForwardDiff.jacobian!)\n│   %22 = Gi::Array{Float64, 3}\n│   %23 = Core.getfield(#self#, Symbol(\"#457#gi\"))::var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}\n│         (%21)(%22, %23, θ)\n│         (Gi = Main.reshape(Gi, n, k, p))\n│   %26 = (:dims,)::Core.Const((:dims,))\n│   %27 = Core.apply_type(Core.NamedTuple, %26)::Core.Const(NamedTuple{(:dims,)})\n│   %28 = Core.tuple(1)::Core.Const((1,))\n│   %29 = (%27)(%28)::Core.Const((dims = 1,))\n│         (G = Core.kwcall(%29, Main.mean, Gi))\n│   %31 = Main.eltype(Gi)::Core.Const(Float64)\n│   %32 = p::Int64\n│   %33 = k::Int64\n│         (Γ = Main.zeros(%31, %32, %33, k))\n│   %35 = Main.eltype(Gi)::Core.Const(Float64)\n│   %36 = k::Int64\n│         (D = Main.zeros(%35, %36, p))\n│   %38 = (1:p)::Core.PartialStruct(UnitRange{Int64}, Any[Core.Const(1), Int64])\n│         (@_3 = Base.iterate(%38))\n│   %40 = (@_3 === nothing)::Bool\n│   %41 = Base.not_int(%40)::Bool\n└──       goto #7 if not %41\n2 ┄ %43 = @_3::Tuple{Int64, Int64}\n│         (j = Core.getfield(%43, 1))\n│   %45 = Core.getfield(%43, 2)::Int64\n│   %46 = (1:n)::Core.PartialStruct(UnitRange{Int64}, Any[Core.Const(1), Int64])\n│         (@_15 = Base.iterate(%46))\n│   %48 = (@_15 === nothing)::Bool\n│   %49 = Base.not_int(%48)::Bool\n└──       goto #5 if not %49\n3 ┄ %51 = @_15::Tuple{Int64, Int64}\n│         (i = Core.getfield(%51, 1))\n│   %53 = Core.getfield(%51, 2)::Int64\n│   %54 = Base.getindex(Γ, j, Main.:(:), Main.:(:))::Matrix{Float64}\n│   %55 = Main.:-::Core.Const(-)\n│   %56 = Base.getindex(Gi, i, Main.:(:), j)::Vector{Float64}\n│   %57 = Base.getindex(G, 1, Main.:(:), j)::Vector{Float64}\n│   %58 = Base.broadcasted(%55, %56, %57)::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{1}, Nothing, typeof(-), Tuple{Vector{Float64}, Vector{Float64}}}\n│   %59 = Base.materialize(%58)::Vector{Float64}\n│   %60 = Base.getindex(giθ, i, Main.:(:))::Vector{Float64}\n│   %61 = Main.:var\"'\"(%60)::Adjoint{Float64, Vector{Float64}}\n│   %62 = (%59 * %61)::Matrix{Float64}\n│   %63 = (%54 + %62)::Matrix{Float64}\n│         Base.setindex!(Γ, %63, j, Main.:(:), Main.:(:))\n│         (@_15 = Base.iterate(%46, %53))\n│   %66 = (@_15 === nothing)::Bool\n│   %67 = Base.not_int(%66)::Bool\n└──       goto #5 if not %67\n4 ─       goto #3\n5 ┄ %70 = Base.dotview(Γ, j, Main.:(:), Main.:(:))::SubArray{Float64, 2, Array{Float64, 3}, Tuple{Int64, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}}, true}\n│   %71 = Main.:/::Core.Const(/)\n│   %72 = Base.getindex(Γ, j, Main.:(:), Main.:(:))::Matrix{Float64}\n│   %73 = Base.broadcasted(%71, %72, n)::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{2}, Nothing, typeof(/), Tuple{Matrix{Float64}, Int64}}\n│         Base.materialize!(%70, %73)\n│   %75 = Base.getindex(G, 1, Main.:(:), j)::Vector{Float64}\n│   %76 = Base.getindex(Γ, j, Main.:(:), Main.:(:))::Matrix{Float64}\n│   %77 = Main.inv(Ω::Core.PartialStruct(Hermitian{Float64, Matrix{Float64}}, Any[Matrix{Float64}, Core.Const('U')]))::Core.PartialStruct(Hermitian{Float64, Matrix{Float64}}, Any[Matrix{Float64}, Core.Const('U')])\n│   %78 = (%76 * %77 * gn)::Matrix{Float64}\n│   %79 = (%75 - %78)::Matrix{Float64}\n│         Base.setindex!(D, %79, Main.:(:), j)\n│         (@_3 = Base.iterate(%38, %45))\n│   %82 = (@_3 === nothing)::Bool\n│   %83 = Base.not_int(%82)::Bool\n└──       goto #7 if not %83\n6 ─       goto #2\n7 ┄ %86 = n::Int64\n│   %87 = k::Int64\n│   %88 = p::Int64\n│   %89 = gn::Adjoint{Float64, Matrix{Float64}}\n│   %90 = Ω::Core.PartialStruct(Hermitian{Float64, Matrix{Float64}}, Any[Matrix{Float64}, Core.Const('U')])\n│   %91 = D::Matrix{Float64}\n│   %92 = Core.getfield(#self#, :P)::Core.Const(var\"#P#29\"())\n│   %93 = Core.tuple(%86, %87, %88, %89, %90, %91, %92)::Core.PartialStruct(Tuple{Int64, Int64, Int64, Adjoint{Float64, Matrix{Float64}}, Hermitian{Float64, Matrix{Float64}}, Matrix{Float64}, var\"#P#29\"}, Any[Int64, Int64, Int64, Adjoint{Float64, Matrix{Float64}}, Core.PartialStruct(Hermitian{Float64, Matrix{Float64}}, Any[Matrix{Float64}, Core.Const('U')]), Matrix{Float64}, var\"#P#29\"])\n└──       return %93\nI also added the where {F statement to ensure compiler specialization, and added the let gi=gi line to help with the performance of captured variables.\njulia&gt; @code_warntype klm(gi)(β0)\nMethodInstance for (::var\"#24#25\"{var\"#28#30\"{var\"#P#29\", var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}}})(::Vector{Float64})\n  from (::var\"#24#25\")(θ) @ Main ~/.julia/dev/ARGridBootstrap/docs/jmd/assignment.jmd:31\nArguments\n  #self#::var\"#24#25\"{var\"#28#30\"{var\"#P#29\", var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}}}\n  θ::Vector{Float64}\nLocals\n  @_3::Int64\n  P::var\"#P#29\"\n  D::Matrix{Float64}\n  Ω::Hermitian{Float64, Matrix{Float64}}\n  gn::Adjoint{Float64, Matrix{Float64}}\n  p::Int64\n  k::Int64\n  n::Int64\nBody::UNION{FLOAT64, COMPLEXF64}\n1 ─ %1  = Core.getfield(#self#, :SP)::var\"#28#30\"{var\"#P#29\", var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}}\n│   %2  = (%1)(θ)::Core.PartialStruct(Tuple{Int64, Int64, Int64, Adjoint{Float64, Matrix{Float64}}, Hermitian{Float64, Matrix{Float64}}, Matrix{Float64}, var\"#P#29\"}, Any[Int64, Int64, Int64, Adjoint{Float64, Matrix{Float64}}, Core.PartialStruct(Hermitian{Float64, Matrix{Float64}}, Any[Matrix{Float64}, Core.Const('U')]), Matrix{Float64}, var\"#P#29\"])\n│   %3  = Base.indexed_iterate(%2, 1)::Core.PartialStruct(Tuple{Int64, Int64}, Any[Int64, Core.Const(2)])\n│         (n = Core.getfield(%3, 1))\n│         (@_3 = Core.getfield(%3, 2))\n│   %6  = Base.indexed_iterate(%2, 2, @_3::Core.Const(2))::Core.PartialStruct(Tuple{Int64, Int64}, Any[Int64, Core.Const(3)])\n│         (k = Core.getfield(%6, 1))\n│         (@_3 = Core.getfield(%6, 2))\n│   %9  = Base.indexed_iterate(%2, 3, @_3::Core.Const(3))::Core.PartialStruct(Tuple{Int64, Int64}, Any[Int64, Core.Const(4)])\n│         (p = Core.getfield(%9, 1))\n│         (@_3 = Core.getfield(%9, 2))\n│   %12 = Base.indexed_iterate(%2, 4, @_3::Core.Const(4))::Core.PartialStruct(Tuple{Adjoint{Float64, Matrix{Float64}}, Int64}, Any[Adjoint{Float64, Matrix{Float64}}, Core.Const(5)])\n│         (gn = Core.getfield(%12, 1))\n│         (@_3 = Core.getfield(%12, 2))\n│   %15 = Base.indexed_iterate(%2, 5, @_3::Core.Const(5))::Core.PartialStruct(Tuple{Hermitian{Float64, Matrix{Float64}}, Int64}, Any[Core.PartialStruct(Hermitian{Float64, Matrix{Float64}}, Any[Matrix{Float64}, Core.Const('U')]), Core.Const(6)])\n│         (Ω = Core.getfield(%15, 1))\n│         (@_3 = Core.getfield(%15, 2))\n│   %18 = Base.indexed_iterate(%2, 6, @_3::Core.Const(6))::Core.PartialStruct(Tuple{Matrix{Float64}, Int64}, Any[Matrix{Float64}, Core.Const(7)])\n│         (D = Core.getfield(%18, 1))\n│         (@_3 = Core.getfield(%18, 2))\n│   %21 = Base.indexed_iterate(%2, 7, @_3::Core.Const(7))::Core.PartialStruct(Tuple{var\"#P#29\", Int64}, Any[var\"#P#29\", Core.Const(8)])\n│         (P = Core.getfield(%21, 1))\n│   %23 = n::Int64\n│   %24 = Main.:var\"'\"(gn)::Matrix{Float64}\n│   %25 = Ω::Core.PartialStruct(Hermitian{Float64, Matrix{Float64}}, Any[Matrix{Float64}, Core.Const('U')])\n│   %26 = (-1 / 2)::Core.Const(-0.5)\n│   %27 = (%25 ^ %26)::UNION{HERMITIAN{FLOAT64, MATRIX{FLOAT64}}, MATRIX{COMPLEXF64}}\n│   %28 = Ω::Core.PartialStruct(Hermitian{Float64, Matrix{Float64}}, Any[Matrix{Float64}, Core.Const('U')])\n│   %29 = (-1 / 2)::Core.Const(-0.5)\n│   %30 = (%28 ^ %29)::UNION{HERMITIAN{FLOAT64, MATRIX{FLOAT64}}, MATRIX{COMPLEXF64}}\n│   %31 = (%30 * D)::UNION{MATRIX{COMPLEXF64}, MATRIX{FLOAT64}}\n│   %32 = (P)(%31)::UNION{MATRIX{COMPLEXF64}, MATRIX{FLOAT64}}\n│   %33 = Ω::Core.PartialStruct(Hermitian{Float64, Matrix{Float64}}, Any[Matrix{Float64}, Core.Const('U')])\n│   %34 = (-1 / 2)::Core.Const(-0.5)\n│   %35 = (%33 ^ %34)::UNION{HERMITIAN{FLOAT64, MATRIX{FLOAT64}}, MATRIX{COMPLEXF64}}\n│   %36 = (%24 * %27 * %32 * %35 * gn)::UNION{MATRIX{COMPLEXF64}, MATRIX{FLOAT64}}\n│   %37 = Base.getindex(%36, 1)::UNION{FLOAT64, COMPLEXF64}\n│   %38 = (%23 * %37)::UNION{FLOAT64, COMPLEXF64}\n└──       return %38\nThere’s still a type-instability in klm. This one is harder to understand. It is due to the fact that the appropriate meaning of a matrix square root depends on the nature of the matrix. In particular, the value could be a complex valued matrix instead of real valued. We know that Ω should be positive definite with a real matrix square root. We can compute its square root from its Eigen decomposition and avoid the type instability.\nfunction klm(gi::F ) where {F &lt;: Function}\n  let gi=gi\n    function(θ)\n      (n,k,p,gn, Ω, D, P) = statparts(gi)(θ)\n      λ, v = eigen(Ω)\n      irΩ = v*diagm(λ.^(-1/2))*v'\n      return n*(gn'*irΩ*P(irΩ*D)*irΩ*gn)[1]\n    end\n  end\nend\nklm (generic function with 1 method)\njulia&gt; @code_warntype klm(gi)(β0)\nMethodInstance for (::var\"#31#32\"{var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}})(::Vector{Float64})\n  from (::var\"#31#32\")(θ) @ Main ~/.julia/dev/ARGridBootstrap/docs/jmd/assignment.jmd:4\nArguments\n  #self#::var\"#31#32\"{var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}}\n  θ::Vector{Float64}\nLocals\n  @_3::Val{:vectors}\n  @_4::Int64\n  irΩ::Matrix{Float64}\n  v::Matrix{Float64}\n  λ::Vector{Float64}\n  P::var\"#P#29\"\n  D::Matrix{Float64}\n  Ω::Hermitian{Float64, Matrix{Float64}}\n  gn::Adjoint{Float64, Matrix{Float64}}\n  p::Int64\n  k::Int64\n  n::Int64\nBody::Float64\n1 ─ %1  = Core.getfield(#self#, Symbol(\"#458#gi\"))::var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}\n│   %2  = Main.statparts(%1)::var\"#28#30\"{var\"#P#29\", var\"#26#27\"{Vector{Float64}, Matrix{Float64}, Matrix{Float64}}}\n│   %3  = (%2)(θ)::Core.PartialStruct(Tuple{Int64, Int64, Int64, Adjoint{Float64, Matrix{Float64}}, Hermitian{Float64, Matrix{Float64}}, Matrix{Float64}, var\"#P#29\"}, Any[Int64, Int64, Int64, Adjoint{Float64, Matrix{Float64}}, Core.PartialStruct(Hermitian{Float64, Matrix{Float64}}, Any[Matrix{Float64}, Core.Const('U')]), Matrix{Float64}, var\"#P#29\"])\n│   %4  = Base.indexed_iterate(%3, 1)::Core.PartialStruct(Tuple{Int64, Int64}, Any[Int64, Core.Const(2)])\n│         (n = Core.getfield(%4, 1))\n│         (@_4 = Core.getfield(%4, 2))\n│   %7  = Base.indexed_iterate(%3, 2, @_4::Core.Const(2))::Core.PartialStruct(Tuple{Int64, Int64}, Any[Int64, Core.Const(3)])\n│         (k = Core.getfield(%7, 1))\n│         (@_4 = Core.getfield(%7, 2))\n│   %10 = Base.indexed_iterate(%3, 3, @_4::Core.Const(3))::Core.PartialStruct(Tuple{Int64, Int64}, Any[Int64, Core.Const(4)])\n│         (p = Core.getfield(%10, 1))\n│         (@_4 = Core.getfield(%10, 2))\n│   %13 = Base.indexed_iterate(%3, 4, @_4::Core.Const(4))::Core.PartialStruct(Tuple{Adjoint{Float64, Matrix{Float64}}, Int64}, Any[Adjoint{Float64, Matrix{Float64}}, Core.Const(5)])\n│         (gn = Core.getfield(%13, 1))\n│         (@_4 = Core.getfield(%13, 2))\n│   %16 = Base.indexed_iterate(%3, 5, @_4::Core.Const(5))::Core.PartialStruct(Tuple{Hermitian{Float64, Matrix{Float64}}, Int64}, Any[Core.PartialStruct(Hermitian{Float64, Matrix{Float64}}, Any[Matrix{Float64}, Core.Const('U')]), Core.Const(6)])\n│         (Ω = Core.getfield(%16, 1))\n│         (@_4 = Core.getfield(%16, 2))\n│   %19 = Base.indexed_iterate(%3, 6, @_4::Core.Const(6))::Core.PartialStruct(Tuple{Matrix{Float64}, Int64}, Any[Matrix{Float64}, Core.Const(7)])\n│         (D = Core.getfield(%19, 1))\n│         (@_4 = Core.getfield(%19, 2))\n│   %22 = Base.indexed_iterate(%3, 7, @_4::Core.Const(7))::Core.PartialStruct(Tuple{var\"#P#29\", Int64}, Any[var\"#P#29\", Core.Const(8)])\n│         (P = Core.getfield(%22, 1))\n│   %24 = Main.eigen(Ω::Core.PartialStruct(Hermitian{Float64, Matrix{Float64}}, Any[Matrix{Float64}, Core.Const('U')]))::Eigen{Float64, Float64, Matrix{Float64}, Vector{Float64}}\n│   %25 = Base.indexed_iterate(%24, 1)::Tuple{Vector{Float64}, Val{:vectors}}\n│         (λ = Core.getfield(%25, 1))\n│         (@_3 = Core.getfield(%25, 2))\n│   %28 = Base.indexed_iterate(%24, 2, @_3)::Tuple{Matrix{Float64}, Val{:done}}\n│         (v = Core.getfield(%28, 1))\n│   %30 = v::Matrix{Float64}\n│   %31 = Main.:^::Core.Const(^)\n│   %32 = λ::Vector{Float64}\n│   %33 = (-1 / 2)::Core.Const(-0.5)\n│   %34 = Base.broadcasted(%31, %32, %33)::Core.PartialStruct(Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{1}, Nothing, typeof(^), Tuple{Vector{Float64}, Float64}}, Any[Core.Const(Base.Broadcast.DefaultArrayStyle{1}()), Core.Const(^), Core.PartialStruct(Tuple{Vector{Float64}, Float64}, Any[Vector{Float64}, Core.Const(-0.5)]), Nothing])\n│   %35 = Base.materialize(%34)::Vector{Float64}\n│   %36 = Main.diagm(%35)::Matrix{Float64}\n│   %37 = Main.:var\"'\"(v)::Adjoint{Float64, Matrix{Float64}}\n│         (irΩ = %30 * %36 * %37)\n│   %39 = n::Int64\n│   %40 = Main.:var\"'\"(gn)::Matrix{Float64}\n│   %41 = irΩ::Matrix{Float64}\n│   %42 = (irΩ * D)::Matrix{Float64}\n│   %43 = (P)(%42)::Matrix{Float64}\n│   %44 = irΩ::Matrix{Float64}\n│   %45 = (%40 * %41 * %43 * %44 * gn)::Matrix{Float64}\n│   %46 = Base.getindex(%45, 1)::Float64\n│   %47 = (%39 * %46)::Float64\n└──       return %47\nFixing these type instabilities speeds up the code by a factor of about 5.\n@benchmark klm(gi)(β0)\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  132.812 μs …   9.251 ms  ┊ GC (min … max):  0.00% … 90\n.89%\n Time  (median):     148.332 μs               ┊ GC (median):     0.00%\n Time  (mean ± σ):   174.327 μs ± 435.225 μs  ┊ GC (mean ± σ):  12.87% ±  5\n.07%\n\n                ▃▆██▅▂                                           \n  ▂▂▂▂▂▂▃▄▄▄▅▅▆████████▇▆▆▅▅▄▄▄▃▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂ ▃\n  133 μs           Histogram: frequency by time          186 μs &lt;\n\n Memory estimate: 219.61 KiB, allocs estimate: 1516."
  },
  {
    "objectID": "assignment.html#reducing-allocations-and-other-optimizations",
    "href": "assignment.html#reducing-allocations-and-other-optimizations",
    "title": "Coding for Performance",
    "section": "Reducing allocations and Other Optimizations",
    "text": "Reducing allocations and Other Optimizations\nProfiling reveals the majority of time is spent in the innermost loop of the statparts function. This loop allocates quite a bit because the arrays are using slices. We can avoid allocations by using @views and more broadcasting. See “Consider using views for slices” and “More dots”,\nfunction statparts(gi::F) where {F &lt;: Function}\n  function P(A::AbstractMatrix) # projection matrix\n    A*pinv(A'*A)*A'\n  end\n  let gi=gi\n    function(θ)\n      giθ = gi(θ)\n      p = length(θ)\n      (n, k) = size(giθ)\n      Ω = Hermitian(cov(giθ))\n      gn=mean(gi(θ), dims=1)'\n      iΩgn = Ω \\ gn\n      Gi = zeros(n,k,p)\n      ForwardDiff.jacobian!(Gi,gi,θ)\n      Gi = reshape(Gi, n , k, p)\n      G = mean(Gi, dims=1)\n      Γ = zeros(eltype(Gi),p,k,k)\n      D = zeros(eltype(Gi),k, p)\n      @inbounds for j in 1:p\n        @inbounds for i in 1:n\n          @views Γ[j,:,:] .+= (Gi[i,:,j] .- G[1,:,j]) * giθ[i,:]'\n        end\n        Γ[j,:,:] ./= n\n        @views D[:,j] .= G[1,:,j] .- Γ[j,:,:]*iΩgn\n      end\n      return(n,k,p,gn, Ω, D, P)\n    end\n  end\nend\n@benchmark klm(gi)(β0)\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  69.363 μs …   6.704 ms  ┊ GC (min … max):  0.00% … 92.\n90%\n Time  (median):     76.354 μs               ┊ GC (median):     0.00%\n Time  (mean ± σ):   86.922 μs ± 255.393 μs  ┊ GC (mean ± σ):  11.10% ±  3.\n73%\n\n               ▁▁▃▄▆▅▇▇▆█▆▇▄▃▂                                  \n  ▁▁▁▁▁▂▂▃▃▄▅▆█████████████████▇▆▅▄▃▃▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁ ▃\n  69.4 μs         Histogram: frequency by time           89 μs &lt;\n\n Memory estimate: 118.53 KiB, allocs estimate: 501.\nThe code is now about ten times faster than the original."
  },
  {
    "objectID": "assignment.html#footnotes",
    "href": "assignment.html#footnotes",
    "title": "Coding for Performance",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLike scalar variables, StaticArrays exist on the stack instead of the heap, so creating them is much less costly and they do not count toward the reported allocations.↩︎"
  },
  {
    "objectID": "index.html#functions",
    "href": "index.html#functions",
    "title": "ARGridBootstrap.jl",
    "section": "Functions",
    "text": "Functions\n\nARGridBootstrap.ar1_original\nARGridBootstrap.argridbootstrap_gpu\nARGridBootstrap.argridkernel!\nARGridBootstrap.b_est_mldivide\nARGridBootstrap.b_est_nox\nARGridBootstrap.b_est_original\nARGridBootstrap.b_est_stride\nARGridBootstrap.gridbootstrap\nARGridBootstrap.gridbootstrap_threaded\nARGridBootstrap.invsym\nARGridBootstrap.oneto\nARGridBootstrap.rngarray\nARGridBootstrap.simulate_estimate_arp\nARGridBootstrap.simulate_estimate_arp_lv\n\n\n\n\nAR\n# ARGridBootstrap.ar1_original — Function.\nar1_original(y0, a, e, rindex=T-&gt;rand(1:length(e), T))\nSimulate AR1 model by sampling errors from e with replacement.\ny[t] = a*y[t-1] + ϵ[t]\nArguments\n\ny0: initial value for y\na: AR parameter\ne: values of for error term. ϵ = e[rindex(T)]]\nrindex function that returns random index in 1:length(e)\n\nReturns\n\ny: vector of length T = length(e)\n\nsource\n# ARGridBootstrap.b_est_mldivide — Method.\nb_est_mldivide(y)\nEstimate AR(1) model with intercept and time trend.\ny[t] = θ[0] + θ[1]t + θ[2]y[t-1] + e[t]\nArguments\n\ny: vector\n\nReturns\n\nθ: estimated coefficients\nse: standard errors\ne: residuals\n\nsource\n# ARGridBootstrap.b_est_nox — Method.\nb_est_nox(y)\nEstimate AR(1) model with intercept and time trend.\ny[t] = θ[0] + θ[1]t + θ[2]y[t-1] + e[t]\nArguments\n\ny: vector\n\nReturns\n\nθ: estimated coefficients\nse: standard errors\ne: residualas\n\nsource\n# ARGridBootstrap.b_est_original — Method.\nb_est_original(y)\nEstimate AR(1) model with intercept and time trend\ny[t] = θ[0] + θ[1]t + θ[2]y[t-1] + e[t]\nArguments\n\ny: vector\n\nReturns\n\nθ: estimated coefficients\nse: standard errors\ne: residuals\n\nsource\n# ARGridBootstrap.b_est_stride — Method.\nb_est_stride(y)\nEstimate AR(1) model with intercept and time trend.\ny[t] = θ[0] + θ[1]t + θ[2]y[t-1] + e[t]\nArguments\n\ny: vector\n\nReturns\n\nθ: estimated coefficients\nse: standard errors\ne: residualas\n\nsource\n# ARGridBootstrap.invsym — Method.\nfast inverse function for statically sized 3x3 StrideArray\nsource\n# ARGridBootstrap.oneto — Method.\noneto(Val(N)) Creates at a compile time the tuple (1, 2, …, N)\nsource\n# ARGridBootstrap.simulate_estimate_arp — Method.\nsimulate_estimate_arp(y0, a, e, ar::Val{P}, rindex=T-&gt;rand(1:length(e),T))\nSimulates and estimates an AR(P) model. y is simulated as\ny[t] = a*y[t-1] + ϵ[t]\nand the estimate of θ from\ny[t] = θ[1] + θ[2]t + θ[3] y[t-1] + … + θ[P] y[t-P] + u[t]\nis computed.\nArguments\n\ny0 initial value of y\na AR(1) parameter\ne error terms to sample from ϵ[t] = e[rindex(1)]\nar::Val{P} order of autoregressive model to estimate\nrindex function that returns random index in 1:length(e)\n\nReturns\n\nθ estimated coefficients\nse standard errors\n\nsource\n# ARGridBootstrap.simulate_estimate_arp_lv — Method.\nsimulate_estimate_arp_lv(y0, a, e, ar::Val{P}, rindex=T-&gt;rand(1:length(e),T))\nSimulates and estimates an AR(P) model. Uses LoopVectorization.jl to produce fast code.\ny is simulated as\ny[t] = a*y[t-1] + ϵ[t]\nand the estimate of θ from\ny[t] = θ[1] + θ[2]t + θ[3] y[t-1] + … + θ[P] y[t-P] + u[t]\nis computed.\nArguments\n\ny0 initial value of y\na AR(1) parameter\ne error terms to sample from ϵ[t] = e[rindex(1)]\nar::Val{P} order of autoregressive model to estimate\nrindex function that returns random index in 1:length(e)\n\nReturns\n\nθ estimated coefficients\nse standard errors\n\nsource\n\n\n\n\nGrid Bootstrap\n# ARGridBootstrap.argridbootstrap_gpu — Method.\nargridbootstrap_gpu(e; αgrid = 0.84:(0.22/20):1.06,\n                      nboot=199, RealType = Float32)\nComputes grid bootstrap estimates for an AR(1) model.\nFor each α ∈ grid, repeatedly simulate data with parameter α and then compute an estimate.\nArguments\n\ne vector error terms that will be resampled with replacement to generate bootstrap sample\ngrid grid of parameter values. For each value, nboot datasets will be simulated and estimates computed.\nnboot\nRealType type of numbers for GPU computation. On many GPUs, Float32 will have better performance than Float64.\n\nReturns\n\nba hatα - α for each grid value and simulated dataset\nt t-stat for each grid value and simulated dataset\n\nsource\n# ARGridBootstrap.argridkernel! — Method.\nargridkernel!(ba,bootq, bootse, ar::Val{P}, e, ei, αgrid)\nGPU kernel for simulation and estimation of AR(P) model.\nArguments (modified on return)\n\nba: nboot × ngrid array. Will be filled with bootstrap estimates of α grid values of true α\nbootq: nboot × ngrid array. Will be filled with bootstrap estimates of α\nbootse: nboot × ngrid array. Will be filled with standard errors of α for each bootstrap repetition\n\nArguments (not modified)\n\nar::Val{P} : autoregressive order for estimation. Simulated model will always be AR(1) with 0 intercept and time trend, but estimation will use an AR(P) model with intercept and time trend. Only the AR(1) parameter estimate is included in ba, bootq, and bootse.\ne : error terms to draw with replacement\nei : nboot × ngrid × length(e) array of indices of e to use to generate bootstrap sample1\nαgrid : length ngrid values of AR(1) parameter to perform bootstrap on.\n\nReturns nothing, but modifies in place ba, bootq, and bootse\nsource\n# ARGridBootstrap.gridbootstrap — Function.\ngridbootstrap(estimator, simulator,\n              grid::AbstractVector,\n              nboot=199)\nComputes grid bootstrap estimates a single parameter model.\nFor each α ∈ grid, repeatedly simulate data with parameter α and then compute an estimate.\nArguments\n\nestimator function of output of simulator that returns a 2-tuple containing an estimate of α and its standard error.\nsimulator function that given α simulates data that can be used to estimate α\ngrid grid of parameter values. For each value, nboot datasets will be simulated and estimates computed.\nnboot\n\nReturns\n\nba hatα - α for each grid value and simulated dataset\nt t-stat for each grid value and simulated dataset\n\nsource\n# ARGridBootstrap.gridbootstrap_threaded — Function.\ngridbootstrap_threaded(estimator, simulator,\n                grid::AbstractVector,\n                nboot=199, rng=rngarray(nthreads())\nComputes grid bootstrap estimates a single parameter model.\nMultithreaded version.\nFor each α ∈ grid, repeatedly simulate data with parameter α and then compute an estimate.\nArguments\n\nestimator function of output of simulator that returns a 2-tuple containing an estimate of α and its standard error.\nsimulator function that given α and rng, simulates data that can be used to estimate α\ngrid grid of parameter values. For each value, nboot datasets will be simulated and estimates computed.\nnboot number of bootstrap simulations per grid point\n\nReturns\n\nba hatα - α for each grid value and simulated dataset\nt t-stat for each grid value and simulated dataset\n\nsource\n# ARGridBootstrap.rngarray — Method.\nrngarray(n)\nCreate n rng states that will not overlap for 10^20 steps.\nNote: this will be unneeded in Julia 1.3 when thread-safe RNG is included.\nsource"
  },
  {
    "objectID": "threads.html",
    "href": "threads.html",
    "title": "Coding for Performance",
    "section": "",
    "text": "Current computers almost all have multiple cores. We can divide the time it takes our code by up to the number of cores we have (but usually less) by writing multi-threaded code. Multi-threaded code performs multiple tasks at once with shared memory. Before you begin writing multi-threaded code, you should make sure your code isn’t already using all available cores. It is likely that the BLAS and Lapack libraries that Julia uses for linear algebra are multi-threaded. If you code is dominated by large matrix operations, it may already be using all available cores. In that case, there will not be much benefit from additional multi-threading.\nRead “The Basics of Single Node Parallel Computing” Rackauckus (2019) (Rackauckas 2019) .\nOnce we have decided that the code might benefit from multi-threading, we should look for loops (or other independent tasks) that can be multi-threaded. There is some overhead from creating threads and communicating among them. Multi-threading generally works best for loops where each iteration involves substantial work, and each iteration is independent of all others. The loops over grid points and bootstrap repetitions in gridbootstrap are perfect candidates. We don’t care about the order in which these loops get executed. The result of each iteration is (mostly) independent of all others.\nusing ARGridBootstrap, CodeTracking, Random, BenchmarkTools, Profile, ProfileCanvas\nfunction code_md(s)\n  println(\"```julia\\n\"*s*\"\\n```\\n\")\nend\nT = 200\ne = randn(T)\ny0 = 0\na = 0.9\ny = ar1_original(y0, a, e)\nest = b_est_original(y)\nαgrid = 0.84:(0.22/50):1.06\nnboot= 199\nwrapper(b_est) = function(x)\n  out=b_est(x)\n  (out.θ[3], out.se[3])\nend\n\n\ns=@code_string gridbootstrap_threaded(wrapper(b_est_original), (a, rng)-&gt;ar1_original(y0, a, est.e, n-&gt;rand(rng,1:(T-1),n)),αgrid, 2)\ncode_md(s)\nfunction gridbootstrap_threaded(estimator, simulator,\n                                grid::AbstractVector,\n                                nboot=199)\n  g = length(grid)\n  bootq = zeros(nboot, g)\n  ba    = zeros(nboot, g)\n  bootse = zeros(nboot,g)\n  #@threads for ak in 1:g\n  #  for j in 1:nboot\n  @threads for ind ∈ CartesianIndices(ba)\n    j = ind[1]\n    ak = ind[2]\n    (bootq[j,ak], bootse[j,ak]) = estimator(simulator(grid[ak],Random.TaskLocalRNG()))\n    ba[j,ak] = bootq[j,ak] - grid[ak]\n  end\n  ts = ba./bootse\n  (ba=ba, t=ts)\nend\n\n\n\nNow, let’s try multi-threading the original version of the code.\njulia&gt; using Base.Threads\n\njulia&gt; println(\"Single thread, original version\")\nSingle thread, original version\n\njulia&gt; @benchmark begin \n         (b,t) = gridbootstrap(wrapper(b_est_original), a-&gt;ar1_original(y0, a, est.e),\n                               αgrid, 199)\n       end\nBenchmarkTools.Trial: 27 samples with 1 evaluation.\n Range (min … max):  175.276 ms … 199.619 ms  ┊ GC (min … max): 11.56% … 10.62%\n Time  (median):     186.845 ms               ┊ GC (median):    16.06%\n Time  (mean ± σ):   186.054 ms ±   4.257 ms  ┊ GC (mean ± σ):  15.72% ±  1.64%\n\n  ▁                    ▁ ▁  ▁▄ ▄▄▁█                              \n  █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▁█▆█▁▁██▆████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆ ▁\n  175 ms           Histogram: frequency by time          200 ms &lt;\n\n Memory estimate: 219.44 MiB, allocs estimate: 345075.\njulia&gt; println(\"$(Threads.nthreads()) threads, original version\")\n40 threads, original version\n\njulia&gt; @benchmark begin \n         (b,t) = gridbootstrap_threaded(wrapper(b_est_original),\n                                        (a, rng)-&gt;ar1_original(y0, a, est.e, n-&gt;rand(rng,1:(T-1),n)),\n                                        αgrid, 199)\n       end\nBenchmarkTools.Trial: 32 samples with 1 evaluation.\n Range (min … max):  102.512 ms … 661.604 ms  ┊ GC (min … max):  0.00% … 81.64%\n Time  (median):     104.351 ms               ┊ GC (median):     0.00%\n Time  (mean ± σ):   158.058 ms ± 161.796 ms  ┊ GC (mean ± σ):  31.58% ± 24.16%\n\n  █                                                              \n  █▄▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▃ ▁\n  103 ms           Histogram: frequency by time          662 ms &lt;\n\n Memory estimate: 311.76 MiB, allocs estimate: 6383971.\nThe execution times are nearly identical on my computer. The reason is that the computation is dominated by the creation of X and multiplying X'*X and X'*y. These operations are already multi-threaded in the BLAS library being used. It is possible that first calling using LinearAlgebra; BLAS.set_num_threads(1) would improve the performance of the multi-threaded bootstrap.\n\n\n\njulia&gt; println(\"Single thread, fastest version\")\nSingle thread, fastest version\n\njulia&gt; estimator(y0=y0,e=est.e) = function(a)\n         out = simulate_estimate_arp(y0,a,e)\n         (out.θ[3], out.se[3])\n       end\nestimator (generic function with 3 methods)\n\njulia&gt; @benchmark  (b,t) = gridbootstrap(estimator(), a-&gt;a, αgrid, nboot)\nBenchmarkTools.Trial: 242 samples with 1 evaluation.\n Range (min … max):  18.752 ms … 48.284 ms  ┊ GC (min … max): 0.00% … 58.59%\n Time  (median):     19.663 ms              ┊ GC (median):    0.00%\n Time  (mean ± σ):   20.719 ms ±  4.339 ms  ┊ GC (mean ± σ):  3.86% ±  9.76%\n\n  ▆█▇▆▃▁                                                       \n  ██████▇▆▄▁▁▁▁▁▆▄▄▁▁▆▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▁▁▁▄▁▁▁▁▁▁▁▁▇ ▆\n  18.8 ms      Histogram: log(frequency) by time      42.7 ms &lt;\n\n Memory estimate: 2.94 MiB, allocs estimate: 60904.\njulia&gt; println(\"$(Threads.nthreads()) threads, fastest version\")\n40 threads, fastest version\n\njulia&gt; estimator_threaded(y0=y0,e=est.e)=function(foo)\n         (a, rng) = foo\n         out=simulate_estimate_arp(y0,a,e,Val(1),()-&gt;rand(rng,1:length(e)))\n         (out.θ[3], out.se[3])\n       end\nestimator_threaded (generic function with 3 methods)\n\njulia&gt; @benchmark (bs, ts) = gridbootstrap_threaded(estimator_threaded(),(a,rng)-&gt;(a,rng), αgrid,nboot)\nBenchmarkTools.Trial: 1507 samples with 1 evaluation.\n Range (min … max):  1.620 ms … 141.653 ms  ┊ GC (min … max):  0.00% … 97.00%\n Time  (median):     2.524 ms               ┊ GC (median):     0.00%\n Time  (mean ± σ):   3.301 ms ±   8.923 ms  ┊ GC (mean ± σ):  18.36% ±  6.66%\n\n         ██▅▇▃                                                 \n  ▄▅▅▄▇▆▆█████████▇▅▅▄▅▃▄▃▃▂▂▂▂▃▂▃▂▂▃▂▂▂▂▁▂▂▁▂▂▂▁▂▁▂▂▁▂▂▂▁▂▂▂ ▃\n  1.62 ms         Histogram: frequency by time        6.71 ms &lt;\n\n Memory estimate: 2.97 MiB, allocs estimate: 61138.\nNotice how the speedup from using multiple threads is far less than number of cores. On my computer, the threaded version of the code is about 7 times faster, even though my computer has 40 “cores” (or 20 physical cores. My computer has 2 processors with 10 cores each, and each core is hyperthreaded into 2. The OS sees 40 processors, but half of them are sharing substantial resources). A speedup far less than the number of cores is typical. Creating and managing multiple threads creates some overhead. Moreover, cores must share various resources; most notably RAM and some cache."
  },
  {
    "objectID": "threads.html#multi-threaded-grid-bootstrap",
    "href": "threads.html#multi-threaded-grid-bootstrap",
    "title": "Coding for Performance",
    "section": "",
    "text": "s=@code_string gridbootstrap_threaded(wrapper(b_est_original), (a, rng)-&gt;ar1_original(y0, a, est.e, n-&gt;rand(rng,1:(T-1),n)),αgrid, 2)\ncode_md(s)\nfunction gridbootstrap_threaded(estimator, simulator,\n                                grid::AbstractVector,\n                                nboot=199)\n  g = length(grid)\n  bootq = zeros(nboot, g)\n  ba    = zeros(nboot, g)\n  bootse = zeros(nboot,g)\n  #@threads for ak in 1:g\n  #  for j in 1:nboot\n  @threads for ind ∈ CartesianIndices(ba)\n    j = ind[1]\n    ak = ind[2]\n    (bootq[j,ak], bootse[j,ak]) = estimator(simulator(grid[ak],Random.TaskLocalRNG()))\n    ba[j,ak] = bootq[j,ak] - grid[ak]\n  end\n  ts = ba./bootse\n  (ba=ba, t=ts)\nend"
  },
  {
    "objectID": "threads.html#some-libraries-are-already-multi-threaded",
    "href": "threads.html#some-libraries-are-already-multi-threaded",
    "title": "Coding for Performance",
    "section": "",
    "text": "Now, let’s try multi-threading the original version of the code.\njulia&gt; using Base.Threads\n\njulia&gt; println(\"Single thread, original version\")\nSingle thread, original version\n\njulia&gt; @benchmark begin \n         (b,t) = gridbootstrap(wrapper(b_est_original), a-&gt;ar1_original(y0, a, est.e),\n                               αgrid, 199)\n       end\nBenchmarkTools.Trial: 27 samples with 1 evaluation.\n Range (min … max):  175.276 ms … 199.619 ms  ┊ GC (min … max): 11.56% … 10.62%\n Time  (median):     186.845 ms               ┊ GC (median):    16.06%\n Time  (mean ± σ):   186.054 ms ±   4.257 ms  ┊ GC (mean ± σ):  15.72% ±  1.64%\n\n  ▁                    ▁ ▁  ▁▄ ▄▄▁█                              \n  █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▁█▆█▁▁██▆████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆ ▁\n  175 ms           Histogram: frequency by time          200 ms &lt;\n\n Memory estimate: 219.44 MiB, allocs estimate: 345075.\njulia&gt; println(\"$(Threads.nthreads()) threads, original version\")\n40 threads, original version\n\njulia&gt; @benchmark begin \n         (b,t) = gridbootstrap_threaded(wrapper(b_est_original),\n                                        (a, rng)-&gt;ar1_original(y0, a, est.e, n-&gt;rand(rng,1:(T-1),n)),\n                                        αgrid, 199)\n       end\nBenchmarkTools.Trial: 32 samples with 1 evaluation.\n Range (min … max):  102.512 ms … 661.604 ms  ┊ GC (min … max):  0.00% … 81.64%\n Time  (median):     104.351 ms               ┊ GC (median):     0.00%\n Time  (mean ± σ):   158.058 ms ± 161.796 ms  ┊ GC (mean ± σ):  31.58% ± 24.16%\n\n  █                                                              \n  █▄▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▃ ▁\n  103 ms           Histogram: frequency by time          662 ms &lt;\n\n Memory estimate: 311.76 MiB, allocs estimate: 6383971.\nThe execution times are nearly identical on my computer. The reason is that the computation is dominated by the creation of X and multiplying X'*X and X'*y. These operations are already multi-threaded in the BLAS library being used. It is possible that first calling using LinearAlgebra; BLAS.set_num_threads(1) would improve the performance of the multi-threaded bootstrap."
  },
  {
    "objectID": "threads.html#multi-threading-where-it-matters",
    "href": "threads.html#multi-threading-where-it-matters",
    "title": "Coding for Performance",
    "section": "",
    "text": "julia&gt; println(\"Single thread, fastest version\")\nSingle thread, fastest version\n\njulia&gt; estimator(y0=y0,e=est.e) = function(a)\n         out = simulate_estimate_arp(y0,a,e)\n         (out.θ[3], out.se[3])\n       end\nestimator (generic function with 3 methods)\n\njulia&gt; @benchmark  (b,t) = gridbootstrap(estimator(), a-&gt;a, αgrid, nboot)\nBenchmarkTools.Trial: 242 samples with 1 evaluation.\n Range (min … max):  18.752 ms … 48.284 ms  ┊ GC (min … max): 0.00% … 58.59%\n Time  (median):     19.663 ms              ┊ GC (median):    0.00%\n Time  (mean ± σ):   20.719 ms ±  4.339 ms  ┊ GC (mean ± σ):  3.86% ±  9.76%\n\n  ▆█▇▆▃▁                                                       \n  ██████▇▆▄▁▁▁▁▁▆▄▄▁▁▆▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▁▁▁▄▁▁▁▁▁▁▁▁▇ ▆\n  18.8 ms      Histogram: log(frequency) by time      42.7 ms &lt;\n\n Memory estimate: 2.94 MiB, allocs estimate: 60904.\njulia&gt; println(\"$(Threads.nthreads()) threads, fastest version\")\n40 threads, fastest version\n\njulia&gt; estimator_threaded(y0=y0,e=est.e)=function(foo)\n         (a, rng) = foo\n         out=simulate_estimate_arp(y0,a,e,Val(1),()-&gt;rand(rng,1:length(e)))\n         (out.θ[3], out.se[3])\n       end\nestimator_threaded (generic function with 3 methods)\n\njulia&gt; @benchmark (bs, ts) = gridbootstrap_threaded(estimator_threaded(),(a,rng)-&gt;(a,rng), αgrid,nboot)\nBenchmarkTools.Trial: 1507 samples with 1 evaluation.\n Range (min … max):  1.620 ms … 141.653 ms  ┊ GC (min … max):  0.00% … 97.00%\n Time  (median):     2.524 ms               ┊ GC (median):     0.00%\n Time  (mean ± σ):   3.301 ms ±   8.923 ms  ┊ GC (mean ± σ):  18.36% ±  6.66%\n\n         ██▅▇▃                                                 \n  ▄▅▅▄▇▆▆█████████▇▅▅▄▅▃▄▃▃▂▂▂▂▃▂▃▂▂▃▂▂▂▂▁▂▂▁▂▂▂▁▂▁▂▂▁▂▂▂▁▂▂▂ ▃\n  1.62 ms         Histogram: frequency by time        6.71 ms &lt;\n\n Memory estimate: 2.97 MiB, allocs estimate: 61138.\nNotice how the speedup from using multiple threads is far less than number of cores. On my computer, the threaded version of the code is about 7 times faster, even though my computer has 40 “cores” (or 20 physical cores. My computer has 2 processors with 10 cores each, and each core is hyperthreaded into 2. The OS sees 40 processors, but half of them are sharing substantial resources). A speedup far less than the number of cores is typical. Creating and managing multiple threads creates some overhead. Moreover, cores must share various resources; most notably RAM and some cache."
  }
]