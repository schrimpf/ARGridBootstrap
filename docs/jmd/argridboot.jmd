---
title       : "Coding for Performance"
subtitle    : "1: Optimizing Single Threaded Code"
author      : Paul Schrimpf
date        : `j using Dates; print(Dates.today())`
bibliography: "perf.bib"
---


# Introduction

Today we will look into some methods to improve the speed of our
code. Although speed is sometimes important, never forget that speed
should be low on your list of priorities when writing code. You should
prioritize correctness and maintainability ahead of
performance. Nonetheless, performance does matter for some problems.

If you have not already, be sure to read [the Peformance Tips section of Julia Docs](https://docs.julialang.org/en/v1/manual/performance-tips/#man-performance-tips-1).

Also, read Rackauckas's notes on ["Optimizing Serial Code."](https://mitmath.github.io/18337/lecture2/optimizing) [@rackauckas2019a].

# Grid bootstrap

As a motivating example we will look at the gridded bootstrap of
Hansen (1999)[@hansen99].

Gauss, Matlab, and R code implementing Hansen's method is available on
[Hansen's
website](https://www.ssc.wisc.edu/~bhansen/progs/restat_99.html). The
Julia code below is more or less a direct translation from Hansen's R
code. Since this is a translation from R of a translation from Gauss,
this code will not necessarily follow best practices for Julia.

```julia; echo=false; results="hidden"
using ARGridBootstrap, CodeTracking
function code_md(s)
  println("```julia\n"*s*"\n```\n")
end
```

```julia; results="raw"
T = 200
e = randn(T)
y0 = 0
a = 0.9
s = @code_string b_est_original(e)
code_md(s)
```

```julia; results="raw"
s=@code_string ar1_original(y0,a,e)
code_md(s)
```

```julia; results="raw"
 s = @code_string gridbootstrap(b_est_original, a->a, 0.5:0.1:1, 99)
code_md(s)
```

# Improving performance

Now, let's run this code and time it. Note that we are running this
with only 50 grid points and 199 bootstrap replications. In real use,
you would want more like 999 bootstrap replications or more, and perhaps more
grid points.

```julia;
# simulate some data
using Random, BenchmarkTools, Profile, ProfileCanvas
T = 200
e = randn(T)
y0 = 0
a = 0.9
y = ar1_original(y0, a, e)
est = b_est_original(y)
αgrid = 0.84:(0.22/50):1.06
nboot= 199
wrapper(b_est) = function(x)
  out=b_est(x)
  (out.θ[3], out.se[3])
end
```
## Initial Benchmark and Profile

```julia; cache=true
benchorig=@benchmark (b,t) = gridbootstrap(wrapper(b_est_original), a->ar1_original(y0, a, est.e),
                             αgrid, nboot)
```

To make code faster, we should begin by profiling.

```julia
# only to make profile results show nicely in generated html
# for interactive use, just use @profview in place of @profile
function profilehtmlstring() 
  buf = IOBuffer()
  show(buf, MIME("text/html"), ProfileCanvas.view(Profile.fetch()))
  s=String(take!(buf))
  println("\n\n"*s*"\n")
end
```

```julia; cache=true; results="raw"
using Profile, ProfileCanvas
Profile.clear();
Profile.init(n=10^7,delay=0.0001);
@profile (b,t) = gridbootstrap(wrapper(b_est_original), a->ar1_original(y0, a, est.e),
                               αgrid, 999)
profilehtmlstring()
```

The profiler works very simply. Every 0.0001 seconds, the line of code
being executed gets recorded. There are then various tools for printing and visualizing the results. The `@profview` macro shows a 
[flame graph](https://queue.acm.org/detail.cfm?id=2927301). The default view might be a bit strange. The base of the flame graph often 
includes Julia's repl and various other things that can be ignored. If you click on the graph, it will zoom in. You can use mouse wheel 
up to zoom back out.  

::: {.callout-tip}
In VSCode, you can just use `@profview` in place of `@profile` and the profile flamegraph will open in a panel within VSCode.
:::


## Removing Redudant Operations

::: {.callout-warning}
The following was true on an older version of Julia, but now there are no 
gains from eliminating `inv`.
:::

From the output (these
numbers can vary quite a bit from run to run), we see
there were 640 ticks in ` gridbootstrap_original` (exact numbers will
vary on each execution, but relative ones should be similar), and
almost all of these occurred within `inv`.  If we want the
code to be faster, we should focus on these lines.  Calling both `inv`
and `\` is redundant; we should combine these computations.


```julia; results="raw"
s = @code_string b_est_mldivide(y)
code_md(s)
```

```julia; cache=true
benchml=@benchmark (b,t) = gridbootstrap(wrapper(b_est_mldivide), a->ar1_original(y0, a, est.e),
                             αgrid, nboot)
```
~~From this, we get a speedup by about a factor of 4 on my computer.~~ 
This used to make a big difference, but no longer seems to matter.

## Reducing Allocations

```julia; cache=true; results="raw"
Profile.clear()
@profile (b,t) = gridbootstrap(wrapper(b_est_mldivide), a->ar1_original(y0, a, est.e),
                               αgrid, 999)
profilehtmlstring()                            
```

Now, the most time consuming parts of the code are, unsurprisingly,
the call to ` \`, and, perhaps surprisingly, ` hcat` from
creating ` x`. Allocating and copying memory is relatively slow. The
creation of ` x` involves both. 

### Caching Intermediate Arrays

One option is to preallocate an arrays and reuse them. The struct `bEstCache` does this.
```julia; cache=true
b_est_cache = ARGridBootstrap.bEstCached(T-1)
benchcache=@benchmark gridbootstrap(wrapper(b_est_cache), a->ar1_original(y0, a, est.e), 
                                    αgrid, nboot)
```

```julia; cache=true; results="raw"
Profile.clear()
@profview (b,t) = gridbootstrap(wrapper(b_est_cache), a->ar1_original(y0, a, est.e),
                               αgrid, 999)
profilehtmlstring()
```

### Eliminating Intermediate Arrays
Better yet, we can avoid creating `x` by just accumulating $X'y$ and $X'X$ in a loop.

```julia; results="raw"
s = @code_string b_est_nox(y)
code_md(s)
```

We put the two main loops into separate functions both for organization and to 
allow us to focus on optimizing these loops below.

```julia; results="raw"
s=@code_string ARGridBootstrap.xx_xy!(zeros(3,3),zeros(3),y)
code_md(s)
```

```julia; results="raw"
s=@code_string ARGridBootstrap.resids!(zeros(length(y)-1),y,zeros(3))
code_md(s)
```


```julia; cache=true
benchnox=@benchmark (b,t) = gridbootstrap(wrapper(b_est_nox), a->ar1_original(y0, a, est.e),
                             αgrid, nboot)
```

We have further cut the time by a factor of two. However, this performance optimization has been costly in terms of readability and extensibility
of our code. If we wanted to fit an AR(p) model instead of AR(1), the
` b_est_nox` function would be more difficult to modify than the
` b_est_mldivide` version.

We additionally gained some performance by using mutable `StaticArrays` to hold $X'X$ and $X'y$. 
```julia; cache=true
xx = zeros(3,3)
xy = zeros(3)
@benchmark ARGridBootstrap.xx_xy!(xx,xy,y)
```

```julia; cache=true
using StaticArrays
xx = @MMatrix zeros(3,3)
xy = @MVector zeros(3)
@benchmark ARGridBootstrap.xx_xy!(xx,xy,y)
```
# SIMD

To get full performance from modern CPUs, it is essential to use 
Single Instruction, Multiple Data instructions (also known as vectorized CPU instructions) 
in our code. These are special CPU instruction that allow applying an operation to multiple 
numbers at once. The LLVM compiler that Julia uses tries to automatically use these 
instructions when it is sure that it is safe to do so. 
See ["Demystifying auto vectorization in Julia"](https://www.juliabloggers.com/demystifying-auto-vectorization-in-julia/) for more information.

The compiler is not always successful in using SIMD instructions, so manual 
usage of SIMD instructions can often help. 

## LoopVectorization.jl

As mentioned above, the Julia compiler tries to automactically use SIMD instructions when it 
is safe to do so. SIMD instructions often change the order of operations, and since
floating point math is not exactly commutative. The compiler tries to avoid reordering 
operations, but this often prevents SIMD use. The macro `@simd` tells the compiler
to not worry about reordering operations and insert SIMD instructions more aggresively. Still,
there are some SIMD operations that the compiler will not insert automatically.

The [LoopVectorization.jl](https://github.com/JuliaSIMD/LoopVectorization.jl) package defines
a macro, `@turbo` that more aggresively inserts SIMD instructions. This can make a 
large difference for some loops and broadcasts.

```julia; cache=true
e = zeros(length(y)-1)
θ = @MVector zeros(3)
@benchmark ARGridBootstrap.resids!($e,$y,$θ)
```

```julia; cache=true
@benchmark ARGridBootstrap.resids_turbo!($e,$y,$θ)
```

We can also write SIMD instructions ourselves. The [SIMD.jl](https://github.com/eschnett/SIMD.jl) 
package makes this somewhat accessible. For an example, `resids_simd` uses this package to
match performance of the `@turbo` version. 

```julia; cache=true
@benchmark ARGridBootstrap.resids_simd!($e,$y,$θ, Val(8))
```

Generally, if `@turbo` successfully inserted SIMD instructions 
and made your code substantially faster, it will not be worth your effort to try to manually 
write SIMD code. However, `@turbo` will not always be able to insert SIMD instructions.
One way to check is through benchmarking. Another way is to inspect 
`@code_llvm ARGridBootstrap.resids_turbo!(e,y,θ)`. Things like `fadd fast <4 x double>` are 
SIMD instructions. The `<4 x double>` part is the key sign. In contrast, something like 
`%26 = fsub double %24, %25` are scalar instructions. 

The loops in `xx_xy!` are not automatically vectorized. Part of the issue is that
`@turbo` cannot tell that `xx` and `xy` are statically allocated. If we rewrite 
the code to use scalars, it would like get vectorized by `@turbo`. The `b_est_stride` 
function does this. However, it is really inconvenient to rewrite array code as scalars.
It may be more maintainable to keep the arrays and write SIMD instructions ourselves.

```julia;  cache=true
@benchmark ARGridBootstrap.xx_xy!($xx,$xy,$y)
```

```julia;  cache=true
@benchmark ARGridBootstrap.xx_xy_simd!($xx,$xy,$y, Val(16))
```

This makes the code faster by a factor of more than 10. The `Val(N)` argument 
controls the width of vectors that gets passed to SIMD instructions. 
The value of `N` can affect execution by a factor of 5 or more. The
best choice of `N` depends on your exact hardware and the code being executed. 

To see how much this is worth it, let's benchmark the full bootstrap code, but using the SIMD 
versions of `resids!` and `xx_xy!`

```julia;  cache=true
b_est_simd = y->b_est_nox(y, xx_xy! =ARGridBootstrap.xx_xy_simd!, resids! =ARGridBootstrap.resids_simd!)
benchsimd=@benchmark (b,t) = gridbootstrap(wrapper(b_est_simd), a->ar1_original(y0, a, est.e),
                             αgrid, nboot)
```

We have not improved total execution very much. The problem is that
very little of the total time was spent in `xx_xy!` and `resids!` to begin with. 
We did make those functions much faster, but they were such a small portion of 
total execution time, that it is not noticeable. We should focus our efforts on 
`ar1_original` if we want to improve. 

# Fastest Version 

The fastest version of the code that I could write combines the ideas
above. As above, it avoids allocating `x`. It also avoids allocating
`e` by combining the simulation and estimation into a single
loop. Finally, it uses mutable static arrays to ensure that operations
on `xx` and `xy` have as little overhead as possible. Note that for
small StaticArrays, `inv` will call a specialized, fast version, and
ends up being faster than `\`.

```julia
using StaticArrays
```

```julia; results="raw"
s = @code_string simulate_estimate_arp(y0,a,e)
code_md(s)
```

```julia; cache=true; 
estimator(y0=y0,e=est.e) = function(a)
  out = simulate_estimate_arp(y0,a,e)
  (out.θ[3], out.se[3])
end
bench_sea=@benchmark  (b,t) = gridbootstrap(estimator(), a->a, αgrid, nboot)
```

On my computer, this version of the code is about 10 times faster than
the original.

For further gains, we will explore [multi-threading](threads.md) and using a [GPU](gpu.md) in parts 2 and 3. 

# Exercises

Some of these have been incorporated into the sections above. 

1. Read [the Performance Tips section of Julia
Manual](https://docs.julialang.org/en/v1/manual/performance-tips/) and
incorporate some of these tips into the above code.

2. Write a version of ` b_est` that avoids allocating the full
$T \times 3$ $X$ matrix, but can still be generalized to an AR(p) model.

3. Examine how the relative performance of these versions of `
b_est` vary with ` T`, ` nboot`, and the number of grid points.

4. The Julia package ` StaticArrays.jl` provides an alternative
array implementation that is often much faster than ` Base.Array`. Try
implementing ` b_est` using ` StaticArrays.jl`. You will likely need to
use mutable arrays (see ` @MMatrix` and ` @MVector`). Note that ` inv` of
a small array will be substantially faster when using ` StaticArray.jl`
instead of ` Base.Array`.

5. The fastest version of the code does not yet use SIMD instructions. 
Try to improve its performance by using SIMD. 
My [SIMDscan](https://github.com/schrimpf/SIMDscan.jl/) package might be useful.

