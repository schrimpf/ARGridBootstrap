{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title       : \"Coding for Performance\"\n",
    "subtitle    : \n",
    "author      : Paul Schrimpf\n",
    "date        : `j using Dates; print(Dates.today())`\n",
    "bibliography: \"perf.bib\"\n",
    "---\n",
    "\n",
    "[![](https://i.creativecommons.org/l/by-sa/4.0/88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)\n",
    "\n",
    "This work is licensed under a [Creative Commons Attribution-ShareAlike\n",
    "4.0 International\n",
    "License](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "\n",
    "### About this document {-}\n",
    "\n",
    "This document was created using Weave.jl. The code is available in\n",
    "[on github](https://github.com/schrimpf/ARGridBootstrap.jl). The same\n",
    "document generates both static webpages and associated (jupyter\n",
    "notebook)[argridboot.ipynb]. \n",
    "\n",
    "# Introduction\n",
    "\n",
    "Today we will look into some methods to improve the speed of our\n",
    "code. Although speed is sometimes important, never forget that speed\n",
    "should be low on your list of priorities when writing code. You should\n",
    "prioritize correctness and maintainability ahead of\n",
    "performance. Nonetheless, performance does matter for some problems. \n",
    "\n",
    "If you have not already, be sure to read [the Peformance Tips section of Julia Docs](https://docs.julialang.org/en/v1/manual/performance-tips/#man-performance-tips-1). \n",
    "\n",
    "Also, read Rackauckas's notes on [\"Optimizing Serial Code.\"](https://mitmath.github.io/18337/lecture2/optimizing)[@rackauckas2019a]. \n",
    "\n",
    "# Grid bootstrap\n",
    "\n",
    "As a motivating example we will look at the gridded bootstrap of\n",
    "Hansen (1999)[@hansen99]. \n",
    "\n",
    "<!-- FIXME: DESCRIPTION.  -->\n",
    "\n",
    "Gauss, Matlab, and R code implementing Hansen's method is available on\n",
    "[Hansen's\n",
    "website](https://www.ssc.wisc.edu/~bhansen/progs/restat_99.html). The\n",
    "Julia code below is more or less a direct translation from Hansen's R\n",
    "code. Since this is a translation from R of a translation from Gauss,\n",
    "this code will not necessarily follow best practices for Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /home/paul/.julia/compiled/v1.2/ARGridBootstrap/7AB93.ji for ARGridBootstrap [8c7cac60-37ca-418c-be28-fd9d1bae9cd2]\n",
      "└ @ Base loading.jl:1240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "functiontext (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ARGridBootstrap\n",
    "\n",
    "function functiontext(functionname, filename; includedoc=true)\n",
    "  lines = readlines(filename)\n",
    "  fstart=findfirst(occursin.(Regex(\"function\\\\s+$(functionname)\"),lines))\n",
    "  fend  =fstart + findfirst(occursin.(r\"^end\",lines[(fstart+1):end]))  \n",
    "  if (includedoc && occursin(r\"^\\\"\\\"\\\"\",lines[fstart-1]) )\n",
    "    dend = fstart -1\n",
    "    dstart = dend - findfirst(occursin.(r\"^\\\"\\\"\\\"\", lines[(fstart-2):(-1):1]))\n",
    "  end\n",
    "  lines[dstart:fend]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "    b_est_original(y)\n",
      "\n",
      "Estimate AR(1) model with intercept and time trend\n",
      "\n",
      "    y[t] = θ[0] + θ[1]t + θ[2]y[t-1] + e[t]\n",
      "\n",
      "# Arguments\n",
      "- `y`: vector \n",
      "\n",
      "# Returns \n",
      "- `θ`: estimated coefficients\n",
      "- `se`: standard errors\n",
      "- `e`: residuals \n",
      "\"\"\"\n",
      "function b_est_original(yin)\n",
      "  T = length(yin)\n",
      "  x = [ones(T-1) 2:T yin[1:(T-1)]]\n",
      "  y = yin[2:T]\n",
      "  θ = x'*x \\ x'y\n",
      "  e = y - x*θ\n",
      "  se = sqrt.(diag(inv(x'*x) *(e'*e))./(T-4))\n",
      "  (θ=θ,se=se,e=e)\n",
      "end\n",
      "\"\"\"\n",
      "    ar1_original(y0, a, e, rindex=T->rand(1:length(e), T))\n",
      "\n",
      "Simulate AR1 model by sampling errors from e with replacement. \n",
      "  \n",
      "    y[t] = a*y[t-1] + ϵ[t]\n",
      "\n",
      "# Arguments \n",
      "- `y0`: initial value for `y`\n",
      "- `a`: AR parameter\n",
      "- `e`: values of for error term. `ϵ = e[rindex(T)]]`\n",
      "- `rindex` function that returns random index in 1:length(e)\n",
      "  \n",
      "# Returns \n",
      "- `y`: vector of length `T = length(e)`\n",
      "\"\"\"\n",
      "function ar1_original(y0, a, e, rindex=T->rand(1:length(e),T))\n",
      "  T = length(e)\n",
      "  y = Array{eltype(e)}(undef, T)\n",
      "  y[1] = abs(a)<1 ? y0 : zero(eltype(y))\n",
      "  et = e[rindex(T-1)]\n",
      "  for t in 2:T\n",
      "    y[t] = a*y[t-1] + et[t-1] \n",
      "  end\n",
      "  y\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "println.(functiontext(\"b_est_original\",joinpath(dirname(Base.pathof(ARGridBootstrap)), \"ar.jl\")));\n",
    "println.(functiontext(\"ar1_original\",joinpath(dirname(Base.pathof(ARGridBootstrap)),\"ar.jl\")));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "    gridbootstrap(estimator, simulator, \n",
      "                  grid::AbstractVector, \n",
      "                  nboot=199)\n",
      "  \n",
      "Computes grid bootstrap estimates a single parameter model. \n",
      "\n",
      "For each α ∈ grid, repeatedly simulate data with parameter α and then compute an estimate. \n",
      " \n",
      "\n",
      "# Arguments\n",
      "- `estimator` function of output of `simulator` that returns a\n",
      "        2-tuple containing an estimate of α and its standard error.  \n",
      "- `simulator` function that given `α` simulates data that can be used to estimate α\n",
      "- `grid` grid of parameter values. For each value, `nboot`\n",
      "        datasets will be simulated and estimates computed.  \n",
      "- `nboot` \n",
      "\n",
      "# Returns\n",
      "- `ba` hatα - α for each grid value and simulated dataset\n",
      "- `t` t-stat  for each grid value and simulated dataset\n",
      "\"\"\"\n",
      "function gridbootstrap(estimator, simulator,\n",
      "                       grid::AbstractVector,\n",
      "                       nboot=199)\n",
      "  g = length(grid)\n",
      "  bootq = zeros(nboot, g)\n",
      "  ba    = zeros(nboot, g)\n",
      "  bootse = zeros(nboot,g)\n",
      "  for ak in 1:g\n",
      "    for j in 1:nboot \n",
      "      (bootq[j,ak], bootse[j,ak]) = estimator(simulator(grid[ak]))\n",
      "      ba[j,ak] = bootq[j,ak] - grid[ak]\n",
      "    end\n",
      "  end\n",
      "  ts = ba./bootse\n",
      "  (ba=ba, t=ts)\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "println.(functiontext(\"gridbootstrap\",joinpath(dirname(Base.pathof(ARGridBootstrap)), \"gridbootstrap.jl\")));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving performance\n",
    "\n",
    "Now, let's run this code and time it. Note that we are running this\n",
    "with only 50 grid points and 199 bootstrap replications. In real use,\n",
    "you would want more like 999 bootstrap replications or more, and perhaps more\n",
    "grid points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  545.383 ms (365375 allocations: 222.07 MiB)\n"
     ]
    }
   ],
   "source": [
    "# simulate some data\n",
    "using Random, BenchmarkTools, Profile\n",
    "T = 200\n",
    "e = randn(T)\n",
    "y0 = 0\n",
    "a = 0.9\n",
    "y = ar1_original(y0, a, e)\n",
    "est = b_est_original(y)\n",
    "αgrid = 0.84:(0.22/50):1.06\n",
    "nboot= 199\n",
    "wrapper(b_est) = function(x)\n",
    "  out=b_est(x)\n",
    "  (out.θ[3], out.se[3])\n",
    "end\n",
    "@btime (b,t) = gridbootstrap(wrapper(b_est_original), a->ar1_original(y0, a, est.e),\n",
    "                             αgrid, nboot);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make code faster, we should begin by profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8918 ./task.jl:268; (::getfield(IJulia, Symbol(\"##15#18\")))()\n",
      " 8918 /home/paul/.julia/packages/IJulia/fRegO/src/eventloop.jl:8; eventloop(::ZMQ.Socket)\n",
      "  8918 ./essentials.jl:789; invokelatest\n",
      "   8918 ./essentials.jl:790; #invokelatest#1\n",
      "    8918 /home/paul/.julia/packages/IJulia/fRegO/src/execute_request.jl:67; execute_request(::ZMQ.Socket, ::IJulia.Msg)\n",
      "     8918 /home/paul/.julia/packages/SoftGlobalScope/cSbw5/src/SoftGlobalScope.jl:218; softscope_include_string(::Module, ::String, ::String)\n",
      "      8918 ./boot.jl:330; eval\n",
      "       8879 /home/paul/.julia/dev/ARGridBootstrap/src/gridbootstrap.jl:32; gridbootstrap(::getfield(Main, Symbol(\"##4#5\")){typeof(b_est_original)}, ::getfield(Main, Symbol(\"##9#10\")), ::StepRangeLen{...\n",
      "        8666 ./In[4]:12; (::getfield(Main, Symbol(\"##4#5\")){typeof(b_est_original)})(::Array{Float64,1})\n",
      "         8517 /home/paul/.julia/dev/ARGridBootstrap/src/ar.jl:50; b_est_original(::Array{Float64,1})\n",
      "          8493 /build/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/LinearAlgebra/src/dense.jl:730; inv(::Array{Float64,2})\n",
      "           8473 /build/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/LinearAlgebra/src/lu.jl:410; inv!\n",
      "            8461 ...d/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/LinearAlgebra/src/lapack.jl:978; getri!(::Array{Float64,2}, ::Array{Int32,1})\n",
      "        207  ./In[5]:3; (::getfield(Main, Symbol(\"##9#10\")))(::Float64)\n",
      "         206 /home/paul/.julia/dev/ARGridBootstrap/src/ar.jl:18; ar1_original(::Int64, ::Float64, ::Array{Float64,1})\n",
      "          151 /home/paul/.julia/dev/ARGridBootstrap/src/ar.jl:21; ar1_original(::Int64, ::Float64, ::Array{Float64,1}, ::getfield(ARGridBootstrap, Symbol(\"##1#2\")){Array{Float64,1}})\n",
      "           42 ./abstractarray.jl:981; getindex\n",
      "            31 ./multidimensional.jl:670; _getindex\n",
      "             12 ./multidimensional.jl:682; _unsafe_getindex(::IndexLinear, ::Array{Float64,1}, ::Array{Int64,1})\n",
      "              12 ./abstractarray.jl:627; similar\n",
      "               12 ./array.jl:318; similar\n",
      "                12 ./boot.jl:413; Type\n",
      "                 12 ./boot.jl:404; Type\n",
      "             15 ./multidimensional.jl:684; _unsafe_getindex(::IndexLinear, ::Array{Float64,1}, ::Array{Int64,1})\n",
      "              15 ./multidimensional.jl:690; _unsafe_getindex!\n",
      "               15 ./multidimensional.jl:694; macro expansion\n",
      "                15 ./cartesian.jl:64; macro expansion\n",
      "                 7 ./multidimensional.jl:700; macro expansion\n",
      "                  6 ./range.jl:595; iterate\n",
      "                   6 ./promotion.jl:403; ==\n",
      "           96 /home/paul/.julia/dev/ARGridBootstrap/src/ar.jl:17; #1\n",
      "            96 /build/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/Random/src/Random.jl:260; rand\n",
      "             96 /build/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/Random/src/Random.jl:257; rand\n",
      "              96 /build/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/Random/src/Random.jl:256; rand\n",
      "               96 /build/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/Random/src/Random.jl:243; rand!(::MersenneTwister, ::Array{Int64,1}, ::UnitRange{Int64})\n",
      "                95 /build/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/Random/src/Random.jl:248; rand!\n",
      "          52  /home/paul/.julia/dev/ARGridBootstrap/src/ar.jl:23; ar1_original(::Int64, ::Float64, ::Array{Float64,1}, ::getfield(ARGridBootstrap, Symbol(\"##1#2\")){Array{Float64,1}})\n",
      "           30 ./float.jl:399; *\n",
      "           15 ./float.jl:395; +\n"
     ]
    }
   ],
   "source": [
    "Profile.clear();\n",
    "Profile.init(n=10^7,delay=0.0001);\n",
    "@profile (b,t) = gridbootstrap(wrapper(b_est_original), a->ar1_original(y0, a, est.e),\n",
    "                               αgrid, 999);\n",
    "Profile.print(noisefloor=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profile.jl works very simply. Every 0.0001 seconds, the line of code\n",
    "being executed gets recorded. `Profile.print` shows the count of how\n",
    "many times each line of code got recorded. From the output (these\n",
    "numbers can vary quite a bit from run to run), we see\n",
    "there were 640 ticks in ` gridbootstrap_original` (exact numbers will\n",
    "vary on each execution, but relative ones should be similar), and\n",
    "almost all of these occurred within `inv`.  If we want the\n",
    "code to be faster, we should focus on these lines.  Calling both `inv`\n",
    "and `\\` is redundant; we should combine these computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "    b_est_mldivide(y)\n",
      "\n",
      "  Estimate AR(1) model with intercept and time trend. \n",
      "\n",
      "    y[t] = θ[0] + θ[1]t + θ[2]y[t-1] + e[t]\n",
      "\n",
      "# Arguments    \n",
      "- `y`: vector \n",
      "\n",
      "# Returns\n",
      "- `θ`: estimated coefficients\n",
      "- `se`: standard errors\n",
      "- `e`: residuals \n",
      "\"\"\"\n",
      "function b_est_mldivide(yin)\n",
      "  T = length(yin)\n",
      "  x = [ones(T-1) 2:T yin[1:(T-1)]]\n",
      "  y = yin[2:T]\n",
      "  tmp = x'*x \\ [x'*y I]\n",
      "  θ = tmp[:,1]\n",
      "  ixx = tmp[:,2:4]\n",
      "  e = y - x*θ\n",
      "  se = sqrt.(diag(ixx *(e'*e))./(T-4))\n",
      "  (θ=θ,se=se,e=e)\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "println.(functiontext(\"b_est_mldivide\",joinpath(dirname(Base.pathof(ARGridBootstrap)), \"ar.jl\")));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  116.672 ms (385673 allocations: 208.60 MiB)\n"
     ]
    }
   ],
   "source": [
    "@btime (b,t) = gridbootstrap(wrapper(b_est_mldivide), a->ar1_original(y0, a, est.e),\n",
    "                             αgrid, nboot);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we get a speedup by about a factor of 4 on my computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445 ./task.jl:268; (::getfield(IJulia, Symbol(\"##15#18\")))()\n",
      " 445 /home/paul/.julia/packages/IJulia/fRegO/src/eventloop.jl:8; eventloop(::ZMQ.Socket)\n",
      "  445 ./essentials.jl:789; invokelatest\n",
      "   445 ./essentials.jl:790; #invokelatest#1\n",
      "    445 /home/paul/.julia/packages/IJulia/fRegO/src/execute_request.jl:67; execute_request(::ZMQ.Socket, ::IJulia.Msg)\n",
      "     445 /home/paul/.julia/packages/SoftGlobalScope/cSbw5/src/SoftGlobalScope.jl:218; softscope_include_string(::Module, ::String, ::String)\n",
      "      445 ./boot.jl:330; eval\n",
      "       405 /home/paul/.julia/dev/ARGridBootstrap/src/gridbootstrap.jl:32; gridbootstrap(::getfield(Main, Symbol(\"##4#5\")){typeof(b_est_mldivide)}, ::getfield(Main, Symbol(\"##14#15\")), ::StepRangeLen...\n",
      "        261 ./In[4]:12; (::getfield(Main, Symbol(\"##4#5\")){typeof(b_est_mldivide)})(::Array{Float64,1})\n",
      "         113 /home/paul/.julia/dev/ARGridBootstrap/src/ar.jl:72; b_est_mldivide(::Array{Float64,1})\n",
      "          97 ./abstractarray.jl:1313; hcat\n",
      "           95 ./abstractarray.jl:1311; typed_hcat\n",
      "            44 ./abstractarray.jl:1341; _typed_hcat(::Type{Float64}, ::Tuple{Array{Float64,1},UnitRange{Int64},Array{Float64,1}})\n",
      "             44 ./tuple.jl:24; getindex\n",
      "            23 ./abstractarray.jl:1343; _typed_hcat(::Type{Float64}, ::Tuple{Array{Float64,1},UnitRange{Int64},Array{Float64,1}})\n",
      "             23 ./abstractarray.jl:1074; setindex!\n",
      "              20 ./multidimensional.jl:712; _setindex!\n",
      "               19 ./multidimensional.jl:717; _unsafe_setindex!(::IndexLinear, ::Array{Float64,2}, ::Array{Float64,1}, ::Base.Slice{Base.OneTo{Int64}}, ::UnitRange{In...\n",
      "                17 ./multidimensional.jl:724; macro expansion\n",
      "                 14 ./cartesian.jl:64; macro expansion\n",
      "                  7 ./multidimensional.jl:730; macro expansion\n",
      "                   5 ./array.jl:704; iterate\n",
      "                    5 ./array.jl:728; getindex\n",
      "         104 /home/paul/.julia/dev/ARGridBootstrap/src/ar.jl:74; b_est_mldivide(::Array{Float64,1})\n",
      "          47 ...ld/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/LinearAlgebra/src/generic.jl:970; \\(::Array{Float64,2}, ::Array{Float64,2})\n",
      "           37 /build/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/LinearAlgebra/src/lu.jl:142; lu\n",
      "            37 /build/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/LinearAlgebra/src/lu.jl:142; lu\n",
      "             37 /build/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/LinearAlgebra/src/lu.jl:142; #lu#122\n",
      "              35 ./none:0; #lu!\n",
      "               35 /build/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/LinearAlgebra/src/lu.jl:40; #lu!#118(::Bool, ::typeof(LinearAlgebra.lu!), ::Array{Float64,2}, ::Val{true})\n",
      "                33 .../julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/LinearAlgebra/src/lapack.jl:550; getrf!\n",
      "          29 /build/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/LinearAlgebra/src/matmul.jl:143; *\n",
      "           29 ...ld/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/LinearAlgebra/src/matmul.jl:282; mul!\n",
      "            29 ...ld/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/LinearAlgebra/src/matmul.jl:223; mul!\n",
      "             29 ...d/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/LinearAlgebra/src/matmul.jl:390; syrk_wrapper!(::Array{Float64,2}, ::Char, ::Array{Float64,2})\n",
      "              28 /build/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/LinearAlgebra/src/blas.jl:1333; syrk!(::Char, ::Char, ::Float64, ::Array{Float64,2}, ::Float64, ::Array{Float64,2})\n",
      "        123 ./In[8]:2; (::getfield(Main, Symbol(\"##14#15\")))(::Float64)\n",
      "         120 /home/paul/.julia/dev/ARGridBootstrap/src/ar.jl:18; ar1_original(::Int64, ::Float64, ::Array{Float64,1})\n",
      "          88 /home/paul/.julia/dev/ARGridBootstrap/src/ar.jl:21; ar1_original(::Int64, ::Float64, ::Array{Float64,1}, ::getfield(ARGridBootstrap, Symbol(\"##1#2\")){Array{Float64,1}})\n",
      "           75 /home/paul/.julia/dev/ARGridBootstrap/src/ar.jl:17; #1\n",
      "            75 /build/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/Random/src/Random.jl:260; rand\n",
      "             75 /build/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/Random/src/Random.jl:257; rand\n",
      "              75 /build/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/Random/src/Random.jl:256; rand\n",
      "               75 /build/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/Random/src/Random.jl:243; rand!(::MersenneTwister, ::Array{Int64,1}, ::UnitRange{Int64})\n",
      "                70 /build/julia/src/julia-1.2.0/usr/share/julia/stdlib/v1.2/Random/src/Random.jl:248; rand!\n",
      "          28 /home/paul/.julia/dev/ARGridBootstrap/src/ar.jl:23; ar1_original(::Int64, ::Float64, ::Array{Float64,1}, ::getfield(ARGridBootstrap, Symbol(\"##1#2\")){Array{Float64,1}})\n",
      "           17 ./float.jl:399; *\n"
     ]
    }
   ],
   "source": [
    "Profile.clear();\n",
    "@profile (b,t) = gridbootstrap(wrapper(b_est_mldivide), a->ar1_original(y0, a, est.e),\n",
    "                               αgrid, 999);\n",
    "Profile.print(noisefloor=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the most time consuming parts of the code are, unsurprisingly,\n",
    "the call to ` \\`, and, perhaps surprisingly, ` hcat` from\n",
    "creating ` x`. Allocating and copying memory is relatively slow. The\n",
    "creation of ` x` involves both. We can avoid creating `x` by just\n",
    "accumulating $X'y$ and $X'X$ in a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\" \n",
      "    b_est_nox(y)\n",
      "\n",
      "  Estimate AR(1) model with intercept and time trend. \n",
      "\n",
      "    y[t] = θ[0] + θ[1]t + θ[2]y[t-1] + e[t]\n",
      "\n",
      "# Arguments\n",
      "- `y`: vector \n",
      "\n",
      "# Returns\n",
      "- `θ`: estimated coefficients\n",
      "- `se`: standard errors\n",
      "- `e`: residualas \n",
      "\"\"\"\n",
      "function b_est_nox(yin)\n",
      "  T = length(yin)\n",
      "  xx = zeros(eltype(yin),3,3)\n",
      "  xy = zeros(eltype(yin),3)\n",
      "  @inbounds @simd for t in 2:T\n",
      "    xx[1,3] += yin[t-1]\n",
      "    xx[2,3] += t*yin[t-1]\n",
      "    xx[3,3] += yin[t-1]^2\n",
      "    xy[1] += yin[t]\n",
      "    xy[2] += t*yin[t]\n",
      "    xy[3] += yin[t-1]*yin[t]\n",
      "  end \n",
      "  xx[1,1] = T-1 # = 1'*1\n",
      "  xx[1,2] = xx[2,1] = (T+1)*T/2 - 1 # sum(p+1:T)\n",
      "  xx[2,2] = (2*(T)+1)*(T)*(T+1)/6 - 1 # sum((p+1:T).^2)  \n",
      "  xx[3,1] = xx[1,3]\n",
      "  xx[3,2] = xx[2,3]\n",
      "  tmp = xx \\ [xy I]\n",
      "  θ = tmp[:,1]\n",
      "  ixx = tmp[:,2:4]\n",
      "  e = similar(yin,T-1)\n",
      "  @simd for t in 2:T\n",
      "    @inbounds e[t-1] = yin[t] - θ[1] - θ[2]*t - θ[3]*yin[t-1]\n",
      "  end\n",
      "  se = sqrt.(diag(ixx *(e'*e))./(T-4))\n",
      "  (θ=θ,se=se,e=e)\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "println.(functiontext(\"b_est_nox\",joinpath(dirname(Base.pathof(ARGridBootstrap)), \"ar.jl\")));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  66.517 ms (304481 allocations: 89.82 MiB)\n"
     ]
    }
   ],
   "source": [
    "@btime (b,t) = gridbootstrap(wrapper(b_est_nox), a->ar1_original(y0, a, est.e),\n",
    "                             αgrid, nboot);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have further cut the time by a factor of two. However, this performance\n",
    "optimization has been costly in terms of readability and extensibility\n",
    "of our code. If we wanted to fit an AR(p) model instead of AR(1), the\n",
    "` b_est_nox` function would be more difficult to modify than the\n",
    "` b_est_mldivide` version. \n",
    "\n",
    "EXERCISE: Read [the Performance Tips section of Julia\n",
    "Manual](https://docs.julialang.org/en/v1/manual/performance-tips/) and\n",
    "incorporate some of these tips into the above code.\n",
    "\n",
    "EXERCISE: write a version of ` b_est` that avoids allocating the full\n",
    "$T \\times 3$ $X$ matrix, but can still be generalized to an AR(p) model. \n",
    "\n",
    "EXERCISE: examine how the relative performance of these versions of `\n",
    "b_est` vary with ` T`, ` nboot`, and the number of grid points. \n",
    "\n",
    "EXERCISE: the Julia package ` StaticArrays.jl` provides an alternative\n",
    "array implementation that is often much faster than ` Base.Array`. Try\n",
    "implementing ` b_est` using ` StaticArrays.jl`. You will likely need to\n",
    "use mutable arrays (see ` @MMatrix` and ` @MVector`). Note that ` inv` of\n",
    "a small array will be substantially faster when using ` StaticArray.jl`\n",
    "instead of ` Base.Array`. \n",
    "\n",
    "## Fastest version\n",
    "\n",
    "The fastest version of the code that I could write combines the ideas\n",
    "above. As above, it avoids allocating `x`. It also avoids allocating\n",
    "`e` by combining the simulation and estimation into a single\n",
    "loop. Finally, it uses mutable static arrays to ensure that operations\n",
    "on `xx` and `xy` have as little overhead as possible. Note that for\n",
    "small StaticArrays, `inv` will call a specialized, fast version, and\n",
    "ends up being faster than `\\`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StaticArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "    simulate_estimate_arp(y0, a, e, ar::Val{P}, rindex=T->rand(1:length(e),T)) \n",
      "\n",
      "Simulates and estimates an AR(P) model. `y` is simulated as\n",
      "  \n",
      "   y[t] = a*y[t-1] + ϵ[t]\n",
      "  \n",
      "and the estimate of θ from \n",
      "\n",
      "   y[t] = θ[1] + θ[2]t + θ[3] y[t-1] + ... + θ[P] y[t-P] + u[t] \n",
      "\n",
      "is computed. \n",
      "\n",
      "# Arguments\n",
      "- `y0` initial value of y\n",
      "- `a` AR(1) parameter\n",
      "- `e` error terms to sample from `ϵ[t] = e[rindex(1)]`\n",
      "- `ar::Val{P}` order of autoregressive model to estimate\n",
      "- `rindex` function that returns random index in 1:length(e)\n",
      "\n",
      "# Returns\n",
      "- `θ` estimated coefficients\n",
      "- `se` standard errors\n",
      "\"\"\"\n",
      "function simulate_estimate_arp(y0, a, e, ar::Val{P}=Val(1),\n",
      "                               rindex=()->rand(1:length(e))) where P\n",
      "  T = length(e)\n",
      "  length(a)==P || error(\"length(a) not equal to P\")\n",
      "  xx = @MMatrix zeros(eltype(e),P+2, P+2)\n",
      "  xy = @MVector zeros(eltype(e),P+2)\n",
      "  yy = zero(eltype(e))\n",
      "  xt = @MVector ones(eltype(e), P+2)\n",
      "  if (abs(a)<1)\n",
      "    xt[3:(P+2)] .= y0\n",
      "  else \n",
      "    xt[3:(P+2)] .= 0.0\n",
      "  end\n",
      "  α = @MVector zeros(eltype(e),P+2)\n",
      "  @simd for i = 1:P\n",
      "    α[2+i] = a[i]\n",
      "  end\n",
      "\n",
      "  xx[1,1] = T-P # = 1'*1\n",
      "  xx[1,2] = xx[2,1] = (T+1)*T/2 - sum(1:P) # sum(P+1:T)\n",
      "  xx[2,2] = (2*(T)+1)*(T)*(T+1)/6 - sum((1:P).^2) # sum((P+1:T).^2)  \n",
      "  @inbounds for t in (P+1):T\n",
      "    et = e[rindex()]\n",
      "    xt[2] = t\n",
      "    for i in 1:(P+2)\n",
      "      @simd for j in 3:(P+2)\n",
      "        xx[i,j] += xt[i]*xt[j]\n",
      "      end\n",
      "    end\n",
      "    y = dot(α, xt) + et\n",
      "    @simd for i in 1:(P+2)\n",
      "      xy[i] += xt[i]*y\n",
      "    end\n",
      "    yy += y^2\n",
      "    if (P>1)\n",
      "      xt[4:(P+2)] .= xt[3:(P+1)]\n",
      "    end\n",
      "    xt[3] = y\n",
      "  end\n",
      "  @inbounds for i in 3:(P+2)\n",
      "    for j in 1:(i-1)\n",
      "      xx[i,j] = xx[j,i]\n",
      "    end\n",
      "  end\n",
      "  ixx = inv(xx)\n",
      "  θ = ixx*xy\n",
      "  ee = yy - xy'*ixx*xy\n",
      "  se = sqrt.(abs.(diag(ixx *(ee))./(T-(2*P+2))))\n",
      "  (θ=θ,se=se)\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "println.(functiontext(\"simulate_estimate_arp\",joinpath(dirname(Base.pathof(ARGridBootstrap)), \"ar.jl\")));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  26.167 ms (111651 allocations: 4.80 MiB)\n"
     ]
    }
   ],
   "source": [
    "estimator(y0=y0,e=est.e) = function(a) \n",
    "  out = simulate_estimate_arp(y0,a,e)\n",
    "  (out.θ[3], out.se[3])\n",
    "end\n",
    "@btime  (b,t) = gridbootstrap(estimator(), a->a, αgrid, nboot);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my computer, this version of the code is about 15 times faster than\n",
    "the original. \n",
    "\n",
    "\n",
    "# Multi-threading\n",
    "\n",
    "Modern computers almost all have multiple cores. We can divide the\n",
    "time it takes our code by up to the number of cores we have (but\n",
    "usually less) by writing multi-threaded code. Multi-threaded code\n",
    "performs multiple tasks at once with shared memory. Before you begin\n",
    "writing multi-threaded code, you should make sure your code isn't\n",
    "already using all available cores. It is likely that the BLAS and\n",
    "Lapack libraries that Julia uses for linear algebra are\n",
    "multi-threaded. If you code is dominated by large matrix operations,\n",
    "it may already be using all available cores. In that case, there will\n",
    "not be much benefit from additional multi-threading.\n",
    "\n",
    "Read [\"The Basics of Single Node Parallel Computing\"](https://mitmath.github.io/18337/lecture5/parallelism_overview)\n",
    "Rackauckus (2019)[@rackauckus2019b].\n",
    "\n",
    "Once we have decided that the code might benefit from multi-threading,\n",
    "we should look for loops (or other independent tasks) that can be\n",
    "multi-threaded. There is some overhead from creating threads and\n",
    "communicating among them. Multi-threading generally works best for\n",
    "loops where each iteration involves substantial work, and each\n",
    "iteration is independent of all others. The loops over grid points and\n",
    "bootstrap repetitions in ` gridbootstrap` are perfect candidates. We\n",
    "don't care about the order in which these loops get executed. The\n",
    "result of each iteration is (mostly) independent of all others.\n",
    "\n",
    "Some care must be taken with random number generators and\n",
    "multi-threaded code. See\n",
    "[the Julia docs](https://docs.julialang.org/en/v1/manual/parallel-computing/index.html#Side-effects-and-mutable-function-arguments-1) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "    gridbootstrap_threaded(estimator, simulator, \n",
      "                    grid::AbstractVector, \n",
      "                    nboot=199)\n",
      "    \n",
      "Computes grid bootstrap estimates a single parameter model. \n",
      "\n",
      "For each α ∈ grid, repeatedly simulate data with parameter α and then compute an estimate. \n",
      " \n",
      "\n",
      "# Arguments\n",
      "- `estimator` function of output of `simulator` that returns a\n",
      "    2-tuple containing an estimate of α and its standard error.  \n",
      "- `simulator` function that given `α` and `rng`, simulates data\n",
      "    that can be used to estimate α \n",
      "- `grid` grid of parameter values. For each value, `nboot`\n",
      "    datasets will be simulated and estimates computed.  \n",
      "- `nboot` \n",
      "\n",
      "# Returns\n",
      "- `ba` hatα - α for each grid value and simulated dataset\n",
      "- `t` t-stat  for each grid value and simulated dataset\n",
      "\"\"\"\n",
      "function gridbootstrap_threaded(estimator, simulator,\n",
      "                                grid::AbstractVector,\n",
      "                                nboot=199; rng=rngarray(nthreads()))\n",
      "  g = length(grid)\n",
      "  bootq = zeros(nboot, g)\n",
      "  ba    = zeros(nboot, g)\n",
      "  bootse = zeros(nboot,g)\n",
      "  @threads for ak in 1:g\n",
      "    for j in 1:nboot \n",
      "      (bootq[j,ak], bootse[j,ak]) = estimator(simulator(grid[ak],rng[threadid()]))\n",
      "      ba[j,ak] = bootq[j,ak] - grid[ak]\n",
      "    end\n",
      "  end\n",
      "  ts = ba./bootse\n",
      "  (ba=ba, t=ts)\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "println.(functiontext(\"gridbootstrap_threaded\",joinpath(dirname(Base.pathof(ARGridBootstrap)), \"gridbootstrap.jl\")));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "    rngarray(n)\n",
      "\n",
      "  Create `n` rng states that will not overlap for 10^20 steps.\n",
      "\n",
      "  Note: this will be unneeded in Julia 1.3 when thread-safe RNG is\n",
      "  included.\n",
      "\"\"\"\n",
      "function rngarray(n)\n",
      "  baserng =  MersenneTwister()\n",
      "  rng = Array{typeof(baserng)}(undef, Base.Threads.nthreads())\n",
      "  rng[1] = baserng\n",
      "  steps = big(10)^20 # randjump is precomputed for steps = big(10)^20\n",
      "  for i in 2:nthreads()\n",
      "    rng[i] = Future.randjump(rng[i-1], steps) \n",
      "  end\n",
      "  rng\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "println.(functiontext(\"rngarray\",joinpath(dirname(Base.pathof(ARGridBootstrap)), \"gridbootstrap.jl\")));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try multi-threading the original version of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single thread, original version\n",
      "  0.652117 seconds (428.66 k allocations: 225.018 MiB, 4.02% gc time)\n",
      "30 threads, original version\n",
      " 17.485715 seconds (6.35 M allocations: 313.294 MiB, 0.71% gc time)\n"
     ]
    }
   ],
   "source": [
    "using Base.Threads\n",
    "println(\"Single thread, original version\")\n",
    "@time begin # this is so slow that using btime is not so necessary\n",
    "  (b,t) = gridbootstrap(wrapper(b_est_original), a->ar1_original(y0, a, est.e),\n",
    "                        αgrid, 199);\n",
    "end;\n",
    "\n",
    "rng = rngarray(nthreads())\n",
    "# make sure the threaded version is compiled before timing it\n",
    "(b,t) = gridbootstrap_threaded(wrapper(b_est_original),\n",
    "                               (a, rng)->ar1_original(y0, a, est.e, n->rand(rng,1:(T-1),n)),\n",
    "                               αgrid, 2, rng=rng);\n",
    "println(\"$(nthreads()) threads, original version\")\n",
    "@time begin # this is so slow that using btime is not so necessary\n",
    "  (b,t) = gridbootstrap_threaded(wrapper(b_est_original),\n",
    "                                 (a, rng)->ar1_original(y0, a, est.e, n->rand(rng,1:(T-1),n)),\n",
    "                                 αgrid, 199, rng=rng);\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution times are nearly identical on my computer. The reason is\n",
    "that the computation is dominated by the creation of ` X` and\n",
    "multiplying ` X'*X` and ` X'*y`. These operations are already\n",
    "multi-threaded in the BLAS version I have installed. It is possible\n",
    "first calling ` using LinearAlgebra; BLAS.set_num_threads(1)` would\n",
    "improve the performance of the multi-threaded bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single thread, fastest version\n",
      "  26.709 ms (111651 allocations: 4.80 MiB)\n",
      "30 threads, fastest version\n",
      "  4.685 ms (21196 allocations: 1.16 MiB)\n"
     ]
    }
   ],
   "source": [
    "println(\"Single thread, fastest version\")\n",
    "@btime  (b,t) = gridbootstrap(estimator(), a->a, αgrid, nboot);\n",
    "\n",
    "println(\"$(nthreads()) threads, fastest version\")\n",
    "estimator_threaded(y0=y0,e=est.e)=function(foo)\n",
    "  (a, rng) = foo\n",
    "  out=simulate_estimate_arp(y0,a,e,Val(1),()->rand(rng,1:length(e)))\n",
    "  (out.θ[3], out.se[3])\n",
    "end\n",
    "rng = rngarray(nthreads())\n",
    "@btime begin\n",
    "  (bs, ts) = gridbootstrap_threaded(estimator_threaded(),\n",
    "                                    (a,rng)->(a,rng), αgrid,\n",
    "                                    nboot, rng=rng)  \n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the speedup from using multiple threads is far less than\n",
    "number of cores. On my computer, the threaded version of the code is\n",
    "about 4 times faster, even though my computer has 40 \"cores\" (or 20\n",
    "physical cores. My computer has 2 processors with 10 cores each, and each\n",
    "core is hyperthreaded into 2. The OS sees 40 processors, but half of\n",
    "them are sharing substantial resources). A speedup far less than the\n",
    "number of cores is typical. Creating and managing multiple threads\n",
    "creates some overhead. Moreover, cores must share various resources;\n",
    "most notably RAM and some cache. \n",
    "\n",
    "# GPU\n",
    "\n",
    "Compared to CPUs, GPUs have a huge number of cores operating at a\n",
    "slower clockrate. GPUs also have their own separate memory, which they\n",
    "can access faster than CPUs access RAM.  These characteristics make\n",
    "GPUs well-suited to large parallel computations. Unfortunately, fully\n",
    "utilizing GPUs can require substantial changes to your code.\n",
    "\n",
    "See [\"The Different Flavors of\n",
    "Parallelism\"](https://mitmath.github.io/18337/lecture6/styles_of_parallelism)\n",
    "Rackauckas (2019)[@rackauckas2019c] for more information comparing\n",
    "GPUs to various forms of parallelism on CPUs.\n",
    "\n",
    "## Array interface\n",
    "\n",
    "The easiest way to use a GPU in Julia is through a high level array\n",
    "interface. ` ArrayFire.jl`, ` CLArrays.jl`, and ` CuArrays.jl` each offer such\n",
    "interfaces. We will focus on ` CuArrays.jl` in these\n",
    "notes. ` CuArrays.jl` relies on Nvidia's CUDA platform, so it only\n",
    "works with Nvidia GPUs. Nvidia tends to dominate GPGPU, and the GPUs\n",
    "available on cedar.computecanada.ca and in my desktop are Nvidia. \n",
    "\n",
    "Using CuArrays is simple, but has some limitations. You create arrays\n",
    "on the GPU using ` CuArray`. Any array level operation on these will\n",
    "then be performed efficiently on the GPU. This includes broadcast\n",
    "functions with ` .` and matrix multiplies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cuarraydemo (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CuArrays, Random, BenchmarkTools\n",
    "\n",
    "\n",
    "N = 1000\n",
    "M = 1000\n",
    "\n",
    "function cuarraydemo(N,M)\n",
    "  # wrapped in a  function so that the CuArrays are freed\n",
    "  # otherwise we will run out GPU memory later\n",
    "  A = randn(N,M);\n",
    "  b = randn(M,2);\n",
    "  println(\"Time on CPU\")\n",
    "  function foo(A,b)\n",
    "    (A.^2)*b\n",
    "  end\n",
    "  @time c=foo(A,b);\n",
    "  @time c=foo(A,b);\n",
    "  A_gpu = CuArray(A); # copy of A in GPU memory\n",
    "  b_gpu = CuArray(b);\n",
    "  println(\"Computations on the GPU are fast\")\n",
    "  # @btime does not work inside a function\n",
    "  @time CuArrays.@sync c_gpu=foo(A_gpu,b_gpu);\n",
    "  @time CuArrays.@sync c_gpu=foo(A_gpu,b_gpu);\n",
    "  println(\"But copying to and from GPU memory is not\")\n",
    "  bar(A,b) =Array(foo(CuArray(A), CuArray(b))) \n",
    "  @time c2=bar(A,b);\n",
    "  @time c2=bar(A,b);  \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time on CPU\n",
      "  0.004194 seconds (3 allocations: 7.645 MiB)\n",
      "  0.003710 seconds (3 allocations: 7.645 MiB)\n",
      "Computations on the GPU are fast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Building the CUDAnative run-time library for your sm_61 device, this might take a while...\n",
      "└ @ CUDAnative /home/paul/.julia/packages/CUDAnative/Lr0yj/src/compiler/rtlib.jl:173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.388847 seconds (11.16 M allocations: 578.044 MiB, 4.29% gc time)\n",
      "  0.000518 seconds (76 allocations: 2.844 KiB)\n",
      "But copying to and from GPU memory is not\n",
      "  0.008507 seconds (98 allocations: 15.308 MiB)\n",
      "  0.008805 seconds (101 allocations: 15.310 MiB)\n"
     ]
    }
   ],
   "source": [
    "cuarraydemo(N,M);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "` CuArrays` also allow indexing, so you could use loops and other\n",
    "constructs. However, this will not be fast. ` CuArrays` by itself will be\n",
    "a good method to utilize GPUs when the code is dominated by operations\n",
    "on large arrays. \n",
    "\n",
    "Unfortunately, the fastest version of our grid bootstrap code does not\n",
    "fit that description. A loop seems needed to generate $y$ due to the\n",
    "recursiveness of the AR(1) model. The fastest version of the code\n",
    "above involves many operations on small 3x3 arrays.\n",
    "\n",
    "EXERCISE: modify ` b_est_original` or ` b_est_mldivide` to utilize\n",
    "` CuArrays`. The approach taken in those functions involves some\n",
    "moderate sized matrices, so it may benefit from ` CuArrays`.\n",
    "\n",
    "\n",
    "## CUDAnative\n",
    "\n",
    "To parallelize the code above on a GPU, we will have to use a lower\n",
    "level interface to the GPU. We will the ` CUDAnative.jl` package. To\n",
    "explain how it works, we will begin with a simple example that just\n",
    "squares all the elements of an array. \n",
    "\n",
    "Disclaimer: my understanding of CUDA and the inner workings of GPUs is\n",
    "far from complete. Some of the details in this section might be\n",
    "inaccurate. \n",
    "\n",
    "A typical workflow with CUDAnative consists of \n",
    "\n",
    "1. Allocate GPU memory and copying arrays into it with ` CuArray`.\n",
    "2. Decide how many threads and what configuration of threads to\n",
    "   launch.\n",
    "3. Each thread does some computation by running a \"kernel\" function.\n",
    "4. Copy result from GPU memory to CPU memory.\n",
    "\n",
    "In the code below, 1 happens in `cuarray_cudanative_compare`, 2 happens in the\n",
    "` square!` function, ` square_kernel!` is the kernel in 3, and 4 is just\n",
    "not done. \n",
    "\n",
    "### Threads and blocks\n",
    "\n",
    "CUDA organizes GPU threads into blocks. I believe that the threads in\n",
    "a block all execute concurrently. Threads in the same block share some\n",
    "memory and registers. All current Nvidia GPUs have a maximum number of\n",
    "threads per block of 1024. Note that threads in the same block share\n",
    "registers[^reg], and different kernel functions will use different\n",
    "numbers of registers at once, so depending on the kernel function, you\n",
    "might be limited to fewer than 1024 threads per block. The number of registers\n",
    "available per block depends on your GPU. You can check your GPU\n",
    "characteristics by compiling and running the C++ program in \n",
    "`$CUDA_PATH/samples/1_Utilities/deviceQuery/`. \n",
    "Alternatively, you can access this information within Julia using\n",
    "` CUDAdrv.jl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum threads per block 1024\n",
      "Maximum x blocks 2147483647\n",
      "Maximum registers per block 65536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using CUDAdrv.@profile in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using CUDAdrv\n",
    "println(\"Maximum threads per block $(attribute(device(), CUDAdrv.MAX_THREADS_PER_BLOCK))\")\n",
    "println(\"Maximum x blocks $(attribute(device(), CUDAdrv.MAX_GRID_DIM_X))\")\n",
    "println(\"Maximum registers per block $(attribute(device(), CUDAdrv.MAX_REGISTERS_PER_BLOCK))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as I can tell, there is no simple way to figure out how many\n",
    "registers a kernel function uses. It will depend both on the code you\n",
    "write and how the compiler optimizes the code. If you encounter\n",
    "cryptic error messages about CUDA resources unavailable, then try\n",
    "reducing the number of threads per block.\n",
    "\n",
    "You can execute more than 1024 threads by specifying a number of\n",
    "blocks. There is also a limit to the number of blocks, but it is\n",
    "rather large. In the code below, we set the number of blocks, so that\n",
    "` nblocks*nthreads >= length(A)`. Each thread then operates on a single\n",
    "element of ` A`. When the code is executed, each thread has a unique\n",
    "` threadIdx` and ` blockIdx` combination, and these are used to assign\n",
    "threads to elements of ` A`. The indices go from 1 to number of threads\n",
    "(or blocks). For convenience you can request threads and blocks to\n",
    "have up 3 dimensions, and there are ` threadIdx().y` and\n",
    "` threadIdx().z` for the additional dimensions.\n",
    "\n",
    "[^reg]: Processor registers are the fastest bits of memory on the\n",
    "    processor, and registers are where the actual addition,\n",
    "    multiplication, and other instructions are carried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cuarray_cudanative_compare (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CUDAnative\n",
    "\n",
    "function square!(A::CuArray)\n",
    "  n = length(A)\n",
    "  maxthreads = 1024\n",
    "  nthreads = min(maxthreads, n)\n",
    "  nblocks  = Int(ceil(n/nthreads))\n",
    "\n",
    "  @cuda threads=nthreads blocks=nblocks square_kernel!(A)\n",
    "  \n",
    "  return A\n",
    "end\n",
    "\n",
    "function square_kernel!(A)\n",
    "  i = threadIdx().x + (blockIdx().x-1)*blockDim().x\n",
    "  if (i<=length(A))\n",
    "    @inbounds A[i] *= A[i]\n",
    "  end\n",
    "  return nothing # CUDA kernels must return nothing\n",
    "end\n",
    "\n",
    "function cuarray_cudanative_compare(A)\n",
    "  A_gpu = CuArray(A);\n",
    "  println(\"CUDAnative square!\")\n",
    "  @time CuArrays.@sync square!(A_gpu);\n",
    "  @time CuArrays.@sync square!(A_gpu);\n",
    "\n",
    "  println(\"CuArray A*=A\")\n",
    "  A_gpu = CuArray(A);\n",
    "  @time CuArrays.@sync A_gpu .*= A_gpu;\n",
    "  @time CuArrays.@sync A_gpu .*= A_gpu;\n",
    "  return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAnative square!\n",
      "  0.144017 seconds (100.71 k allocations: 6.322 MiB)\n",
      "  0.000426 seconds (21 allocations: 592 bytes)\n",
      "CuArray A*=A\n",
      "  0.226973 seconds (214.06 k allocations: 10.758 MiB)\n",
      "  0.000303 seconds (53 allocations: 2.594 KiB)\n"
     ]
    }
   ],
   "source": [
    "cuarray_cudanative_compare(randn(N,M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Limitations\n",
    "\n",
    "CUDA kernel functions execute on the GPU and in GPU memory. Since GPU\n",
    "memory is allocated and managed differently than RAM, many Julia\n",
    "functions will not work in CUDA kernels. Most importantly, Julia\n",
    "functions that allocate dynamically sized arrays will not work. This\n",
    "means that even matrix multiplication like ` θ = ixx*xy` will fail (if\n",
    "`ixx` or `xy` are dynamically allocated) since it allocates an array\n",
    "for ` θ`. You can, however, have local scalars, tuples, and `\n",
    "StaticArrays` within a kernel function. The key difference is that the\n",
    "sizes of these types are known at compile time. If `ixx` and `xy` are\n",
    "`StaticArrays`, then you can do something like `θ = ixx*xy`. Since the\n",
    "compiler knows the size of `ixx` and `xy`, the compiler also know the\n",
    "size of `θ`. However, even with ` StaticArrays` you must be careful\n",
    "with operations that that create new StaticArrays (like matrix\n",
    "multiplies). These will cause problems if called repeatedly within a\n",
    "loop.[^loops]\n",
    "\n",
    "[^loops]: If you create StaticArrays inside a loop, they get allocated\n",
    "    to the GPU's \"dynamic shared memory.\" I believe a new allocation\n",
    "    happens each loop iteration. This will be slow, and there is a\n",
    "    fairly small amount of dynamic shared memory, of which you will\n",
    "    soon run out.\n",
    "\n",
    "It is possible to dynamicaaly allocate GPU memory within a kernel\n",
    "function, but it requires using the low-level interface to CUDA in \n",
    "`CUDAnative.jl` and/or ` CUDAdrv.jl`. Moreoever, it is generally not a\n",
    "good idea to be dynamically allocating and freeing memory in each of\n",
    "the thousands of threads you execute.[^caveat]\n",
    "\n",
    "\n",
    "[^caveat]: There are situations where allocating shared memory is a\n",
    "    needed and a good idea, but these require some advanced techniques\n",
    "    that we will not cover.\n",
    "\n",
    "## GPU grid bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "    argridbootstrap_gpu(e; αgrid = 0.84:(0.22/20):1.06,\n",
      "                          nboot=199, RealType = Float32)\n",
      "\n",
      "Computes grid bootstrap estimates for an AR(1) model. \n",
      "\n",
      "For each α ∈ grid, repeatedly simulate data with parameter α and then compute an estimate. \n",
      " \n",
      "# Arguments\n",
      "- `e` vector error terms that will be resampled with replacement\n",
      "        to generate bootstrap sample  \n",
      "- `grid` grid of parameter values. For each value, `nboot`\n",
      "        datasets will be simulated and estimates computed.  \n",
      "- `nboot` \n",
      "- `RealType` type of numbers for GPU computation. On many GPUs,\n",
      "        Float32 will have better performance than Float64.\n",
      "\n",
      "# Returns\n",
      "- `ba` hatα - α for each grid value and simulated dataset\n",
      "- `t` t-stat  for each grid value and simulated dataset   \n",
      "\"\"\"\n",
      "function argridbootstrap_gpu(e, y0;\n",
      "                             grid = 0.84:(0.22/20):1.06,\n",
      "                             nboot=199, RealType = Float32)\n",
      "  g = length(grid)\n",
      "\n",
      "  P = 3\n",
      "  # Allocate GPU memory\n",
      "  bootq = CuArray(zeros(RealType, nboot, g))\n",
      "  ba    = CuArray(zeros(RealType, nboot, g))\n",
      "  bootse= CuArray(zeros(RealType, nboot,g))\n",
      "  αg = CuArray(RealType.(grid))\n",
      "  eg = CuArray(RealType.(e))\n",
      "  ei = Int.(ceil.(length(e).*CuArrays.rand(RealType,nboot,g,length(e))))\n",
      "\n",
      "  # use of registers in gridkernel! limits the maximum threads to less\n",
      "  # than the full 1024\n",
      "  maxthreads = sizeof(RealType)<=4 ? 512 : 256\n",
      "  gthreads =2^2\n",
      "  bthreads =maxthreads ÷ gthreads\n",
      "  bblocks = Int(ceil(nboot/bthreads))\n",
      "  gblocks = Int(ceil(g/gthreads))\n",
      "\n",
      "  @cuda threads=bthreads,gthreads blocks=bblocks,gblocks argridkernel!(ba,bootq,bootse,Val(1), eg, ei, αg)\n",
      "  ts = ba./bootse\n",
      "  (ba=collect(ba), t=collect(ts))\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "println.(functiontext(\"argridbootstrap_gpu\",joinpath(dirname(Base.pathof(ARGridBootstrap)), \"gridbootstrap.jl\")));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "    argridkernel!(ba,bootq, bootse, ar::Val{P}, e, ei, αgrid) \n",
      "\n",
      "GPU kernel for simulation and estimation of AR(P) model. \n",
      "\n",
      "# Arguments (modified on return)\n",
      "- `ba`: `nboot × ngrid` array.  Will be filled with bootstrap estimates of α\n",
      "   grid values of true α \n",
      "- `bootq`: `nboot × ngrid` array.  Will be filled with bootstrap\n",
      "   estimates of α\n",
      "- `bootse`: `nboot × ngrid` array.  Will be filled with standard\n",
      "   errors of α for each bootstrap repetition      \n",
      "\n",
      "\n",
      "# Arguments (not modified)\n",
      "- `ar::Val{P}` : autoregressive order for estimation. Simulated\n",
      "   model will always be AR(1) with 0 intercept and time trend, but\n",
      "   estimation will use an AR(P) model with intercept and time\n",
      "   trend. Only the AR(1) parameter estimate is included in `ba`,\n",
      "   `bootq`, and `bootse`.\n",
      "- `e` : error terms to draw with replacement\n",
      "- `ei` : `nboot × ngrid × length(e)` array of indices of `e` to\n",
      "         use to generate bootstrap sample1\n",
      "- `αgrid` : length `ngrid` values of AR(1) parameter to perform\n",
      "   bootstrap on.\n",
      "\n",
      "Returns nothing, but modifies in place `ba`, `bootq`, and `bootse`\n",
      "\"\"\"\n",
      "function argridkernel!(ba,bootq, bootse, \n",
      "                       ar::Val{P}, e, ei, αgrid) where P\n",
      "  b = threadIdx().x +  (blockIdx().x-1)*blockDim().x  \n",
      "  ak= threadIdx().y + (blockIdx().y-1)*blockDim().y  \n",
      "  if (b>size(ba,1) || ak>size(ba,2))\n",
      "    return nothing\n",
      "  end\n",
      "  T = size(ei,3)\n",
      "  R = eltype(ba)\n",
      "  xx = zeros(MMatrix{P+2,P+2,R})\n",
      "  xy = zeros(MVector{P+2,R})\n",
      "  xt = zeros(MVector{P+2,R})\n",
      "  xt[1] = one(R)\n",
      "  yy = zero(R)\n",
      "  xx[1,1] = T-P \n",
      "  xx[1,2] = xx[2,1] = (T+1)*T/2 - (P+1)*P/2 #sum((P+1):T) \n",
      "  xx[2,2] = (2*T+1)*T*(T+1)/6 - (2*P+1)*P*(P+1)/6 #sum((P+1:T).^2)\n",
      "  α = zeros(MVector{P+2, R})\n",
      "  α[3] = αgrid[ak]\n",
      "  @inbounds for t = (P+1):T\n",
      "    xt[2] = t\n",
      "    for i = 1:(P+2)\n",
      "      for j = 3:(P+2)\n",
      "        xx[i,j] += xt[i]*xt[j]\n",
      "      end\n",
      "    end\n",
      "    y = e[ei[b,ak,t]] + dot(α,xt)\n",
      "    for i in 1:(P+2)\n",
      "      xy[i] += xt[i]*y\n",
      "    end\n",
      "    yy += y*y\n",
      "    for i = 4:(P+2) # shift y lags\n",
      "      xt[i] = xt[i-1]\n",
      "    end\n",
      "    xt[3] = y\n",
      "  end\n",
      "  \n",
      "  for i = 3:(P+2)\n",
      "     for j = 1:(i-1)\n",
      "       xx[i,j] = xx[j,i]\n",
      "     end\n",
      "  end\n",
      "  ixx = inv(xx)\n",
      "  θ3 = zero(R)\n",
      "  for i = 1:3\n",
      "    θ3 += ixx[3,i]*xy[i]\n",
      "  end\n",
      "  ee = yy\n",
      "  for i = 1:3\n",
      "    for j = 1:3\n",
      "      ee -= xy[i]*ixx[i,j]*xy[j]\n",
      "    end\n",
      "  end\n",
      "  se3 = CUDAnative.sqrt(ixx[3,3]*ee/(T-(2*P+2)))\n",
      "  bootq[b,ak]  = θ3\n",
      "  bootse[b,ak] = se3\n",
      "  ba[b,ak] = bootq[b,ak] - αgrid[ak]\n",
      "  return nothing\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "println.(functiontext(\"argridkernel!\",joinpath(dirname(Base.pathof(ARGridBootstrap)), \"gridbootstrap.jl\")));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.071 ms (289 allocations: 892.50 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime begin\n",
    "  grid = argridbootstrap_gpu(est.e, y0, grid=αgrid, nboot=nboot, RealType=Float64);\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the fastest CPU code above, the GPU version takes about\n",
    "1/20th the time of the single-threaded CPU code, and about 1/5th the\n",
    "time of the 30-threaded CPU code. Considering that the two CPUs in my\n",
    "workstation together cost about 6 times more than the single GPU, the\n",
    "performance of the GPU code is quite good. Also, we carefully profiled\n",
    "and tuned the CPU code, but not the GPU code (although the GPU code\n",
    "does use all algorithmic improvements of the fastest CPU code). Profiling GPU kernel\n",
    "code requires using Nvidia's profiler, see\n",
    "[CUDAnative\n",
    "documentation](https://juliagpu.github.io/CUDAnative.jl/stable/man/performance.html)\n",
    "for information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
