<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="Paul Schrimpf">
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Coding for Performance - ARGridBootstrap.jl</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/atelier-forest-light.min.css">
        <link href="../assets/Documenter.css" rel="stylesheet">

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">ARGridBootstrap.jl</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href=".." class="nav-link">Package Documentation</a>
                            </li>
                            <li class="navitem active">
                                <a href="./" class="nav-link">Coding for Performance</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../license/" class="dropdown-item">License</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                            <li class="nav-item">
                                <a rel="prev" href=".." class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../license/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li class="nav-item">
                                <a href="https://github.com/schrimpf/ARGridBootstrap.jl/edit/master/docs/argridboot.md" class="nav-link"><i class="fa fa-github"></i> Edit on GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            
            <li class="nav-item" data-level="1"><a href="#introduction" class="nav-link">Introduction</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#grid-bootstrap" class="nav-link">Grid bootstrap</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#improving-performance" class="nav-link">Improving performance</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#fastest-version" class="nav-link">Fastest version</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#multi-threading" class="nav-link">Multi-threading</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#gpu" class="nav-link">GPU</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#array-interface" class="nav-link">Array interface</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#custom-cuda-kernels" class="nav-link">Custom CUDA Kernels</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#gpu-grid-bootstrap" class="nav-link">GPU grid bootstrap</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<p><a href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a></p>
<p>This work is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike
4.0 International
License</a></p>
<h3 -="-" id="about-this-document">About this document<a class="headerlink" href="#about-this-document" title="Permanent link">&para;</a></h3>
<p>This document was created using Weave.jl. The code is available in
<a href="https://github.com/schrimpf/ARGridBootstrap.jl">on github</a>. The same
document generates both static webpages and associated (jupyter
notebook)[argridboot.ipynb].</p>
<h1 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h1>
<p>Today we will look into some methods to improve the speed of our
code. Although speed is sometimes important, never forget that speed
should be low on your list of priorities when writing code. You should
prioritize correctness and maintainability ahead of
performance. Nonetheless, performance does matter for some problems.</p>
<p>If you have not already, be sure to read <a href="https://docs.julialang.org/en/v1/manual/performance-tips/#man-performance-tips-1">the Peformance Tips section of Julia Docs</a>.</p>
<p>Also, read Rackauckas&rsquo;s notes on <a href="https://mitmath.github.io/18337/lecture2/optimizing">&ldquo;Optimizing Serial Code.&rdquo;</a> [^1].</p>
<h1 id="grid-bootstrap">Grid bootstrap<a class="headerlink" href="#grid-bootstrap" title="Permanent link">&para;</a></h1>
<p>As a motivating example we will look at the gridded bootstrap of
Hansen (1999)[^2].</p>
<!-- FIXME: DESCRIPTION.  -->

<p>Gauss, Matlab, and R code implementing Hansen&rsquo;s method is available on
<a href="https://www.ssc.wisc.edu/~bhansen/progs/restat_99.html">Hansen&rsquo;s
website</a>. The
Julia code below is more or less a direct translation from Hansen&rsquo;s R
code. Since this is a translation from R of a translation from Gauss,
this code will not necessarily follow best practices for Julia.</p>
<pre><code class="language-julia">T = 200
e = randn(T)
y0 = 0
a = 0.9
s = @code_string b_est_original(e)
code_md(s)
</code></pre>
<pre><code class="language-julia">function b_est_original(yin)
  T = length(yin)
  x = [ones(T-1) 2:T yin[1:(T-1)]]
  y = yin[2:T]
  θ = x'*x \ x'y
  e = y - x*θ
  se = sqrt.(diag(inv(x'*x) *(e'*e))./(T-4))
  (θ=θ,se=se,e=e)
end
</code></pre>
<pre><code class="language-julia">s=@code_string ar1_original(y0,a,e)
code_md(s)
</code></pre>
<pre><code class="language-julia">function ar1_original(y0, a, e, rindex=T-&gt;rand(1:length(e),T))
  T = length(e)
  y = Array{eltype(e)}(undef, T)
  y[1] = abs(a)&lt;1 ? y0 : zero(eltype(y))
  et = e[rindex(T-1)]
  for t in 2:T
    y[t] = a*y[t-1] + et[t-1] 
  end
  y
end
</code></pre>
<pre><code class="language-julia">s = @code_string gridbootstrap(b_est_original, a-&gt;a, 0.5:0.1:1, 99)
code_md(s)
</code></pre>
<pre><code class="language-julia">function gridbootstrap(estimator, simulator,
                       grid::AbstractVector,
                       nboot=199)
  g = length(grid)
  bootq = zeros(nboot, g)
  ba    = zeros(nboot, g)
  bootse = zeros(nboot,g)
  for ak in 1:g
    for j in 1:nboot
      (bootq[j,ak], bootse[j,ak]) = estimator(simulator(grid[ak]))
      ba[j,ak] = bootq[j,ak] - grid[ak]
    end
  end
  ts = ba./bootse
  (ba=ba, t=ts)
end
</code></pre>
<h2 id="improving-performance">Improving performance<a class="headerlink" href="#improving-performance" title="Permanent link">&para;</a></h2>
<p>Now, let&rsquo;s run this code and time it. Note that we are running this
with only 50 grid points and 199 bootstrap replications. In real use,
you would want more like 999 bootstrap replications or more, and perhaps more
grid points.</p>
<pre><code class="language-julia">julia&gt; Profile.clear();
Error: UndefVarError: Profile not defined

julia&gt; Profile.init(n=10^7,delay=0.0001);
Error: UndefVarError: Profile not defined

julia&gt; @profile (b,t) = gridbootstrap(wrapper(b_est_original), a-&gt;ar1_original(y0, a, est.e),
                                      αgrid, 999);
Error: LoadError: UndefVarError: @profile not defined
in expression starting at /home/paul/.julia/dev/ARGridBootstrap/docs/jmd/argridboot.jmd:1

julia&gt; Profile.print(noisefloor=2.0)
Error: UndefVarError: Profile not defined
</code></pre>
<p>To make code faster, we should begin by profiling.</p>
<pre><code class="language-julia">println.(functiontext(&quot;b_est_mldivide&quot;,joinpath(dirname(Base.pathof(ARGridBootstrap)), &quot;ar.jl&quot;)));
</code></pre>
<pre><code>&quot;&quot;&quot;
    b_est_mldivide(y)

  Estimate AR(1) model with intercept and time trend. 

    y[t] = θ[0] + θ[1]t + θ[2]y[t-1] + e[t]

# Arguments    
- `y`: vector 

# Returns
- `θ`: estimated coefficients
- `se`: standard errors
- `e`: residuals 
&quot;&quot;&quot;
function b_est_mldivide(yin)
  T = length(yin)
  x = [ones(T-1) 2:T yin[1:(T-1)]]
  y = yin[2:T]
  tmp = x'*x \ [x'*y I]
  θ = tmp[:,1]
  ixx = tmp[:,2:4]
  e = y - x*θ
  se = sqrt.(diag(ixx *(e'*e))./(T-4))
  (θ=θ,se=se,e=e)
end
</code></pre>
<p>Profile.jl works very simply. Every 0.0001 seconds, the line of code
being executed gets recorded. <code>Profile.print</code> shows the count of how
many times each line of code got recorded. From the output (these
numbers can vary quite a bit from run to run), we see
there were 640 ticks in <code>gridbootstrap_original</code> (exact numbers will
vary on each execution, but relative ones should be similar), and
almost all of these occurred within <code>inv</code>.  If we want the
code to be faster, we should focus on these lines.  Calling both <code>inv</code>
and <code>\</code> is redundant; we should combine these computations.</p>
<pre><code class="language-julia">s = @code_string b_est_mldivide(y)
code_md(s)
</code></pre>
<pre><code class="language-julia">function b_est_mldivide(yin)
  T = length(yin)
  x = [ones(T-1) 2:T yin[1:(T-1)]]
  y = yin[2:T]
  tmp = x'*x \ [x'*y I]
  θ = tmp[:,1]
  ixx = tmp[:,2:4]
  e = y - x*θ
  se = sqrt.(diag(ixx *(e'*e))./(T-4))
  (θ=θ,se=se,e=e)
end
</code></pre>
<pre><code class="language-julia">julia&gt; Profile.clear();
Error: UndefVarError: Profile not defined

julia&gt; @profile (b,t) = gridbootstrap(wrapper(b_est_mldivide), a-&gt;ar1_original(y0, a, est.e),
                                      αgrid, 999);
Error: LoadError: UndefVarError: @profile not defined
in expression starting at /home/paul/.julia/dev/ARGridBootstrap/docs/jmd/argridboot.jmd:1

julia&gt; Profile.print(noisefloor=2.0)
Error: UndefVarError: Profile not defined
</code></pre>
<p>From this, we get a speedup by about a factor of 4 on my computer.</p>
<pre><code class="language-julia">println.(functiontext(&quot;b_est_nox&quot;,joinpath(dirname(Base.pathof(ARGridBootstrap)), &quot;ar.jl&quot;)));
</code></pre>
<pre><code>&quot;&quot;&quot; 
    b_est_nox(y)

  Estimate AR(1) model with intercept and time trend. 

    y[t] = θ[0] + θ[1]t + θ[2]y[t-1] + e[t]

# Arguments
- `y`: vector 

# Returns
- `θ`: estimated coefficients
- `se`: standard errors
- `e`: residualas 
&quot;&quot;&quot;
function b_est_nox(yin)
  T = length(yin)
  xx = @MMatrix zeros(eltype(yin),3,3)
  xy = @MVector zeros(eltype(yin),3)
  @inbounds @simd for t in 2:T
    xx[1,3] += yin[t-1]
    #xx[2,3] += t*yin[t-1]
    xx[2,3] = muladd(t,yin[t-1], xx[2,3])
    xx[3,3] += yin[t-1]^2
    xy[1] += yin[t]
    #xy[2] += t*yin[t]
    xy[2] = muladd(t, yin[t], xy[2])
    xy[3] = muladd(yin[t-1],yin[t], xy[3])
  end 
  xx[1,1] = T-1 # = 1'*1
  xx[1,2] = xx[2,1] = (T+1)*T/2 - 1 # sum(p+1:T)
  xx[2,2] = (2*(T)+1)*(T)*(T+1)/6 - 1 # sum((p+1:T).^2)  
  xx[3,1] = xx[1,3]
  xx[3,2] = xx[2,3]
  ixx = inv(xx)
  θ = ixx * xy
  e = similar(yin,T-1)
  @simd for t in 2:T
    @inbounds e[t-1] = yin[t] - θ[1] - θ[2]*t - θ[3]*yin[t-1]
  end
  se = sqrt.(diag(ixx *(e'*e))./(T-4))
  (θ=θ,se=se,e=e)
end
</code></pre>
<p>Now, the most time consuming parts of the code are, unsurprisingly,
the call to <code>\</code>, and, perhaps surprisingly, <code>hcat</code> from
creating <code>x</code>. Allocating and copying memory is relatively slow. The
creation of <code>x</code> involves both. We can avoid creating <code>x</code> by just
accumulating $X&rsquo;y$ and $X&rsquo;X$ in a loop.</p>
<pre><code class="language-julia">s = @code_string b_est_nox(y)
code_md(s)
</code></pre>
<pre><code class="language-julia">function b_est_nox(yin)
  T = length(yin)
  xx = @MMatrix zeros(eltype(yin),3,3)
  xy = @MVector zeros(eltype(yin),3)
  @inbounds @simd for t in 2:T
    xx[1,3] += yin[t-1]
    #xx[2,3] += t*yin[t-1]
    xx[2,3] = muladd(t,yin[t-1], xx[2,3])
    xx[3,3] += yin[t-1]^2
    xy[1] += yin[t]
    #xy[2] += t*yin[t]
    xy[2] = muladd(t, yin[t], xy[2])
    xy[3] = muladd(yin[t-1],yin[t], xy[3])
  end 
  xx[1,1] = T-1 # = 1'*1
  xx[1,2] = xx[2,1] = (T+1)*T/2 - 1 # sum(p+1:T)
  xx[2,2] = (2*(T)+1)*(T)*(T+1)/6 - 1 # sum((p+1:T).^2)  
  xx[3,1] = xx[1,3]
  xx[3,2] = xx[2,3]
  ixx = inv(xx)
  θ = ixx * xy
  e = similar(yin,T-1)
  @simd for t in 2:T
    @inbounds e[t-1] = yin[t] - θ[1] - θ[2]*t - θ[3]*yin[t-1]
  end
  se = sqrt.(diag(ixx *(e'*e))./(T-4))
  (θ=θ,se=se,e=e)
end
</code></pre>
<pre><code class="language-julia">using StaticArrays
</code></pre>
<pre><code>Error: ArgumentError: Package StaticArrays not found in current path:
- Run `import Pkg; Pkg.add(&quot;StaticArrays&quot;)` to install the StaticArrays pac
kage.
</code></pre>
<p>We have further cut the time by a factor of two. However, this performance
optimization has been costly in terms of readability and extensibility
of our code. If we wanted to fit an AR(p) model instead of AR(1), the
<code>b_est_nox</code> function would be more difficult to modify than the
<code>b_est_mldivide</code> version.</p>
<p>EXERCISE: Read <a href="https://docs.julialang.org/en/v1/manual/performance-tips/">the Performance Tips section of Julia
Manual</a> and
incorporate some of these tips into the above code.</p>
<p>EXERCISE: write a version of <code>b_est</code> that avoids allocating the full
$T \times 3$ $X$ matrix, but can still be generalized to an AR(p) model.</p>
<p>EXERCISE: examine how the relative performance of these versions of <code>b_est</code> vary with <code>T</code>, <code>nboot</code>, and the number of grid points.</p>
<p>EXERCISE: the Julia package <code>StaticArrays.jl</code> provides an alternative
array implementation that is often much faster than <code>Base.Array</code>. Try
implementing <code>b_est</code> using <code>StaticArrays.jl</code>. You will likely need to
use mutable arrays (see <code>@MMatrix</code> and <code>@MVector</code>). Note that <code>inv</code> of
a small array will be substantially faster when using <code>StaticArray.jl</code>
instead of <code>Base.Array</code>.</p>
<h2 id="fastest-version">Fastest version<a class="headerlink" href="#fastest-version" title="Permanent link">&para;</a></h2>
<p>The fastest version of the code that I could write combines the ideas
above. As above, it avoids allocating <code>x</code>. It also avoids allocating
<code>e</code> by combining the simulation and estimation into a single
loop. Finally, it uses mutable static arrays to ensure that operations
on <code>xx</code> and <code>xy</code> have as little overhead as possible. Note that for
small StaticArrays, <code>inv</code> will call a specialized, fast version, and
ends up being faster than <code>\</code>.</p>
<pre><code class="language-julia">using StaticArrays
</code></pre>
<pre><code class="language-julia">s = @code_string simulate_estimate_arp(y0,a,e)
code_md(s)
</code></pre>
<pre><code class="language-julia">function simulate_estimate_arp(y0, a, e, ar::Val{P}=Val(1),
                               rindex=()-&gt;rand(1:length(e))) where P
  T = length(e)
  length(a)==P || error(&quot;length(a) not equal to P&quot;)
  xx = @MMatrix zeros(eltype(e),P+2, P+2)
  xy = @MVector zeros(eltype(e),P+2)
  yy = zero(eltype(e))
  xt = @MVector ones(eltype(e), P+2)
  if (abs(a)&lt;1)
    xt[3:(P+2)] .= y0
  else 
    xt[3:(P+2)] .= 0.0
  end
  α = @MVector zeros(eltype(e),P+2)
  @simd for i = 1:P
    α[2+i] = a[i]
  end

  xx[1,1] = T-P # = 1'*1
  xx[1,2] = xx[2,1] = (T+1)*T/2 - sum(1:P) # sum(P+1:T)
  xx[2,2] = (2*(T)+1)*(T)*(T+1)/6 - sum((1:P).^2) # sum((P+1:T).^2)  
  @inbounds for t in (P+1):T
    et = e[rindex()]
    xt[2] = t
    for i in 1:(P+2)
      @simd for j in 3:(P+2)
        xx[i,j] += xt[i]*xt[j]
      end
    end
    y = dot(α, xt) + et
    @simd for i in 1:(P+2)
      xy[i] += xt[i]*y
    end
    yy += y^2
    if (P&gt;1)
      xt[4:(P+2)] .= xt[3:(P+1)]
    end
    xt[3] = y
  end
  @inbounds for i in 3:(P+2)
    for j in 1:(i-1)
      xx[i,j] = xx[j,i]
    end
  end
  ixx = inv(xx)
  θ = ixx*xy
  ee = yy - xy'*ixx*xy
  se = sqrt.(abs.(diag(ixx *(ee))./(T-(2*P+2))))
  (θ=θ,se=se)
end
</code></pre>
<pre><code class="language-julia">println.(functiontext(&quot;gridbootstrap_threaded&quot;,joinpath(dirname(Base.pathof(ARGridBootstrap)), &quot;gridbootstrap.jl&quot;)));
</code></pre>
<pre><code>&quot;&quot;&quot;
    gridbootstrap_threaded(estimator, simulator, 
                    grid::AbstractVector, 
                    nboot=199, rng=rngarray(nthreads())

Computes grid bootstrap estimates a single parameter model. 

Multithreaded version.

For each α ∈ grid, repeatedly simulate data with parameter α and then compu
te an estimate. 


# Arguments
- `estimator` function of output of `simulator` that returns a
    2-tuple containing an estimate of α and its standard error.  
- `simulator` function that given `α` and `rng`, simulates data
    that can be used to estimate α 
- `grid` grid of parameter values. For each value, `nboot`
    datasets will be simulated and estimates computed.  
- `nboot` 
- `rng` array of RNG states of length = number of threads

# Returns
- `ba` hatα - α for each grid value and simulated dataset
- `t` t-stat  for each grid value and simulated dataset
&quot;&quot;&quot;
function gridbootstrap_threaded(estimator, simulator,
                                grid::AbstractVector,
                                nboot=199; rng=rngarray(nthreads()))
  g = length(grid)
  bootq = zeros(nboot, g)
  ba    = zeros(nboot, g)
  bootse = zeros(nboot,g)
  #@threads for ak in 1:g
  #  for j in 1:nboot
  @threads for idx ∈ CartesianIndices(ba)
    j =  idx[1]
    ak = idx[2]
    (bootq[j,ak], bootse[j,ak]) = estimator(simulator(grid[ak],rng[threadid
()]))
    ba[j,ak] = bootq[j,ak] - grid[ak]
  end
  ts = ba./bootse
  (ba=ba, t=ts)
end
</code></pre>
<p>On my computer, this version of the code is about 15 times faster than
the original.</p>
<h1 id="multi-threading">Multi-threading<a class="headerlink" href="#multi-threading" title="Permanent link">&para;</a></h1>
<p>Modern computers almost all have multiple cores. We can divide the
time it takes our code by up to the number of cores we have (but
usually less) by writing multi-threaded code. Multi-threaded code
performs multiple tasks at once with shared memory. Before you begin
writing multi-threaded code, you should make sure your code isn&rsquo;t
already using all available cores. It is likely that the BLAS and
Lapack libraries that Julia uses for linear algebra are
multi-threaded. If you code is dominated by large matrix operations,
it may already be using all available cores. In that case, there will
not be much benefit from additional multi-threading.</p>
<p>Read <a href="https://mitmath.github.io/18337/lecture5/parallelism_overview">&ldquo;The Basics of Single Node Parallel Computing&rdquo;</a>
Rackauckus (2019) [^3] .</p>
<p>Once we have decided that the code might benefit from multi-threading,
we should look for loops (or other independent tasks) that can be
multi-threaded. There is some overhead from creating threads and
communicating among them. Multi-threading generally works best for
loops where each iteration involves substantial work, and each
iteration is independent of all others. The loops over grid points and
bootstrap repetitions in <code>gridbootstrap</code> are perfect candidates. We
don&rsquo;t care about the order in which these loops get executed. The
result of each iteration is (mostly) independent of all others.</p>
<p>Some care must be taken with random number generators and
multi-threaded code. See
<a href="https://docs.julialang.org/en/v1/manual/parallel-computing/index.html#Side-effects-and-mutable-function-arguments-1">the Julia docs</a> for more information.</p>
<pre><code class="language-julia">rng = rngarray(nthreads())
s=@code_string gridbootstrap_threaded(wrapper(b_est_original), (a, rng)-&gt;ar1_original(y0, a, est.e, n-&gt;rand(rng,1:(T-1),n)),αgrid, 2, rng=rng)
code_md(s)
</code></pre>
<p>Error: MethodError: no method matching getindex(::Nothing, ::Int64)</p>
<p>Now, let&rsquo;s try multi-threading the original version of the code.</p>
<pre><code class="language-julia">using Base.Threads
println(&quot;Single thread, original version&quot;)
@time begin # this is so slow that using btime is not so necessary
  (b,t) = gridbootstrap(wrapper(b_est_original), a-&gt;ar1_original(y0, a, est.e),
                        αgrid, 199);
end;

rng = rngarray(nthreads())
# make sure the threaded version is compiled before timing it
(b,t) = gridbootstrap_threaded(wrapper(b_est_original),
                               (a, rng)-&gt;ar1_original(y0, a, est.e, n-&gt;rand(rng,1:(T-1),n)),
                               αgrid, 2, rng=rng);
println(&quot;$(nthreads()) threads, original version&quot;)
@time begin # this is so slow that using btime is not so necessary
  (b,t) = gridbootstrap_threaded(wrapper(b_est_original),
                                 (a, rng)-&gt;ar1_original(y0, a, est.e, n-&gt;rand(rng,1:(T-1),n)),
                                 αgrid, 199, rng=rng);
end;
</code></pre>
<pre><code>Single thread, original version
Error: UndefVarError: wrapper not defined
</code></pre>
<p>The execution times are nearly identical on my computer. The reason is
that the computation is dominated by the creation of <code>X</code> and
multiplying <code>X'*X</code> and <code>X'*y</code>. These operations are already
multi-threaded in the BLAS version I have installed. It is possible
first calling <code>using LinearAlgebra; BLAS.set_num_threads(1)</code> would
improve the performance of the multi-threaded bootstrap.</p>
<pre><code class="language-julia">println(&quot;Single thread, fastest version&quot;)
@btime  (b,t) = gridbootstrap(estimator(), a-&gt;a, αgrid, nboot);

println(&quot;$(nthreads()) threads, fastest version&quot;)
estimator_threaded(y0=y0,e=est.e)=function(foo)
  (a, rng) = foo
  out=simulate_estimate_arp(y0,a,e,Val(1),()-&gt;rand(rng,1:length(e)))
  (out.θ[3], out.se[3])
end
rng = rngarray(nthreads())
@btime begin
  (bs, ts) = gridbootstrap_threaded(estimator_threaded(),
                                    (a,rng)-&gt;(a,rng), αgrid,
                                    nboot, rng=rng)  
end;
</code></pre>
<pre><code>Single thread, fastest version
Error: LoadError: UndefVarError: @btime not defined
in expression starting at /home/paul/.julia/dev/ARGridBootstrap/docs/jmd/ar
gridboot.jmd:3
</code></pre>
<p>Notice how the speedup from using multiple threads is far less than
number of cores. On my computer, the threaded version of the code is
about 4 times faster, even though my computer has 40 &ldquo;cores&rdquo; (or 20
physical cores. My computer has 2 processors with 10 cores each, and each
core is hyperthreaded into 2. The OS sees 40 processors, but half of
them are sharing substantial resources). A speedup far less than the
number of cores is typical. Creating and managing multiple threads
creates some overhead. Moreover, cores must share various resources;
most notably RAM and some cache.</p>
<h1 id="gpu">GPU<a class="headerlink" href="#gpu" title="Permanent link">&para;</a></h1>
<p>Compared to CPUs, GPUs have a huge number of cores operating at a
slower clockrate. GPUs also have their own separate memory, which they
can access faster than CPUs access RAM.  These characteristics make
GPUs well-suited to large parallel computations. Unfortunately, fully
utilizing GPUs can require substantial changes to your code.</p>
<p>See <a href="https://mitmath.github.io/18337/lecture6/styles_of_parallelism">&ldquo;The Different Flavors of
Parallelism&rdquo;</a>
Rackauckas (2019) [^4] for more information comparing
GPUs to various forms of parallelism on CPUs.</p>
<h2 id="array-interface">Array interface<a class="headerlink" href="#array-interface" title="Permanent link">&para;</a></h2>
<p>The easiest way to use a GPU in Julia is through a high level array
interface. <code>ArrayFire.jl</code>, <code>oneAPI.jl</code>, and <code>CUDA.jl</code> each offer such
interfaces. We will focus on <code>CUDA.jl</code> in these
notes. <code>CUDA.jl</code> relies on Nvidia&rsquo;s CUDA platform, so it only
works with Nvidia GPUs. Nvidia tends to dominate GPGPU, and the GPUs
available on cedar.computecanada.ca and in my desktop are Nvidia.</p>
<p>Using CUDA.CuArray is simple, but has some limitations. You create arrays
on the GPU using <code>CuArray</code>. Any array level operation on these will
then be performed efficiently on the GPU. This includes broadcast
functions with <code>.</code> and matrix multiplies.</p>
<pre><code class="language-julia">using CUDA, Random, BenchmarkTools


N = 1000
M = 1000

function cuarraydemo(N,M)
  # wrapped in a  function so that the CuArrays are freed
  # otherwise we will run out GPU memory later
  A = randn(N,M);
  b = randn(M,2);
  println(&quot;Time on CPU&quot;)
  function foo(A,b)
    (A.^2)*b
  end
  @time c=foo(A,b);
  @time c=foo(A,b);
  A_gpu = CuArray(A); # copy of A in GPU memory
  b_gpu = CuArray(b);
  println(&quot;Computations on the GPU are fast&quot;)
  # @btime does not work inside a function
  @time CUDA.@sync c_gpu=foo(A_gpu,b_gpu);
  @time CUDA.@sync c_gpu=foo(A_gpu,b_gpu);
  println(&quot;But copying to and from GPU memory is not&quot;)
  bar(A,b) =Array(foo(CuArray(A), CuArray(b)))
  @time c2=bar(A,b);
  @time c2=bar(A,b);
end
</code></pre>
<pre><code>cuarraydemo (generic function with 1 method)
</code></pre>
<pre><code class="language-julia">julia&gt; cuarraydemo(N,M);
Time on CPU
  0.004548 seconds (3 allocations: 7.645 MiB)
  0.005072 seconds (3 allocations: 7.645 MiB)
Computations on the GPU are fast
  0.000300 seconds (61 allocations: 2.406 KiB)
  0.000207 seconds (61 allocations: 2.406 KiB)
But copying to and from GPU memory is not
  0.001016 seconds (77 allocations: 18.609 KiB)
  0.001003 seconds (77 allocations: 18.609 KiB)
</code></pre>
<p><code>CuArray</code>s also allow indexing, so you could use loops and other
constructs. However, this will not be fast. <code>CuArray</code>s by itself will be
a good method to utilize GPUs when the code is dominated by operations
on large arrays.</p>
<p>Unfortunately, the fastest version of our grid bootstrap code does not
fit that description. A loop seems needed to generate $y$ due to the
recursiveness of the AR(1) model. The fastest version of the code
above involves many operations on small 3x3 arrays.</p>
<p>EXERCISE: modify <code>b_est_original</code> or <code>b_est_mldivide</code> to utilize
<code>CuArray</code>s. The approach taken in those functions involves some
moderate sized matrices, so it may benefit from <code>CuArray</code>s.</p>
<h2 id="custom-cuda-kernels">Custom CUDA Kernels<a class="headerlink" href="#custom-cuda-kernels" title="Permanent link">&para;</a></h2>
<p>To parallelize the code above on a GPU, we will have to use a lower
level interface to the GPU. To explain how it works, we will begin
with a simple example that just squares all the elements of an array.</p>
<p>Disclaimer: my understanding of CUDA and the inner workings of GPUs is
far from complete. Some of the details in this section might be
inaccurate.</p>
<p>A typical workflow with CUDA consists of</p>
<ol>
<li>Allocate GPU memory and copying arrays into it with <code>CuArray</code>.</li>
<li>Decide how many threads and what configuration of threads to
   launch.</li>
<li>Each thread does some computation by running a &ldquo;kernel&rdquo; function.</li>
<li>Copy result from GPU memory to CPU memory.</li>
</ol>
<p>In the code below, 1 happens in <code>cuarray_cudanative_compare</code>, 2 happens in the
<code>square!</code> function, <code>square_kernel!</code> is the kernel in 3, and 4 is just
not done.</p>
<h3 id="threads-and-blocks">Threads and blocks<a class="headerlink" href="#threads-and-blocks" title="Permanent link">&para;</a></h3>
<p>CUDA organizes GPU threads into blocks. I believe that the threads in
a block all execute concurrently. Threads in the same block share some
memory and registers. All current Nvidia GPUs have a maximum number of
threads per block of 1024. Note that threads in the same block share
registers<sup id="fnref:reg"><a class="footnote-ref" href="#fn:reg">1</a></sup>, and different kernel functions will use different
numbers of registers at once, so depending on the kernel function, you
might be limited to fewer than 1024 threads per block. The number of
registers available per block depends on your GPU. You can check your
GPU characteristics by compiling and running the C++ program in
<code>$CUDA_PATH/samples/1_Utilities/deviceQuery/</code>. Alternatively, you can
see this information in Julia by running the code below.</p>
<pre><code class="language-julia">println(&quot;Maximum threads per block $(attribute(device(), CUDA.CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK))&quot;)
println(&quot;Maximum x blocks $(attribute(device(), CUDA.CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_X))&quot;)
println(&quot;Maximum registers per block $(attribute(device(), CUDA.CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_BLOCK))&quot;)
</code></pre>
<pre><code>Maximum threads per block 1024
Maximum x blocks 2147483647
Maximum registers per block 65536
</code></pre>
<p>There is no simple way to predict how many registers a kernel function
uses. It will depend both on the code you write and how the compiler
optimizes the code. If you encounter cryptic error messages about CUDA
resources unavailable, then try reducing the number of threads per
block. Alternatively, you can limit the number of registers used by
passing the <code>maxregs</code> argument to <code>@cuda</code>.</p>
<p>You can execute more than 1024 threads by specifying a number of
blocks. There is also a limit to the number of blocks, but it is
rather large. In the code below, we set the number of blocks, so that
<code>nblocks*nthreads &gt;= length(A)</code>. Each thread then operates on a single
element of <code>A</code>. When the code is executed, each thread has a unique
<code>threadIdx</code> and <code>blockIdx</code> combination, and these are used to assign
threads to elements of <code>A</code>. The indices go from 1 to number of threads
(or blocks). For convenience you can request threads and blocks to
have up 3 dimensions, and there are <code>threadIdx().y</code> and
<code>threadIdx().z</code> for the additional dimensions.</p>
<pre><code class="language-julia">function square!(A::CuArray)
  n = length(A)
  maxthreads = 1024
  nthreads = min(maxthreads, n)
  nblocks  = Int(ceil(n/nthreads))

  @cuda threads=nthreads blocks=nblocks square_kernel!(A)

  return A
end

function square_kernel!(A)
  i = threadIdx().x + (blockIdx().x-1)*blockDim().x
  if (i&lt;=length(A))
    @inbounds A[i] *= A[i]
  end
  return nothing # CUDA kernels must return nothing
end

function cuarray_cudanative_compare(A)
  A_gpu = CuArray(A);
  println(&quot;CUDAnative square!&quot;)
  @time CUDA.@sync square!(A_gpu);
  @time CUDA.@sync square!(A_gpu);

  println(&quot;CuArray A*=A&quot;)
  A_gpu = CuArray(A);
  @time CUDA.@sync A_gpu .*= A_gpu;
  @time CUDA.@sync A_gpu .*= A_gpu;
  return nothing
end
</code></pre>
<pre><code>cuarray_cudanative_compare (generic function with 1 method)
</code></pre>
<pre><code class="language-julia">julia&gt; cuarray_cudanative_compare(randn(N,M))
CUDAnative square!
  0.065662 seconds (18.80 k allocations: 2.233 MiB, 18.22% compilation time)
  0.000126 seconds (3 allocations: 256 bytes)
CuArray A*=A
  0.000174 seconds (23 allocations: 1.859 KiB)
  0.000135 seconds (23 allocations: 1.859 KiB)
</code></pre>
<h3 id="kernel-limitations">Kernel Limitations<a class="headerlink" href="#kernel-limitations" title="Permanent link">&para;</a></h3>
<p>CUDA kernel functions execute on the GPU and in GPU memory. Since GPU
memory is allocated and managed differently than RAM, many Julia
functions will not work in CUDA kernels. Most importantly, Julia
functions that allocate dynamically sized arrays will not work. This
means that even matrix multiplication like <code>θ = ixx*xy</code> will fail (if
<code>ixx</code> or <code>xy</code> are dynamically allocated) since it allocates an array
for <code>θ</code>. You can, however, have local scalars, tuples, and <code>StaticArrays</code> within a kernel function. The key difference is that the
sizes of these types are known at compile time. If <code>ixx</code> and <code>xy</code> are
<code>StaticArrays</code>, then you can do something like <code>θ = ixx*xy</code>. Since the
compiler knows the size of <code>ixx</code> and <code>xy</code>, the compiler also know the
size of <code>θ</code>. However, even with <code>StaticArrays</code> you must be careful
with operations that that create new StaticArrays (like matrix
multiplies). These will cause problems if called repeatedly within a
loop.<sup id="fnref:loops"><a class="footnote-ref" href="#fn:loops">2</a></sup></p>
<p>It is possible to dynamicaaly allocate GPU memory within a kernel
function, but it requires using the low-level interface to CUDA in
<code>CUDA.jl</code>. Moreoever, it is generally not a good idea to be
dynamically allocating and freeing memory in each of the thousands of
threads you execute.<sup id="fnref:caveat"><a class="footnote-ref" href="#fn:caveat">3</a></sup></p>
<h2 id="gpu-grid-bootstrap">GPU grid bootstrap<a class="headerlink" href="#gpu-grid-bootstrap" title="Permanent link">&para;</a></h2>
<pre><code class="language-julia">s = @code_string argridbootstrap_gpu(est.e, y0, grid=αgrid, nboot=nboot, RealType=Float64)
code_md(s)
</code></pre>
<p>Error: MethodError: no method matching getindex(::Nothing, ::Int64)</p>
<pre><code class="language-julia">s = @code_string ARGridBootstrap.argridkernel!(1.,1., 1., Val(1), 1., 1. , 1.)
code_md(s)
</code></pre>
<pre><code class="language-julia">function argridkernel!(ba,bootq, bootse,
                       ar::Val{P}, e, ei, αgrid) where P
  b = threadIdx().x +  (blockIdx().x-1)*blockDim().x
  ak= threadIdx().y + (blockIdx().y-1)*blockDim().y
  if (b&gt;size(ba,1) || ak&gt;size(ba,2))
    return nothing
  end
  T = size(ei,3)
  R = eltype(ba)
  xx = zeros(MMatrix{P+2,P+2,R})
  xy = zeros(MVector{P+2,R})
  xt = zeros(MVector{P+2,R})
  xt[1] = one(R)
  yy = zero(R)
  xx[1,1] = T-P
  xx[1,2] = xx[2,1] = (T+1)*T/2 - (P+1)*P/2 #sum((P+1):T)
  xx[2,2] = (2*T+1)*T*(T+1)/6 - (2*P+1)*P*(P+1)/6 #sum((P+1:T).^2)
  α = zeros(MVector{P+2, R})
  α[3] = αgrid[ak]
  @inbounds for t = (P+1):T
    xt[2] = t
    for i = 1:(P+2)
      for j = 3:(P+2)
        xx[i,j] += xt[i]*xt[j]
      end
    end
    y = e[ei[b,ak,t]] + dot(α,xt)
    for i in 1:(P+2)
      xy[i] += xt[i]*y
    end
    yy += y*y
    for i = 4:(P+2) # shift y lags
      xt[i] = xt[i-1]
    end
    xt[3] = y
  end

  for i = 3:(P+2)
     for j = 1:(i-1)
       xx[i,j] = xx[j,i]
     end
  end
  ixx = inv(xx)
  θ3 = zero(R)
  for i = 1:3
    θ3 += ixx[3,i]*xy[i]
  end
  ee = yy
  for i = 1:3
    for j = 1:3
      ee -= xy[i]*ixx[i,j]*xy[j]
    end
  end
  se3 = CUDA.sqrt(ixx[3,3]*ee/(T-(2*P+2)))
  bootq[b,ak]  = θ3
  bootse[b,ak] = se3
  ba[b,ak] = bootq[b,ak] - αgrid[ak]
  return nothing
end
</code></pre>
<pre><code class="language-julia">@btime begin
  grid = argridbootstrap_gpu(est.e, y0, grid=αgrid, nboot=nboot, RealType=Float64);
end;
</code></pre>
<pre><code>Error: LoadError: UndefVarError: @btime not defined
in expression starting at /home/paul/.julia/dev/ARGridBootstrap/docs/jmd/ar
gridboot.jmd:2
</code></pre>
<p>Compared to the fastest CPU code above, the GPU version takes about
1/20th the time of the single-threaded CPU code, and about 1/5th the
time of the 30-threaded CPU code. Considering that the two CPUs in my
workstation together cost about 6 times more than the single GPU, the
performance of the GPU code is quite good. Also, we carefully profiled
and tuned the CPU code, but not the GPU code (although the GPU code
does use all algorithmic improvements of the fastest CPU code). Profiling GPU kernel
code requires using Nvidia&rsquo;s profiler, see
<a href="https://cuda.juliagpu.org/stable/development/profiling/">CUDA.jl
documentation</a>
for information.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:reg">
<p>Processor registers are the fastest bits of memory on the
processor, and registers are where the actual addition,
multiplication, and other instructions are carried out.&#160;<a class="footnote-backref" href="#fnref:reg" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:loops">
<p>If you create StaticArrays inside a loop, they get allocated
to the GPU&rsquo;s &ldquo;dynamic shared memory.&rdquo; I believe a new allocation
happens each loop iteration. This will be slow, and there is a
fairly small amount of dynamic shared memory, of which you will
soon run out.&#160;<a class="footnote-backref" href="#fnref:loops" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:caveat">
<p>There are situations where allocating shared memory is
needed and a good idea, but these require some advanced techniques
that we will not cover.&#160;<a class="footnote-backref" href="#fnref:caveat" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
</ol>
</div></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Paul Schrimpf</p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML" defer></script>
        <script src="../assets/mathjaxhelper.js" defer></script>

        <div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
